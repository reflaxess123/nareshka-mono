#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ LLM-–æ—Ç—á–µ—Ç–æ–≤ –∏–Ω—Ç–µ—Ä–≤—å—é –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö PostgreSQL
"""

import os
import re
import hashlib
import json
from datetime import datetime
from pathlib import Path
import psycopg2
from psycopg2.extras import RealDictCursor
import uuid
from typing import Dict, List, Optional, Tuple


class InterviewReportImporter:
    def __init__(self, db_config: Dict[str, str]):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏–º–ø–æ—Ä—Ç–µ—Ä–∞
        
        Args:
            db_config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î
        """
        self.db_config = db_config
        self.connection = None
        self.companies_mapping = {}
        self.tech_standardization = {
            'javascript': 'JavaScript',
            'js': 'JavaScript', 
            'react': 'React',
            'typescript': 'TypeScript',
            'ts': 'TypeScript',
            'css': 'CSS',
            'html': 'HTML',
            'redux': 'Redux',
            'node': 'Node.js',
            'nodejs': 'Node.js',
            'vue': 'Vue.js',
            'angular': 'Angular',
            'python': 'Python',
            '–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞': 'Architecture',
            '–∫–æ–º–∞–Ω–¥–∞': 'TeamWork',
            '–∞–ª–≥–æ—Ä–∏—Ç–º—ã': 'Algorithms',
            'git': 'Git'
        }
        self.company_standardization = {
            '—Å–±–µ—Ä–±–∞–Ω–∫': '–°–±–µ—Ä',
            '—Å–±–µ—Ä': '–°–±–µ—Ä',
            '–∞–ª—å—Ñ–∞-–±–∞–Ω–∫': '–ê–ª—å—Ñ–∞-–ë–∞–Ω–∫',
            '–∞–ª—å—Ñ–∞–±–∞–Ω–∫': '–ê–ª—å—Ñ–∞-–ë–∞–Ω–∫',
            '—è–Ω–¥–µ–∫—Å': '–Ø–Ω–¥–µ–∫—Å',
            '–≤–∫ –≤–∏–¥–µ–æ': '–í–ö',
            '–≤–∫': '–í–ö',
            '–≤—Ç–±': '–í–¢–ë',
            '–∞–≤–∏—Ç–æ': '–ê–≤–∏—Ç–æ',
            '—Ç–∏–Ω—å–∫–æ—Ñ—Ñ': '–¢-–ë–∞–Ω–∫',
            '—Ç-–±–∞–Ω–∫': '–¢-–ë–∞–Ω–∫'
        }

    def connect_db(self):
        """–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö"""
        try:
            self.connection = psycopg2.connect(**self.db_config)
            self.connection.autocommit = True
            print("‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ë–î —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î: {e}")
            raise

    def load_companies_mapping(self, companies_file: str):
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤ –∏ –∫–æ–º–ø–∞–Ω–∏–π"""
        mapping = {}
        
        with open(companies_file, 'r', encoding='utf-8') as f:
            content = f.read()
            
        # –ü–∞—Ä—Å–∏–º –∑–∞–ø–∏—Å–∏ –≤–∏–¥–∞: ### 1. filename.md
        pattern = r'### (\d+)\. (.+?)\.md\n- \*\*–ö–æ–º–ø–∞–Ω–∏—è\*\*: (.+?)\n'
        matches = re.findall(pattern, content)
        
        for match in matches:
            number, filename, company = match
            # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä—É–µ–º
            company = company.strip()
            if company.lower() in self.company_standardization:
                company = self.company_standardization[company.lower()]
            elif company == "–ù–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–º–ø–∞–Ω–∏–∏" or company == "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö":
                company = "Unknown"
            
            mapping[filename + '.md'] = company
            
        print(f"üìã –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(mapping)} —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–π –∫–æ–º–ø–∞–Ω–∏–π")
        self.companies_mapping = mapping

    def parse_date_from_filename(self, filename: str) -> Optional[datetime]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞—Ç—ã –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è —Ñ–∞–π–ª–∞"""
        # –ü–∞—Ç—Ç–µ—Ä–Ω: 2024-07-11 15-00-11_transcript_llm_FULL_report.md
        date_pattern = r'(\d{4}-\d{2}-\d{2})\s+(\d{2})-(\d{2})-(\d{2})'
        match = re.search(date_pattern, filename)
        
        if match:
            date_part = match.group(1)
            hour = match.group(2)
            minute = match.group(3) 
            second = match.group(4)
            
            datetime_str = f"{date_part} {hour}:{minute}:{second}"
            return datetime.strptime(datetime_str, "%Y-%m-%d %H:%M:%S")
        
        return None

    def parse_questions_from_content(self, content: str) -> Tuple[int, List[str]]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤–æ–ø—Ä–æ—Å–æ–≤ –∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π –∏–∑ –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
        questions_count = 0
        technologies = set()
        
        # –ò—â–µ–º —Ç–∞–±–ª–∏—Ü—É –≤–æ–ø—Ä–æ—Å–æ–≤
        table_pattern = r'\|\s*‚Ññ.*?\|\s*–í–æ–ø—Ä–æ—Å.*?\|\s*–¢–µ–º—ã.*?\|(.+?)(?=\n##|\n\n|\Z)'
        table_match = re.search(table_pattern, content, re.DOTALL)
        
        if table_match:
            table_content = table_match.group(1)
            # –ü–∞—Ä—Å–∏–º —Å—Ç—Ä–æ–∫–∏ —Ç–∞–±–ª–∏—Ü—ã
            row_pattern = r'\|\s*(\d+)\s*\|.*?\|\s*([^|]+)\s*\|'
            rows = re.findall(row_pattern, table_content)
            
            questions_count = len(rows)
            
            for row in rows:
                tech = row[1].strip().lower()
                if tech in self.tech_standardization:
                    technologies.add(self.tech_standardization[tech])
                else:
                    technologies.add(tech.title())
        
        return questions_count, list(technologies)

    def parse_duration_from_content(self, content: str) -> Optional[int]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏–∑ –±–ª–æ–∫–∞ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π"""
        duration_pattern = r'–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å:\s*([\d.]+)\s*–º–∏–Ω'
        match = re.search(duration_pattern, content)
        
        if match:
            try:
                return int(float(match.group(1)))
            except ValueError:
                pass
                
        return None

    def calculate_difficulty(self, questions_count: int, duration_minutes: Optional[int]) -> int:
        """–†–∞—Å—á–µ—Ç —É—Ä–æ–≤–Ω—è —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –∏–Ω—Ç–µ—Ä–≤—å—é"""
        # –ë–∞–∑–æ–≤–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –≤–æ–ø—Ä–æ—Å–æ–≤
        if questions_count <= 5:
            difficulty = 1
        elif questions_count <= 10:
            difficulty = 2
        elif questions_count <= 15:
            difficulty = 3
        elif questions_count <= 20:
            difficulty = 4
        else:
            difficulty = 5
            
        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        if duration_minutes:
            if duration_minutes >= 90:
                difficulty = min(5, difficulty + 1)
            elif duration_minutes <= 30:
                difficulty = max(1, difficulty - 1)
                
        return difficulty

    def parse_report_file(self, file_path: str) -> Dict:
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –æ—Ç—á–µ—Ç–∞"""
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
            
        filename = os.path.basename(file_path)
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        interview_date = self.parse_date_from_filename(filename)
        questions_count, technologies = self.parse_questions_from_content(content)
        duration_minutes = self.parse_duration_from_content(content)
        company_name = self.companies_mapping.get(filename, "Unknown")
        difficulty_level = self.calculate_difficulty(questions_count, duration_minutes)
        
        # –°–æ–∑–¥–∞–µ–º —Ö–µ—à –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        content_hash = hashlib.md5(content.encode('utf-8')).hexdigest()
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–µ–≥–∏
        tags = ["frontend", "llm_report"]
        if "React" in technologies:
            tags.append("react")
        if "JavaScript" in technologies:
            tags.append("javascript")
            
        return {
            'id': str(uuid.uuid4()),
            'company_name': company_name,
            'interview_date': interview_date or datetime.now(),
            'position': "Frontend —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫",
            'full_content': content,
            'duration_minutes': duration_minutes,
            'questions_count': questions_count if questions_count > 0 else None,
            'source_type': 'llm_report',
            'content_hash': content_hash,
            'extracted_urls': [],
            'companies': [company_name] if company_name != "Unknown" else [],
            'difficulty_level': difficulty_level,
            'telegram_author': None,
            'tags': tags,
            'stage_number': 1,
            'technologies': technologies
        }

    def insert_interview_record(self, record: Dict):
        """–í—Å—Ç–∞–≤–∫–∞ –∑–∞–ø–∏—Å–∏ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö"""
        sql = """
        INSERT INTO "InterviewRecord" (
            id, company_name, interview_date, position, full_content,
            duration_minutes, questions_count, source_type, content_hash,
            extracted_urls, companies, difficulty_level, "createdAt", "updatedAt",
            telegram_author, tags, stage_number, technologies
        ) VALUES (
            %(id)s, %(company_name)s, %(interview_date)s, %(position)s, %(full_content)s,
            %(duration_minutes)s, %(questions_count)s, %(source_type)s, %(content_hash)s,
            %(extracted_urls)s, %(companies)s, %(difficulty_level)s, NOW(), NOW(),
            %(telegram_author)s, %(tags)s, %(stage_number)s, %(technologies)s
        ) ON CONFLICT (content_hash) DO NOTHING;
        """
        
        with self.connection.cursor() as cursor:
            cursor.execute(sql, record)

    def process_reports_directory(self, reports_dir: str):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö –æ—Ç—á–µ—Ç–æ–≤ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏"""
        reports_path = Path(reports_dir)
        
        if not reports_path.exists():
            print(f"‚ùå –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è {reports_dir} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            return
            
        md_files = list(reports_path.glob("*.md"))
        print(f"üìÅ –ù–∞–π–¥–µ–Ω–æ {len(md_files)} .md —Ñ–∞–π–ª–æ–≤")
        
        processed = 0
        errors = 0
        
        for file_path in md_files:
            try:
                print(f"üìÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º: {file_path.name}")
                record = self.parse_report_file(str(file_path))
                self.insert_interview_record(record)
                processed += 1
                
                if processed % 10 == 0:
                    print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {processed}/{len(md_files)}")
                    
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {file_path.name}: {e}")
                errors += 1
                
        print(f"\nüéØ –ò—Ç–æ–≥–æ:")
        print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {processed}")
        print(f"‚ùå –û—à–∏–±–æ–∫: {errors}")

    def close_connection(self):
        """–ó–∞–∫—Ä—ã—Ç–∏–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –ë–î"""
        if self.connection:
            self.connection.close()
            print("üîå –°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –ë–î –∑–∞–∫—Ä—ã—Ç–æ")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ë–î (–Ω–∞—Å—Ç—Ä–æ–π—Ç–µ –ø–æ–¥ —Å–≤–æ—é –±–∞–∑—É)
    DB_CONFIG = {
        'host': 'localhost',
        'port': 5432,
        'database': 'nareshka',  # –ó–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ –≤–∞—à–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –ë–î
        'user': 'postgres',      # –ó–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ –≤–∞—à –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å
        'password': 'password'   # –ó–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ –≤–∞—à –ø–∞—Ä–æ–ª—å
    }
    
    # –ü—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º
    REPORTS_DIR = r"C:\Users\refla\nareshka-mono\sobes-data\reports"
    COMPANIES_FILE = r"C:\Users\refla\nareshka-mono\sobes-data\companies_extracted.md"
    
    # –°–æ–∑–¥–∞–µ–º –∏–º–ø–æ—Ä—Ç–µ—Ä
    importer = InterviewReportImporter(DB_CONFIG)
    
    try:
        # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ –ë–î
        importer.connect_db()
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –∫–æ–º–ø–∞–Ω–∏–π
        importer.load_companies_mapping(COMPANIES_FILE)
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ—Ç—á–µ—Ç—ã
        importer.process_reports_directory(REPORTS_DIR)
        
    except Exception as e:
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
    finally:
        importer.close_connection()


if __name__ == "__main__":
    main()