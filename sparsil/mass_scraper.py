#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–ú–∞—Å—Å–æ–≤—ã–π —Å–±–æ—Ä—â–∏–∫ –≤—Å–µ—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ Telegram —á–∞—Ç–∞
–£–ø—Ä–∞–≤–ª—è–µ—Ç –ø—Ä–æ—Ü–µ—Å—Å–æ–º —Å–±–æ—Ä–∞ —á–µ—Ä–µ–∑ MCP API
"""

import json
import os
from typing import List, Dict, Any
import time

class MassTelegramScraper:
    def __init__(self, total_messages: int = 155797, batch_size: int = 20):
        self.total_messages = total_messages
        self.batch_size = batch_size
        self.chat_name = "Frontend ‚Äì TO THE JOB"
        self.results_dir = "telegram_scraping_results"
        self.progress_file = "scraping_progress.json"
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        os.makedirs(self.results_dir, exist_ok=True)
        
    def generate_offset_list(self) -> List[int]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö offset'–æ–≤ –¥–ª—è —Å–±–æ—Ä–∞"""
        offsets = []
        current_offset = self.total_messages
        
        while current_offset > 0:
            offsets.append(current_offset)
            current_offset -= self.batch_size
            
        return offsets
    
    def save_progress(self, current_offset: int, completed_offsets: List[int]):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è"""
        progress = {
            "current_offset": current_offset,
            "completed_offsets": completed_offsets,
            "total_completed": len(completed_offsets),
            "timestamp": time.time()
        }
        
        with open(self.progress_file, 'w', encoding='utf-8') as f:
            json.dump(progress, f, ensure_ascii=False, indent=2)
    
    def load_progress(self) -> Dict[str, Any]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è"""
        if os.path.exists(self.progress_file):
            with open(self.progress_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {"completed_offsets": [], "current_offset": self.total_messages}
    
    def create_batch_file(self, offset: int, batch_num: int) -> str:
        """–°–æ–∑–¥–∞–µ—Ç —Ñ–∞–π–ª –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ batch'–∞"""
        filename = f"{self.results_dir}/batch_{batch_num:04d}_offset_{offset}.json"
        return filename
    
    def get_next_offset_to_process(self) -> int:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–µ–¥—É—é—â–∏–π offset –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        progress = self.load_progress()
        completed = set(progress.get("completed_offsets", []))
        all_offsets = self.generate_offset_list()
        
        for offset in all_offsets:
            if offset not in completed:
                return offset
        
        return -1  # –í—Å–µ offset'—ã –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã
    
    def mark_offset_completed(self, offset: int):
        """–û—Ç–º–µ—á–∞–µ—Ç offset –∫–∞–∫ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã–π"""
        progress = self.load_progress()
        completed = progress.get("completed_offsets", [])
        
        if offset not in completed:
            completed.append(offset)
            
        self.save_progress(offset, completed)
    
    def get_completion_stats(self) -> Dict[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è"""
        progress = self.load_progress()
        all_offsets = self.generate_offset_list()
        completed = progress.get("completed_offsets", [])
        
        return {
            "total_batches": len(all_offsets),
            "completed_batches": len(completed),
            "remaining_batches": len(all_offsets) - len(completed),
            "completion_percentage": (len(completed) / len(all_offsets)) * 100,
            "next_offset": self.get_next_offset_to_process()
        }
    
    def combine_all_results(self) -> List[Dict[str, Any]]:
        """–û–±—ä–µ–¥–∏–Ω—è–µ—Ç –≤—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –æ–¥–∏–Ω —Å–ø–∏—Å–æ–∫"""
        all_messages = []
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        result_files = [f for f in os.listdir(self.results_dir) if f.startswith("batch_") and f.endswith(".json")]
        result_files.sort()  # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
        
        for filename in result_files:
            filepath = os.path.join(self.results_dir, filename)
            try:
                with open(filepath, 'r', encoding='utf-8') as f:
                    batch_data = json.load(f)
                    if isinstance(batch_data, list):
                        all_messages.extend(batch_data)
                    elif isinstance(batch_data, dict) and 'messages' in batch_data:
                        all_messages.extend(batch_data['messages'])
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ {filename}: {e}")
        
        return all_messages
    
    def save_final_result(self):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç"""
        all_messages = self.combine_all_results()
        
        final_result = {
            "chat_name": self.chat_name,
            "total_messages_collected": len(all_messages),
            "collection_timestamp": time.time(),
            "messages": all_messages
        }
        
        with open("all_telegram_messages_complete.json", 'w', encoding='utf-8') as f:
            json.dump(final_result, f, ensure_ascii=False, indent=2)
        
        print(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(all_messages)} —Å–æ–æ–±—â–µ–Ω–∏–π –≤ all_telegram_messages_complete.json")
        return len(all_messages)

def main():
    scraper = MassTelegramScraper()
    
    print("=== –ú–ê–°–°–û–í–´–ô –°–ë–û–†–©–ò–ö TELEGRAM –°–û–û–ë–©–ï–ù–ò–ô ===")
    print(f"–¶–µ–ª–µ–≤–æ–π —á–∞—Ç: {scraper.chat_name}")
    print(f"–í—Å–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è —Å–±–æ—Ä–∞: {scraper.total_messages}")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    stats = scraper.get_completion_stats()
    print(f"\n–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    print(f"–í—Å–µ–≥–æ batch'–µ–π: {stats['total_batches']}")
    print(f"–ó–∞–≤–µ—Ä—à–µ–Ω–æ: {stats['completed_batches']}")
    print(f"–û—Å—Ç–∞–ª–æ—Å—å: {stats['remaining_batches']}")
    print(f"–ü—Ä–æ–≥—Ä–µ—Å—Å: {stats['completion_percentage']:.1f}%")
    
    # –ü–æ–ª—É—á–∞–µ–º —Å–ª–µ–¥—É—é—â–∏–π offset –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
    next_offset = stats['next_offset']
    if next_offset == -1:
        print("\n‚úÖ –í–°–ï OFFSET'–´ –û–ë–†–ê–ë–û–¢–ê–ù–´!")
        print("–û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã...")
        total_collected = scraper.save_final_result()
        print(f"üéâ –°–æ–±—Ä–∞–Ω–æ {total_collected} —Å–æ–æ–±—â–µ–Ω–∏–π!")
    else:
        print(f"\nüìã –°–ª–µ–¥—É—é—â–∏–π offset –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {next_offset}")
        print(f"–ù–æ–º–µ—Ä batch'–∞: {stats['total_batches'] - stats['remaining_batches'] + 1}")
        
        # –°–æ–∑–¥–∞–µ–º –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é –¥–ª—è MCP –≤—ã–∑–æ–≤–∞
        batch_num = stats['total_batches'] - stats['remaining_batches'] + 1
        print(f"\nü§ñ –ò–ù–°–¢–†–£–ö–¶–ò–Ø –î–õ–Ø MCP –í–´–ó–û–í–ê:")
        print(f"mcp_telegram_tg_dialog(name='{scraper.chat_name}', offset={next_offset})")
        print(f"–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤: {scraper.create_batch_file(next_offset, batch_num)}")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –≤—Å–µ offset'—ã –¥–ª—è —Å–ø—Ä–∞–≤–∫–∏
    all_offsets = scraper.generate_offset_list()
    print(f"\n–í—Å–µ–≥–æ offset'–æ–≤: {len(all_offsets)}")
    print(f"–û—Ç {max(all_offsets)} –¥–æ {min(all_offsets)}")

if __name__ == "__main__":
    main() 