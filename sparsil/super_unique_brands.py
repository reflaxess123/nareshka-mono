#!/usr/bin/env python3
"""
–°—É–ø–µ—Ä-–∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –±—Ä–µ–Ω–¥–æ–≤ –∫–æ–º–ø–∞–Ω–∏–π
–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –æ—á–∏—â–∞–µ—Ç –∏ –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –≤—Å–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –æ–¥–Ω–æ–π –∫–æ–º–ø–∞–Ω–∏–∏
"""

import re
from typing import List, Dict, Set
from collections import defaultdict

def super_clean_brand(company: str) -> str:
    """–°—É–ø–µ—Ä-–∞–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –Ω–∞–∑–≤–∞–Ω–∏—è –¥–æ –±–∞–∑–æ–≤–æ–≥–æ –±—Ä–µ–Ω–¥–∞"""
    if not company:
        return ""
    
    # –£–±–∏—Ä–∞–µ–º –Ω—É–º–µ—Ä–∞—Ü–∏—é
    name = re.sub(r'^\s*\d+\.\s*', '', company)
    
    # –ê–ì–†–ï–°–°–ò–í–ù–û —É–±–∏—Ä–∞–µ–º –í–°–Å —á—Ç–æ –≤ —Å–∫–æ–±–∫–∞—Ö –∏ –ø–æ—Å–ª–µ –Ω–∏—Ö
    name = re.sub(r'\s*\([^)]*\).*$', '', name)
    name = re.sub(r'\s*\[[^\]]*\].*$', '', name)
    
    # –£–±–∏—Ä–∞–µ–º –≤—Å—ë –ø–æ—Å–ª–µ —Ç–∏—Ä–µ, –∑–∞–ø—è—Ç–æ–π, –¥–≤–æ–µ—Ç–æ—á–∏—è
    name = re.sub(r'\s*[-‚Äì‚Äî,:;].*$', '', name)
    
    # –£–±–∏—Ä–∞–µ–º –≤—Å—ë –ø–æ—Å–ª–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
    stop_words = [
        '–ø—Ä–æ–µ–∫—Ç', '–∞—É—Ç—Å—Ç–∞—Ñ—Ñ', '–∫–æ–º–∞–Ω–¥–∞', '–æ—Ç–¥–µ–ª', '—Å—Ç—Ä–∏–º', '–ø–ª–∞—Ç—Ñ–æ—Ä–º–∞',
        '–Ω–∞ –ø—Ä–æ–µ–∫—Ç', '–≤ –∫–æ–º–∞–Ω–¥—É', '—á–µ—Ä–µ–∑', '–æ—Ç', '–¥–ª—è', '–≤',
        '—Ç–µ—Ö', '—Ç–µ—Ö–Ω–∏—á–∫–∞', '—Å–æ–±–µ—Å', '—Å–∫—Ä–∏–Ω–∏–Ω–≥', '–∏–Ω—Ç–µ—Ä–≤—å—é', '—Ñ–∏–Ω–∞–ª',
        '—ç—Ç–∞–ø', '—Å–µ–∫—Ü–∏—è', '—á–∞—Å—Ç—å', '–≤—Å—Ç—Ä–µ—á–∞', '–∑–Ω–∞–∫–æ–º—Å—Ç–≤–æ', '—Ä–∞–∑–≥–æ–≤–æ—Ä',
        'hr', '—ç–π—á–∞—Ä–∫–∞', '–Ω–∞–ø–∏—Å–∞–ª–∞', '—Å–∞–º–∞', '–ª–∏–¥', '–ª–∏–¥–æ–º',
        '–≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π', '–≤–Ω—É—Ç—Ä–∏', '–≤–Ω–µ—à–Ω–∏–π', '–≤–Ω—É—Ç—Ä', '–∞—É—Ç—Å–æ—Ä—Å',
        '–¥–æ—á–∫–∞', '—Ä–∞–Ω–µ–µ', '–±—ã–ª–æ', '—É–∫–∞–∑–∞–Ω–æ', '–Ω—É–∂–µ–Ω', '–∫—Ç–æ', '—á—Ç–æ',
        '–≥–¥–µ', '–∫–æ–≥–¥–∞', '–ø–æ—á–µ–º—É', '–∫–∞–∫', '–∫–æ—Ç–æ—Ä–∞—è', '–∫–æ—Ç–æ—Ä—ã–π',
        '—à–∫–æ–ª–∞', '–æ–Ω–ª–∞–π–Ω', '–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è', '—É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç'
    ]
    
    for stop_word in stop_words:
        # –ò—â–µ–º —Å—Ç–æ–ø-—Å–ª–æ–≤–æ –∫–∞–∫ –æ—Ç–¥–µ–ª—å–Ω–æ–µ —Å–ª–æ–≤–æ
        pattern = r'\s+' + re.escape(stop_word) + r'.*$'
        name = re.sub(pattern, '', name, flags=re.IGNORECASE)
    
    # –£–±–∏—Ä–∞–µ–º –¥–∞—Ç—ã –∏ –Ω–æ–º–µ—Ä–∞
    name = re.sub(r'\s+\d{2}\.\d{2}.*$', '', name)
    name = re.sub(r'\s+\d{4}.*$', '', name)
    name = re.sub(r'\s+–æ—Ç\s+\d+.*$', '', name)
    name = re.sub(r'\s+\d+\s*$', '', name)
    
    # –£–±–∏—Ä–∞–µ–º markdown –∏ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
    name = re.sub(r'\*\*', '', name)
    name = name.replace('"', '').replace("'", '').replace('`', '')
    name = name.replace('#', '').replace('*', '')
    
    # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã –≤ –Ω–∞—á–∞–ª–µ –∏ –∫–æ–Ω—Ü–µ
    name = re.sub(r'^[:\-\*\s\"\']+', '', name)
    name = re.sub(r'[:\-\*\s\"\']+$', '', name)
    
    # –£–±–∏—Ä–∞–µ–º —Ç–æ—á–∫–∏ –≤ –∫–æ–Ω—Ü–µ (–∫—Ä–æ–º–µ –¥–æ–º–µ–Ω–æ–≤)
    if not re.search(r'\.(ru|com|org|net)$', name.lower()):
        name = re.sub(r'\.+$', '', name)
    
    # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
    name = ' '.join(name.split())
    
    return name.strip()

def normalize_brand_key(name: str) -> str:
    """–°–æ–∑–¥–∞–µ—Ç –∫–ª—é—á –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ –±—Ä–µ–Ω–¥–æ–≤"""
    if not name:
        return ""
    
    # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
    key = name.lower()
    
    # –£–±–∏—Ä–∞–µ–º –≤—Å–µ —Å–∏–º–≤–æ–ª—ã –∫—Ä–æ–º–µ –±—É–∫–≤ –∏ —Ü–∏—Ñ—Ä
    key = re.sub(r'[^–∞-—è—ëa-z0-9]', '', key)
    
    # –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∞–≤–∏–ª–∞ –¥–ª—è –º–µ–≥–∞–±—Ä–µ–Ω–¥–æ–≤
    mega_brands = {
        '—Å–±–µ—Ä': ['—Å–±–µ—Ä', '—Å–±–µ—Ä–±–∞–Ω–∫', '—Å–±–µ—Ä—Ç', '—Å–±–µ—Ä–∫–æ—Ä—É—Å', '—Å–±–µ—Ä—Ü–∏—Ç–∏'],
        '–∞–ª—å—Ñ–∞–±–∞–Ω–∫': ['–∞–ª—å—Ñ–∞', '–∞–ª—å—Ñ–∞–±–∞–Ω–∫', '–∞–ª—å—Ñ–∞–±–∞–Ω–∫'],
        '—Ç–∏–Ω—å–∫–æ—Ñ—Ñ': ['—Ç–∏–Ω—å–∫–æ—Ñ—Ñ', '—Ç–±–∞–Ω–∫', '—Ç–∏–Ω—å'],
        '—è–Ω–¥–µ–∫—Å': ['—è–Ω–¥–µ–∫—Å', 'yandex'],
        '–º—Ç—Å': ['–º—Ç—Å'],
        '–≤—Ç–±': ['–≤—Ç–±'],
        '–≥–∞–∑–ø—Ä–æ–º–±–∞–Ω–∫': ['–≥–∞–∑–ø—Ä–æ–º–±–∞–Ω–∫', '–≥–∞–∑–ø—Ä–æ–º', '–≥–ø–±'],
        '—Ä–æ—Å–±–∞–Ω–∫': ['—Ä–æ—Å–±–∞–Ω–∫'],
        '—Ä–∞–π—Ñ—Ñ–∞–π–∑–µ–Ω': ['—Ä–∞–π—Ñ—Ñ–∞–π–∑–µ–Ω', '—Ä–∞–π—Ñ–∞–π–∑–µ–Ω'],
        'ozon': ['ozon', '–æ–∑–æ–Ω'],
        'wildberries': ['wildberries', 'wb'],
        'avito': ['avito', '–∞–≤–∏—Ç–æ'],
        'epam': ['epam'],
        'ibs': ['ibs'],
        'x5': ['x5', 'x5tech', 'x5group', 'x5retail'],
        '—Å–µ–≤–µ—Ä—Å—Ç–∞–ª—å': ['—Å–µ–≤–µ—Ä—Å—Ç–∞–ª—å'],
        '—Å–æ–≤–∫–æ–º–±–∞–Ω–∫': ['—Å–æ–≤–∫–æ–º–±–∞–Ω–∫'],
        'rshb': ['—Ä—Å—Ö–±', '—Ä—Å—Ö–±–∏–Ω—Ç–µ—Ö'],
        'psb': ['–ø—Å–±', '–ø—Ä–æ–º—Å–≤—è–∑—å–±–∞–Ω–∫']
    }
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–Ω–æ—Å—Ç—å –∫ –º–µ–≥–∞–±—Ä–µ–Ω–¥—É
    for main_brand, variants in mega_brands.items():
        if key in variants:
            return main_brand
    
    return key

def is_valid_final_brand(name: str) -> bool:
    """–§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏ –±—Ä–µ–Ω–¥–∞"""
    if not name or len(name) < 2:
        return False
    
    name_lower = name.lower().strip()
    
    # –ò—Å–∫–ª—é—á–∞–µ–º –º—É—Å–æ—Ä
    garbage_exact = [
        'hr', '—ç–π—á–∞—Ä–∫–∞', '—Ç–µ—Ö', '—Å–æ–±–µ—Å', '—ç—Ç–∞–ø', '—Ñ–∏–Ω–∞–ª', '–ø—Ä–æ–µ–∫—Ç',
        '–∞—É—Ç—Å—Ç–∞—Ñ—Ñ', '–∞—É—Ç—Å–æ—Ä—Å', '–∫–æ–º–∞–Ω–¥–∞', '–æ—Ç–¥–µ–ª', '—Å—Ç—Ä–∏–º', '–ø–ª–∞—Ç—Ñ–æ—Ä–º–∞',
        '–≤—Å—Ç—Ä–µ—á–∞', '–∑–Ω–∞–∫–æ–º—Å—Ç–≤–æ', '—Ä–∞–∑–≥–æ–≤–æ—Ä', '–∏–Ω—Ç–µ—Ä–≤—å—é', '—Å–∫—Ä–∏–Ω–∏–Ω–≥',
        '–≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π', '–≤–Ω–µ—à–Ω–∏–π', '–¥–æ—á–∫–∞', '—á–∞—Å—Ç—å', '—Å–µ–∫—Ü–∏—è'
    ]
    
    if name_lower in garbage_exact:
        return False
    
    # –ò—Å–∫–ª—é—á–∞–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –º—É—Å–æ—Ä
    if re.search(r'^(then|function|import|export|const|console)', name_lower):
        return False
    
    # –ò—Å–∫–ª—é—á–∞–µ–º –æ–ø–∏—Å–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—Ä–∞–∑—ã
    if re.search(r'(—á—Ç–æ –≤—ã–≤–µ–¥–µ—Ç|–Ω–∞–ø–∏—Å–∞—Ç—å|—Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å|–Ω–∞–π—Ç–∏ –≤—Å–µ)', name_lower):
        return False
    
    # –î–æ–ª–∂–Ω—ã –±—ã—Ç—å –±—É–∫–≤—ã
    if not re.search(r'[–∞-—è—ëa-zA-Z]', name):
        return False
    
    # –ù–µ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–µ
    if len(name) > 40:
        return False
    
    return True

def choose_best_brand_variant(variants: List[str]) -> str:
    """–í—ã–±–∏—Ä–∞–µ—Ç –ª—É—á—à–∏–π –≤–∞—Ä–∏–∞–Ω—Ç –Ω–∞–∑–≤–∞–Ω–∏—è –±—Ä–µ–Ω–¥–∞"""
    if not variants:
        return ""
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º –≤–∞–ª–∏–¥–Ω—ã–µ
    valid = [v for v in variants if is_valid_final_brand(v)]
    if not valid:
        return ""
    
    # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
    unique_valid = list(set(valid))
    
    # –ö—Ä–∏—Ç–µ—Ä–∏–∏ –∫–∞—á–µ—Å—Ç–≤–∞ (—á–µ–º –º–µ–Ω—å—à–µ, —Ç–µ–º –ª—É—á—à–µ)
    def quality_score(name: str) -> tuple:
        length = len(name)
        has_dots = '.' in name and not name.endswith('.ru')
        has_numbers = bool(re.search(r'\d', name))
        has_symbols = bool(re.search(r'[^–∞-—è—ë–ê-–Ø–Åa-zA-Z0-9\s\.]', name))
        is_all_caps = name.isupper()
        has_extra_spaces = '  ' in name
        
        # –ü—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º –∑–Ω–∞–∫–æ–º—ã–µ –Ω–∞–ø–∏—Å–∞–Ω–∏—è
        is_known_good = name in [
            '–°–±–µ—Ä', '–Ø–Ω–¥–µ–∫—Å', '–ú–¢–°', '–í–¢–ë', '–ê–ª—å—Ñ–∞-–ë–∞–Ω–∫', '–¢–∏–Ω—å–∫–æ—Ñ—Ñ',
            '–ì–∞–∑–ø—Ä–æ–º–±–∞–Ω–∫', '–ê–≤–∏—Ç–æ', 'Ozon', 'Wildberries', 'EPAM', 'IBS'
        ]
        
        return (not is_known_good, has_symbols, has_dots, has_numbers, is_all_caps, has_extra_spaces, length)
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –∏ –±–µ—Ä–µ–º –ª—É—á—à–∏–π
    sorted_variants = sorted(unique_valid, key=quality_score)
    return sorted_variants[0]

def create_super_unique_brands():
    """–°–æ–∑–¥–∞–µ—Ç —Å—É–ø–µ—Ä-—É–Ω–∏–∫–∞–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫ –±—Ä–µ–Ω–¥–æ–≤"""
    
    print("üöÄ –°–û–ó–î–ê–ù–ò–ï –°–£–ü–ï–†-–£–ù–ò–ö–ê–õ–¨–ù–´–• –ë–†–ï–ù–î–û–í –ö–û–ú–ü–ê–ù–ò–ô")
    print("=" * 60)
    
    # –ß–∏—Ç–∞–µ–º —É–ª—å—Ç—Ä–∞-—á–∏—Å—Ç—ã–π —Å–ø–∏—Å–æ–∫
    try:
        with open('ultra_clean_companies.txt', 'r', encoding='utf-8') as f:
            content = f.read()
    except FileNotFoundError:
        print("‚ùå –§–∞–π–ª ultra_clean_companies.txt –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–º–ø–∞–Ω–∏–∏
    lines = content.split('\n')
    companies = []
    in_full_list = False
    
    for line in lines:
        line = line.strip()
        if '–ü–û–õ–ù–´–ô –°–ü–ò–°–û–ö' in line:
            in_full_list = True
            continue
        elif in_full_list and line and not line.startswith('-'):
            clean_line = re.sub(r'^\s*\d+\.\s*', '', line)
            if clean_line:
                companies.append(clean_line)
    
    print(f"üìã –ò—Å—Ö–æ–¥–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π: {len(companies)}")
    
    # –°—É–ø–µ—Ä-–∞–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞
    brand_groups = defaultdict(list)
    processed = 0
    
    for company in companies:
        clean_brand = super_clean_brand(company)
        if not clean_brand:
            continue
        
        brand_key = normalize_brand_key(clean_brand)
        if brand_key and is_valid_final_brand(clean_brand):
            brand_groups[brand_key].append(clean_brand)
            processed += 1
    
    print(f"üìã –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {processed}")
    print(f"üìã –ì—Ä—É–ø–ø –±—Ä–µ–Ω–¥–æ–≤: {len(brand_groups)}")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫—Ä—É–ø–Ω—ã–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è
    print(f"\nüî• –ö–†–£–ü–ù–´–ï –û–ë–™–ï–î–ò–ù–ï–ù–ò–Ø:")
    large_groups = [(k, v) for k, v in brand_groups.items() if len(v) > 2]
    large_groups.sort(key=lambda x: len(x[1]), reverse=True)
    
    for brand_key, variants in large_groups[:10]:
        unique_variants = list(set(variants))
        print(f"  {brand_key}: {unique_variants} ({len(variants)} —É–ø–æ–º–∏–Ω–∞–Ω–∏–π)")
    
    # –°–æ–∑–¥–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫
    final_brands = []
    total_merged = 0
    
    for brand_key, variants in brand_groups.items():
        if len(variants) > 1:
            total_merged += len(variants) - 1
        
        best_brand = choose_best_brand_variant(variants)
        if best_brand:
            final_brands.append(best_brand)
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º
    final_brands.sort(key=lambda x: x.lower())
    
    print(f"\n‚úÖ –†–ï–ó–£–õ–¨–¢–ê–¢:")
    print(f"   –°—É–ø–µ—Ä-—É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –±—Ä–µ–Ω–¥–æ–≤: {len(final_brands)}")
    print(f"   –û–±—ä–µ–¥–∏–Ω–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π: {total_merged}")
    
    # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —É–ø–æ–º–∏–Ω–∞–Ω–∏—è
    brand_popularity = defaultdict(int)
    for brand_key, variants in brand_groups.items():
        best_brand = choose_best_brand_variant(variants)
        if best_brand:
            brand_popularity[best_brand] = len(variants)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º
    output_file = 'super_unique_brands.txt'
    
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("–°–£–ü–ï–†-–£–ù–ò–ö–ê–õ–¨–ù–´–ï –ë–†–ï–ù–î–´ –ö–û–ú–ü–ê–ù–ò–ô\n")
        f.write("=" * 60 + "\n\n")
        f.write(f"–í—Å–µ–≥–æ —Å—É–ø–µ—Ä-—É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –±—Ä–µ–Ω–¥–æ–≤: {len(final_brands)}\n")
        f.write(f"–û–±—ä–µ–¥–∏–Ω–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {total_merged}\n\n")
        
        # –¢–û–ü –ø–æ –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç–∏
        popular = sorted(final_brands, key=lambda x: brand_popularity.get(x, 1), reverse=True)
        
        f.write("–¢–û–ü-30 –°–ê–ú–´–• –ü–û–ü–£–õ–Ø–†–ù–´–•:\n")
        f.write("-" * 40 + "\n")
        for i, brand in enumerate(popular[:30], 1):
            count = brand_popularity.get(brand, 1)
            f.write(f"{i:2d}. {brand} ({count} —É–ø–æ–º–∏–Ω–∞–Ω–∏–π)\n")
        
        f.write(f"\n\n–í–°–ï –°–£–ü–ï–†-–£–ù–ò–ö–ê–õ–¨–ù–´–ï –ë–†–ï–ù–î–´ ({len(final_brands)}):\n")
        f.write("-" * 40 + "\n")
        
        for i, brand in enumerate(final_brands, 1):
            f.write(f"{i:3d}. {brand}\n")
    
    print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤: {output_file}")
    
    # –¢–û–ü-20
    print(f"\nüèÜ –¢–û–ü-20 –°–ê–ú–´–• –ü–û–ü–£–õ–Ø–†–ù–´–•:")
    top20 = sorted(final_brands, key=lambda x: brand_popularity.get(x, 1), reverse=True)[:20]
    for i, brand in enumerate(top20, 1):
        count = brand_popularity.get(brand, 1)
        print(f"{i:2d}. {brand} ({count} —É–ø–æ–º–∏–Ω–∞–Ω–∏–π)")

if __name__ == "__main__":
    create_super_unique_brands() 