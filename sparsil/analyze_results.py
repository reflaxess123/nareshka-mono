#!/usr/bin/env python3
"""ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² Ğ¿Ğ°Ñ€ÑĞ¸Ğ½Ğ³Ğ° ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹ Ğ¸Ğ· Ñ‚ĞµĞ¼Ñ‹ 'Ğ—Ğ°Ğ¿Ğ¸ÑĞ¸ ÑĞ¾Ğ±ĞµÑĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¹'"""

import json
from datetime import datetime
from collections import Counter
import re

def analyze_telegram_data():
    """ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¸Ğ· telegram_topic_messages.json"""
    
    # Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ
    with open('telegram_topic_messages.json', encoding='utf-8') as f:
        data = json.load(f)
    
    messages = data['messages']
    metadata = data['metadata']
    
    print("=" * 60)
    print("ğŸ“Š ĞĞĞĞ›Ğ˜Ğ— Ğ Ğ•Ğ—Ğ£Ğ›Ğ¬Ğ¢ĞĞ¢ĞĞ’ ĞŸĞĞ Ğ¡Ğ˜ĞĞ“Ğ")
    print("=" * 60)
    
    # ĞÑĞ½Ğ¾Ğ²Ğ½Ğ°Ñ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ°
    print(f"ğŸ“ Ğ¢ĞµĞ¼Ğ°: {metadata['topic_name']}")
    print(f"ğŸ†” Topic ID: {metadata['topic_id']}")
    print(f"ğŸ“Š Ğ’ÑĞµĞ³Ğ¾ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹: {metadata['total_messages']}")
    print(f"ğŸ“… Ğ”Ğ°Ñ‚Ğ° Ğ¿Ğ°Ñ€ÑĞ¸Ğ½Ğ³Ğ°: {metadata['extraction_date']}")
    
    # Ğ’Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾Ğ¹ Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´
    if messages:
        first_date = messages[-1]['date']  # Ğ¡Ğ°Ğ¼Ğ¾Ğµ ÑÑ‚Ğ°Ñ€Ğ¾Ğµ
        last_date = messages[0]['date']    # Ğ¡Ğ°Ğ¼Ğ¾Ğµ Ğ½Ğ¾Ğ²Ğ¾Ğµ
        print(f"ğŸ“… ĞŸĞµÑ€Ğ¸Ğ¾Ğ´: Ñ {first_date} Ğ¿Ğ¾ {last_date}")
    
    print("\n" + "=" * 60)
    print("ğŸ¢ ĞĞĞĞ›Ğ˜Ğ— ĞšĞĞœĞŸĞĞĞ˜Ğ™")
    print("=" * 60)
    
    # ĞŸĞ¾Ğ¸ÑĞº ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹ Ñ ĞºĞ¾Ğ¼Ğ¿Ğ°Ğ½Ğ¸ÑĞ¼Ğ¸
    companies = []
    company_pattern = r'ĞšĞ¾Ğ¼Ğ¿Ğ°Ğ½Ğ¸Ñ[:\s]+([^\n]+)'
    
    for msg in messages:
        text = msg['text']
        match = re.search(company_pattern, text, re.IGNORECASE)
        if match:
            company = match.group(1).strip()
            companies.append(company)
    
    print(f"ğŸ’¼ Ğ¡Ğ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹ Ñ ĞºĞ¾Ğ¼Ğ¿Ğ°Ğ½Ğ¸ÑĞ¼Ğ¸: {len(companies)}")
    print(f"ğŸ“ˆ Ğ£Ğ½Ğ¸ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ñ… ĞºĞ¾Ğ¼Ğ¿Ğ°Ğ½Ğ¸Ğ¹: {len(set(companies))}")
    
    # Ğ¢Ğ¾Ğ¿ ĞºĞ¾Ğ¼Ğ¿Ğ°Ğ½Ğ¸Ğ¹
    if companies:
        company_counts = Counter(companies)
        print(f"\nğŸ† Ğ¢ĞĞŸ-10 ĞšĞĞœĞŸĞĞĞ˜Ğ™:")
        for i, (company, count) in enumerate(company_counts.most_common(10), 1):
            print(f"  {i:2d}. {company} ({count} Ñ€Ğ°Ğ·)")
    
    print("\n" + "=" * 60)
    print("ğŸ’° ĞĞĞĞ›Ğ˜Ğ— Ğ—ĞĞ ĞŸĞ›ĞĞ¢")
    print("=" * 60)
    
    # ĞŸĞ¾Ğ¸ÑĞº Ğ·Ğ°Ñ€Ğ¿Ğ»Ğ°Ñ‚Ğ½Ñ‹Ñ… Ğ²Ğ¸Ğ»Ğ¾Ğº
    salary_patterns = [
        r'[Ğ’Ğ²]Ğ¸Ğ»ĞºĞ°[:\s]+([^\n]+)',
        r'[Ğ—Ğ·]Ğ°Ñ€Ğ¿Ğ»Ğ°Ñ‚Ğ°[:\s]+([^\n]+)',
        r'(\d{2,3})[Ğº\s]*[-â€“]\s*(\d{2,3})[Ğº\s]*[Ñ‚Ñ‹Ñ]*',
        r'(\d{2,3})\s*[Ğº]*\s*[Ñ‚Ñ‹Ñ]*'
    ]
    
    salaries = []
    for msg in messages:
        text = msg['text']
        for pattern in salary_patterns:
            matches = re.findall(pattern, text, re.IGNORECASE)
            salaries.extend(matches)
    
    print(f"ğŸ’° Ğ£Ğ¿Ğ¾Ğ¼Ğ¸Ğ½Ğ°Ğ½Ğ¸Ğ¹ Ğ·Ğ°Ñ€Ğ¿Ğ»Ğ°Ñ‚: {len(salaries)}")
    
    # ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ·Ğ°Ñ€Ğ¿Ğ»Ğ°Ñ‚Ğ½Ñ‹Ñ… Ğ´Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½Ğ¾Ğ²
    salary_numbers = []
    for salary in salaries:
        if isinstance(salary, tuple):
            # Ğ”Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½ Ğ·Ğ°Ñ€Ğ¿Ğ»Ğ°Ñ‚
            try:
                min_sal = int(re.search(r'\d+', str(salary[0])).group())
                max_sal = int(re.search(r'\d+', str(salary[1])).group())
                salary_numbers.extend([min_sal, max_sal])
            except:
                pass
        else:
            # ĞĞ´Ğ¸Ğ½Ğ¾Ñ‡Ğ½Ğ¾Ğµ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ
            nums = re.findall(r'\d{2,3}', str(salary))
            salary_numbers.extend([int(n) for n in nums])
    
    if salary_numbers:
        print(f"ğŸ’µ ĞœĞ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ğ·Ğ°Ñ€Ğ¿Ğ»Ğ°Ñ‚Ğ°: {min(salary_numbers)}k")
        print(f"ğŸ’µ ĞœĞ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ğ·Ğ°Ñ€Ğ¿Ğ»Ğ°Ñ‚Ğ°: {max(salary_numbers)}k")
        print(f"ğŸ’µ Ğ¡Ñ€ĞµĞ´Ğ½ÑÑ Ğ·Ğ°Ñ€Ğ¿Ğ»Ğ°Ñ‚Ğ°: {sum(salary_numbers)/len(salary_numbers):.1f}k")
    
    print("\n" + "=" * 60)
    print("ğŸ‘¥ ĞĞĞĞ›Ğ˜Ğ— ĞĞ’Ğ¢ĞĞ ĞĞ’")
    print("=" * 60)
    
    # ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹
    authors = [msg['from_username'] for msg in messages if msg.get('from_username')]
    author_counts = Counter(authors)
    
    print(f"ğŸ‘¤ Ğ’ÑĞµĞ³Ğ¾ Ğ°Ğ²Ñ‚Ğ¾Ñ€Ğ¾Ğ²: {len(set(authors))}")
    print(f"ğŸ“ Ğ¡Ñ€ĞµĞ´Ğ½ĞµĞµ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹ Ğ½Ğ° Ğ°Ğ²Ñ‚Ğ¾Ñ€Ğ°: {len(messages)/len(set(authors)):.1f}")
    
    print(f"\nğŸ† Ğ¢ĞĞŸ-10 ĞĞšĞ¢Ğ˜Ğ’ĞĞ«Ğ¥ ĞĞ’Ğ¢ĞĞ ĞĞ’:")
    for i, (author, count) in enumerate(author_counts.most_common(10), 1):
        print(f"  {i:2d}. @{author} ({count} ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹)")
    
    print("\n" + "=" * 60)
    print("ğŸ” ĞŸĞ Ğ˜ĞœĞ•Ğ Ğ« Ğ¡ĞĞĞ‘Ğ©Ğ•ĞĞ˜Ğ™")
    print("=" * 60)
    
    # ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¾ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ¾Ğ²
    for i, msg in enumerate(messages[:3]):
        print(f"\nğŸ“ Ğ¡Ğ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ #{i+1} (ID: {msg['id']}):")
        print(f"ğŸ“… Ğ”Ğ°Ñ‚Ğ°: {msg['date']}")
        print(f"ğŸ‘¤ ĞĞ²Ñ‚Ğ¾Ñ€: @{msg.get('from_username', 'unknown')}")
        print(f"ğŸ’¬ Ğ¢ĞµĞºÑÑ‚: {msg['text'][:200]}{'...' if len(msg['text']) > 200 else ''}")
        print("-" * 40)
    
    print("\nğŸ‰ ĞĞĞĞ›Ğ˜Ğ— Ğ—ĞĞ’Ğ•Ğ Ğ¨Ğ•Ğ!")
    print(f"ğŸ“„ ĞŸĞ¾Ğ»Ğ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹ Ğ²: telegram_topic_messages.json")
    print(f"ğŸ“Š CSV Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°: telegram_topic_messages.csv")

if __name__ == "__main__":
    analyze_telegram_data() 