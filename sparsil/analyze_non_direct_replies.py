#!/usr/bin/env python3
"""
–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å–æ–æ–±—â–µ–Ω–∏–π –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ —è–≤–ª—è—é—Ç—Å—è –ø—Ä—è–º—ã–º–∏ –æ—Ç–≤–µ—Ç–∞–º–∏ –Ω–∞ —Ç–µ–º—É 489
"""

import json
from collections import Counter

def analyze_non_direct_replies():
    """–ê–Ω–∞–ª–∏–∑ –Ω–µ–ø—Ä—è–º—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤"""
    
    print("üîç –ê–ù–ê–õ–ò–ó –ù–ï–ü–†–Ø–ú–´–• –û–¢–í–ï–¢–û–í")
    print("=" * 60)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    with open('telegram_topic_messages.json', 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    messages = data['messages']
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è
    direct_replies = [m for m in messages if m.get('reply_to_msg_id') == 489]
    non_direct_replies = [m for m in messages if m.get('reply_to_msg_id') and m.get('reply_to_msg_id') != 489]
    
    print(f"‚úîÔ∏è –ü—Ä—è–º—ã–µ –æ—Ç–≤–µ—Ç—ã –Ω–∞ —Ç–µ–º—É 489: {len(direct_replies)}")
    print(f"‚ö†Ô∏è –û—Ç–≤–µ—Ç—ã –Ω–∞ –¥—Ä—É–≥–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è: {len(non_direct_replies)}")
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –Ω–∞ —á—Ç–æ –æ—Ç–≤–µ—á–∞—é—Ç
    reply_targets = Counter()
    for msg in non_direct_replies:
        reply_targets[msg['reply_to_msg_id']] += 1
    
    print(f"\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –û–¢–í–ï–¢–û–í:")
    for target_id, count in reply_targets.most_common():
        # –ò—â–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        original = next((m for m in messages if m['id'] == target_id), None)
        if original:
            print(f"\nüìå –û—Ç–≤–µ—Ç—ã –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ {target_id} ({count} —Ä–∞–∑):")
            print(f"   –ò—Å—Ö–æ–¥–Ω–æ–µ: {original['text'][:150]}...")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã –æ—Ç–≤–µ—Ç–æ–≤
            replies_to_this = [m for m in non_direct_replies if m['reply_to_msg_id'] == target_id]
            for i, reply in enumerate(replies_to_this[:2], 1):
                print(f"   –û—Ç–≤–µ—Ç {i}: {reply['text'][:100]}...")
        else:
            print(f"\nüìå –û—Ç–≤–µ—Ç—ã –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ {target_id} ({count} —Ä–∞–∑) - –∏—Å—Ö–æ–¥–Ω–æ–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
    print(f"\nüìÖ –í–†–ï–ú–ï–ù–ù–û–ô –ê–ù–ê–õ–ò–ó:")
    
    # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –¥–∞—Ç—ã
    from datetime import datetime
    
    direct_dates = []
    non_direct_dates = []
    
    for msg in direct_replies:
        if msg['date']:
            direct_dates.append(datetime.fromisoformat(msg['date'].replace('Z', '+00:00')))
    
    for msg in non_direct_replies:
        if msg['date']:
            non_direct_dates.append(datetime.fromisoformat(msg['date'].replace('Z', '+00:00')))
    
    if direct_dates and non_direct_dates:
        direct_dates.sort()
        non_direct_dates.sort()
        
        print(f"–ü—Ä—è–º—ã–µ –æ—Ç–≤–µ—Ç—ã: {direct_dates[0].strftime('%Y-%m-%d')} - {direct_dates[-1].strftime('%Y-%m-%d')}")
        print(f"–ù–µ–ø—Ä—è–º—ã–µ –æ—Ç–≤–µ—Ç—ã: {non_direct_dates[0].strftime('%Y-%m-%d')} - {non_direct_dates[-1].strftime('%Y-%m-%d')}")
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ
    print(f"\nüîç –ê–ù–ê–õ–ò–ó –°–û–î–ï–†–ñ–ê–ù–ò–Ø –ù–ï–ü–†–Ø–ú–´–• –û–¢–í–ï–¢–û–í:")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
    non_direct_text = ' '.join([msg['text'].lower() for msg in non_direct_replies if msg['text']])
    
    # –°–ª–æ–≤–∞ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω—ã–µ –¥–ª—è –æ–±—Å—É–∂–¥–µ–Ω–∏–π vs –∑–∞–ø–∏—Å–µ–π —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–π
    discussion_words = ['—Å–ø–∞—Å–∏–±–æ', '—Å–æ–≥–ª–∞—Å–µ–Ω', '–¥–∞', '–Ω–µ—Ç', '—Ç–æ–∂–µ', '—É –º–µ–Ω—è', '–∞ —è']
    interview_words = ['–∫–æ–º–ø–∞–Ω–∏—è', '—Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ', '–≤–∞–∫–∞–Ω—Å–∏—è', '–∑–∞—Ä–ø–ª–∞—Ç–∞', '–≤–æ–ø—Ä–æ—Å', '–∑–∞–¥–∞—á–∞']
    
    print(f"–°–ª–æ–≤–∞ –æ–±—Å—É–∂–¥–µ–Ω–∏–π:")
    for word in discussion_words:
        count = non_direct_text.count(word)
        if count > 0:
            print(f"  '{word}': {count}")
    
    print(f"–°–ª–æ–≤–∞ –∑–∞–ø–∏—Å–µ–π —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–π:")
    for word in interview_words:
        count = non_direct_text.count(word)
        if count > 0:
            print(f"  '{word}': {count}")
    
    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    print(f"\nüìã –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
    
    discussion_score = sum(non_direct_text.count(w) for w in discussion_words)
    interview_score = sum(non_direct_text.count(w) for w in interview_words)
    
    print(f"–°—á–µ—Ç '–æ–±—Å—É–∂–¥–µ–Ω–∏—è': {discussion_score}")
    print(f"–°—á–µ—Ç '–∑–∞–ø–∏—Å–∏ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–π': {interview_score}")
    
    if interview_score > discussion_score:
        print(f"‚úîÔ∏è –ù–µ–ø—Ä—è–º—ã–µ –æ—Ç–≤–µ—Ç—ã —Ç–æ–∂–µ —Å–æ–¥–µ—Ä–∂–∞—Ç –∑–∞–ø–∏—Å–∏ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–π")
        print(f"‚úîÔ∏è –ú–æ–∂–Ω–æ –≤–∫–ª—é—á–∏—Ç—å –≤ —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç")
    else:
        print(f"‚ùå –ù–µ–ø—Ä—è–º—ã–µ –æ—Ç–≤–µ—Ç—ã —Å–æ–¥–µ—Ä–∂–∞—Ç –±–æ–ª—å—à–µ –æ–±—Å—É–∂–¥–µ–Ω–∏–π")
        print(f"‚ö†Ô∏è –õ—É—á—à–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ –ø—Ä—è–º—ã–µ –æ—Ç–≤–µ—Ç—ã")
    
    return direct_replies, non_direct_replies

if __name__ == "__main__":
    analyze_non_direct_replies() 