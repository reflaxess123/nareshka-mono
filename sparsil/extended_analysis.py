#!/usr/bin/env python3
"""
–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –≤—Å–µ—Ö —Å–æ–±—Ä–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ —á–∞—Ç–∞ Frontend ‚Äì TO THE JOB
"""

import json
import re
from datetime import datetime
from typing import List, Dict, Optional

# –í—Å–µ —Å–æ–±—Ä–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (—Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ)
EXTENDED_COLLECTED_MESSAGES = [
    # –ü–µ—Ä–≤–∞—è –ø–æ—Ä—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö (—É–∂–µ –±—ã–ª–∞)
    {"who": "budkakdomaputnic", "when": "2025-07-08 21:19:16", "text": "https://telemost.yandex.ru/j/13592002799790"},
    {"who": "theibd56", "when": "2025-07-08 18:00:35", "text": "–ö–æ–º–ø–∞–Ω–∏—è: –°–ø–æ—Ä—Ç—Å (Sports.ru) \n–°—Å—ã–ª–∫–∞ –Ω–∞ –≤–∞–∫—É: —Å–∞–º –Ω–∞–ø–∏—Å–∞–ª hr\n–í–∏–ª–∫–∞: —Ö–∑ (–Ω–∞–∑–≤–∞–ª 250-300, —Å–∫–∞–∑–∞–ª–∏ –≤ –≤–∏–ª–∫–µ –≤—Å–µ –Ω–æ—Ä–º)\n\n1. –≤–æ–ø—Ä–æ—Å—ã –ø–æ –æ–ø—ã—Ç—É\n2. –≥—Ä–µ–π–¥ —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤ –≤ –∫–æ–º–∞–Ω–¥–µ?\n3. –∫–∞–∫ –∫–æ–¥ —Ä–µ–≤—å—é –ø—Ä–æ—Ö–æ–¥–∏—Ç?\n4. –µ—Å–ª–∏ —É–π–¥–µ—à—å —Å –ø—Ä–æ–µ–∫—Ç–∞ –∫–∞–∫ –¥—É–º–∞–µ—à—å —á—Ç–æ —Å—Ç–∞–Ω–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å —Ö—É–∂–µ?\n5. –ø—Ä–µ–¥—Å—Ç–∞–≤—å —á—Ç–æ –µ—Å—Ç—å —Ç—Ä–∏ –æ—Ç–∫—Ä—ã—Ç—ã–µ –≤–∫–ª–∞–¥–∫–∏ (–ø–æ—Ç–æ–º –≤–∫–ª–∞–¥–∫–∞ –Ω–∞ –ø–∫ –∏ —Ç—Ñ) –ø–µ—Ä–µ—á–∏—Å–ª–∏ —Å–ø–æ—Å–æ–±—ã –æ–±—â–µ–Ω–∏—è –º–µ–∂–¥—É –Ω–∏–º–∏?\n6. –∫–∞–∫ —Ä–∞–∑–¥–µ–ª—è–ª–∏ –∑–æ–Ω—É –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏ –Ω–∞ –ø—Ä–æ–µ–∫—Ç–∞—Ö?\n7. –∫–∞–∫ –ø–æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ—Å—Ç–∏ –Ω–∞ –ø—Ä–æ–µ–∫—Ç–∞—Ö?\n8. —Å —á–µ–º –±—ã –Ω–µ —Ö–æ—Ç–µ–ª —Ä–∞–±–æ—Ç–∞—Ç—å?\n9. —á—Ç–æ —Ö–æ—Ç–µ–ª –±—ã –ø–æ–¥–Ω–∞—Ç–æ—Å–∫–∞—Ç—å/–∏–∑—É—á–∏—Ç—å?\n10. –º—ã –ø–∏—à–µ–º –Ω–∞ Vue —Ç–µ–±–µ –Ω–æ—Ä–º, –∫–∞–∫ –∫ —Ç–∞–∫–æ–º—É –æ—Ç–Ω–æ—Å–∏—à—å—Å—è?\n\n–ó–∞–¥–∞—á–∏ –∫–∞–∫ –∑–¥–µ—Å—å - https://t.me/c/2071074234/489/138602"},
    {"who": "danimaxi54", "when": "2025-07-08 17:48:29", "text": "–∑–∞–¥–∞—á–∞ –∏–∑ —Å–µ–≤–µ—Ä—Å—Ç–∞–ª–∏"},
    {"who": "Mankeym", "when": "2025-07-08 17:47:41", "text": "//–î–∞–Ω –º–∞—Å—Å–∏–≤ —Å—Å—ã–ª–æ–∫: ['url1', 'url2', ...] –∏ –ª–∏–º–∏—Ç –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ (limit) –ù–µ–æ–±—Ö–æ–¥–∏–º–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —Ñ—É–Ω–∫—Ü–∏—é, –∫–æ—Ç–æ—Ä—ã—è –æ–ø—Ä–æ—Å–∏—Ç —É—Ä–ª—ã –≤ —Ç–æ–º //–ø–æ—Ä—è–¥–∫—É, –≤ –∫–æ—Ç–æ—Ä–æ–º –æ–Ω–∏ –∏–¥—É—Ç –≤ –º–∞—Å—Å–∏–≤–µ, –∏ –≤—ã–∑–æ–≤–µ—Ç callback —Å –º–∞—Å—Å–∏–≤–æ–º –æ—Ç–≤–µ—Ç–æ–≤ ['url1_answer', 'url2_anser', ...] —Ç–∞–∫, —á—Ç–æ–±—ã –≤ –ª—é–±–æ–π –º–æ–º–µ–Ω—Ç //–≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω—è–ª–æ—Å—å –Ω–µ –±–æ–ª–µ–µ limit –∑–∞–ø—Ä–æ—Å–æ–≤ (–∫–∞–∫ —Ç–æ–ª—å–∫–æ –ª—é–±–æ–π –∏–∑ –Ω–∏—Ö –∑–∞–≤–µ—Ä—à–∏–ª—Å—è, —Å—Ä–∞–∑—É –∂–µ –æ—Ç–ø—Ä–∞–≤–∏—Ç—Å—è —Å–ª–µ–¥—É—é—â–∏–π) –¢.–µ. –Ω—É–∂–Ω–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —à–∏–Ω—É —Å —à–∏—Ä–∏–Ω–æ–π —Ä–∞–≤–Ω–æ–π limit.\n// –¥–æ–ø. –¥–æ–±–∞–≤–∏—Ç—å –º–µ–º–æ–∏–∑–∞—Ü–∏—é\nfunction parallelLimit(urls, limit, callback) {\n    // –ï—Å–ª–∏ limit –±–æ–ª—å—à–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ URL, —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –µ–≥–æ —Ä–∞–≤–Ω—ã–º –¥–ª–∏–Ω–µ –º–∞—Å—Å–∏–≤–∞ URL\n    limit = Math.min(limit, urls.length);\n    \n    let results = new Array(urls.length);\n    let active = 0;\n    let index = 0;\n    const cache = new Map(); // –î–æ–±–∞–≤–ª—è–µ–º –∫—ç—à –¥–ª—è –º–µ–º–æ–∏–∑–∞—Ü–∏–∏\n    \n    function processNext() {\n        if (index >= urls.length && active === 0) {\n            callback(results);\n            return;\n        }\n        \n        while (index < urls.length && active < limit) {\n            const currIndex = index;\n            const url = urls[currIndex];\n            index++;\n            active++;\n            \n            // –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ URL –≤ –∫—ç—à–µ\n            if (cache.has(url)) {\n                // –ï—Å–ª–∏ URL —É–∂–µ –≤ –∫—ç—à–µ, –±–µ—Ä—ë–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ—Ç—Ç—É–¥–∞\n                results[currIndex] = cache.get(url);\n                active--;\n                // –ò—Å–ø–æ–ª—å–∑—É–µ–º setTimeout –¥–ª—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ—Å—Ç–∏ –∏ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∏—è —Å—Ç–µ–∫–∞\n                setTimeout(processNext, 0);\n            } else {\n                // –ï—Å–ª–∏ URL –Ω–µ—Ç –≤ –∫—ç—à–µ, –≤—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å\n                fetch(url)\n                    .then(response => {\n                        // –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–≤–µ—Ç –≤ –∫—ç—à\n                        cache.set(url, response);\n                        results[currIndex] = response;\n                        active--;\n                        processNext();\n                    });\n            }\n        }\n    }\n    \n    // –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—É—Å—Ç–æ–≥–æ –º–∞—Å—Å–∏–≤–∞ URL\n    if (urls.length === 0) {\n        callback(results);\n        return;\n    }\n    \n    processNext();\n}"},
    
    # –ù–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ —Å–±–æ—Ä–∞
    {"who": "sentryDispatch", "when": "2025-07-08 17:30:43", "text": "–ü–æ–º–æ–≥–∏—Ç–µ –≤ —è–Ω–¥–µ–∫—Å–µ, –Ω–∞ –∞–ª–≥–æ—Å–∞—Ö, —Å–µ–π—á–∞—Å –æ—Ç–æ–π–¥—É –∏ –Ω–µ —Å–º–æ–≥—É –ø–æ–º–æ—á—å"},
    {"who": "sentryDispatch", "when": "2025-07-08 17:28:51", "text": "const getNodes = (tree, type) => {\n  let result = [];\n  const stack = [tree];  // –°—Ç–µ–∫ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å –∫–æ—Ä–Ω—è –¥–µ—Ä–µ–≤–∞\n\n  while (stack.length > 0) {\n    const node = stack.pop();  // –ë–µ—Ä–µ–º —É–∑–µ–ª –∏–∑ —Å—Ç–µ–∫–∞\n\n    // –ï—Å–ª–∏ —Ç–∏–ø —É–∑–ª–∞ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å –∑–∞–¥–∞–Ω–Ω—ã–º, –¥–æ–±–∞–≤–ª—è–µ–º –µ–≥–æ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç\n    if (node.type === type) {\n      result.push(node);  // –î–æ–±–∞–≤–ª—è–µ–º –≤–µ—Å—å —É–∑–µ–ª\n    }\n\n    // –ï—Å–ª–∏ —É —É–∑–ª–∞ –µ—Å—Ç—å –¥–æ—á–µ—Ä–Ω–∏–µ —ç–ª–µ–º–µ–Ω—Ç—ã, –¥–æ–±–∞–≤–ª—è–µ–º –∏—Ö –≤ —Å—Ç–µ–∫\n    if (node.children) {\n      stack.push(...node.children);  // –î–æ–±–∞–≤–ª—è–µ–º –≤—Å–µ –¥–æ—á–µ—Ä–Ω–∏–µ —ç–ª–µ–º–µ–Ω—Ç—ã\n    }\n  }\n\n  return result;\n};"},
    {"who": "VP262626", "when": "2025-07-08 17:27:59", "text": "–ü–æ–ª—É—á–µ–Ω–Ω—ã–π –æ—Ç —Å–µ—Ä–≤–µ—Ä–∞ HTML-–¥–æ–∫—É–º–µ–Ω—Ç –±—Ä–∞—É–∑–µ—Ä –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –≤ DOM –¥–µ—Ä–µ–≤–æ.\n\n5. –ó–∞–≥—Ä—É–∂–∞—é—Ç—Å—è –∏ –ø–∞—Ä—Å—è—Ç—Å—è css-—Å—Ç–∏–ª–∏, —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç—Å—è CSSOM (CSS Object Model). –ó–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è JS, –µ—Å–ª–∏ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ html –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è script, —Ç–æ –æ–Ω –±–ª–æ–∫–∏—Ä—É–µ—Ç –¥–∞–ª—å–Ω–µ–π—à–∏–π —Ä–µ–Ω–¥–µ—Ä, –ø–æ–∫–∞ —Å–∫—Ä–∏–ø—Ç –Ω–µ –æ—Ç—Ä–∞–±–æ—Ç–∞–µ—Ç\n\n6. –ù–∞ –æ—Å–Ω–æ–≤–µ DOM –∏ CSSOM —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç—Å—è –¥–µ—Ä–µ–≤–æ —Ä–µ–Ω–¥–µ—Ä–∏–Ω–≥–∞, –∏–ª–∏ render tree ‚Äî –Ω–∞–±–æ—Ä –æ–±—ä–µ–∫—Ç–æ–≤ —Ä–µ–Ω–¥–µ—Ä–∏–Ω–≥–∞. Render tree –¥—É–±–ª–∏—Ä—É–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É DOM, –Ω–æ —Å—é–¥–∞ –Ω–µ –ø–æ–ø–∞–¥–∞—é—Ç –Ω–µ–≤–∏–¥–∏–º—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä ‚Äî <head>, –∏–ª–∏ —ç–ª–µ–º–µ–Ω—Ç—ã —Å–æ —Å—Ç–∏–ª–µ–º display:none;). –¢–∞–∫–∂–µ, –∫–∞–∂–¥–∞—è —Å—Ç—Ä–æ–∫–∞ —Ç–µ–∫—Å—Ç–∞ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ –≤ –¥–µ—Ä–µ–≤–µ —Ä–µ–Ω–¥–µ—Ä–∏–Ω–≥–∞ –∫–∞–∫ –æ—Ç–¥–µ–ª—å–Ω—ã–π renderer. –ö–∞–∂–¥—ã–π –æ–±—ä–µ–∫—Ç —Ä–µ–Ω–¥–µ—Ä–∏–Ω–≥–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –µ–º—É –æ–±—ä–µ–∫—Ç DOM –∏ —Ä–∞—Å—Å—á–∏—Ç–∞–Ω–Ω—ã–π –¥–ª—è —ç—Ç–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞ —Å—Ç–∏–ª—å. –ü—Ä–æ—â–µ –≥–æ–≤–æ—Ä—è, render tree –æ–ø–∏—Å—ã–≤–∞–µ—Ç –≤–∏–∑—É–∞–ª—å–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ DOM.\n\n 7. –î–ª—è –∫–∞–∂–¥–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ render tree —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç—Å—è –ø–æ–ª–æ–∂–µ–Ω–∏–µ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ –∏ –µ–≥–æ —Ä–∞–∑–º–µ—Ä—ã, –≤—ã—Å–æ—Ç–∞, —à–∏—Ä–∏–Ω–∞, –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç —Å—Ç–∞–¥–∏—è layout.\n\n8. –ü—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –æ—Ç—Ä–∏—Å–æ–≤–∫–∞ –∫–∞–∂–¥–æ–≥–æ –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ —É–∑–ª–∞ –≤ –±—Ä–∞—É–∑–µ—Ä–µ ‚Äî painting."},
    {"who": "VP262626", "when": "2025-07-08 17:27:52", "text": "1. –ë—Ä–∞—É–∑–µ—Ä –ø–∞—Ä—Å–∏—Ç URL –∏ –ø—Ä–æ–≤–µ—Ä—è–µ—Ç, –µ—Å—Ç—å –ª–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –º–µ–∂–¥—É IP-–∞–¥—Ä–µ—Å–æ–º –∏ –¥–æ–º–µ–Ω–æ–º –≤ —Å–≤–æ–µ–º –∫—ç—à–µ.\n\n- –ï—Å–ª–∏ –Ω–µ –Ω–∞—Ö–æ–¥–∏—Ç –≤ –∫—ç—à–µ –±—Ä–∞—É–∑–µ—Ä–∞, —Ç–æ –æ–Ω –æ–±—Ä–∞—â–∞–µ—Ç—Å—è –∫ –æ–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º–µ. –û–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ —Å–∏—Å—Ç–µ–º–Ω–æ–º —Ñ–∞–π–ª–µ hosts, –∫–æ—Ç–æ—Ä—ã–π —Å–æ–¥–µ—Ä–∂–∏—Ç –∑–∞–ø–∏—Å–∏ –æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ –¥–æ–º–µ–Ω–æ–≤ –∏ IP-–∞–¥—Ä–µ—Å–æ–≤.\n\n- –ï—Å–ª–∏ –∏ –≤ —Å–∏—Å—Ç–µ–º–Ω–æ–º —Ñ–∞–π–ª–µ hosts —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –±—Ä–∞—É–∑–µ—Ä –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç DNS –∑–∞–ø—Ä–æ—Å. –≠—Ç–æ—Ç –∑–∞–ø—Ä–æ—Å —Å–æ–¥–µ—Ä–∂–∏—Ç –∏–º—è —Å–µ—Ä–≤–µ—Ä–∞, –∫–æ—Ç–æ—Ä–æ–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–æ –≤ IP-–∞–¥—Ä–µ—Å. –ó–∞–ø—Ä–æ—Å –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è –∫ DNS-—Å–µ—Ä–≤–µ—Ä—É, –∫–æ—Ç–æ—Ä—ã–π –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç IP-–∞–¥—Ä–µ—Å —Å–∞–π—Ç–∞ –∏ –ø–æ–ª—É—á–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ DNS –∑–∞–ø—Ä–æ—Å —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –≤ –∫—ç—à–µ.\n\n2. –ö–æ–≥–¥–∞ IP –∞–¥—Ä–µ—Å —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è –∏–∑–≤–µ—Å—Ç–µ–Ω, –±—Ä–∞—É–∑–µ—Ä –Ω–∞—á–∏–Ω–∞–µ—Ç —É—Å—Ç–∞–Ω–æ–≤–∫—É —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è –∫ —Å–µ—Ä–≤–µ—Ä—É —Å –ø–æ–º–æ—â—å—é TCP —Ä—É–∫–æ–ø–æ–∂–∞—Ç–∏—è. –í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –æ–±–º–µ–Ω —Ñ–ª–∞–≥–∞–º–∏ –≤ 3 —ç—Ç–∞–ø–∞: SYN, SYN-ACK –∏ ACK –¥–ª—è —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è.\n\n3. –ö–æ–≥–¥–∞ –º—ã —É—Å—Ç–∞–Ω–æ–≤–∏–ª–∏ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ, –±—Ä–∞—É–∑–µ—Ä –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç GET –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è HTML —Ñ–∞–π–ª–∞."},
    {"who": "sentryDispatch", "when": "2025-07-08 17:24:15", "text": "–í—Ä–µ–º–µ–Ω–Ω–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å:\n–í—Ä–µ–º—è: O(N), –≥–¥–µ N ‚Äî –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–∑–ª–æ–≤ –≤ –¥–µ—Ä–µ–≤–µ.\n\n–ú—ã –ø—Ä–æ—Ö–æ–¥–∏–º –ø–æ –≤—Å–µ–º —É–∑–ª–∞–º —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω —Ä–∞–∑, —á—Ç–æ –¥–∞—ë—Ç –ª–∏–Ω–µ–π–Ω—É—é —Å–ª–æ–∂–Ω–æ—Å—Ç—å –ø–æ –≤—Ä–µ–º–µ–Ω–∏.\n\n–ü—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å:\n–ü–∞–º—è—Ç—å: O(N), —Ç–∞–∫ –∫–∞–∫ –≤ —Ö—É–¥—à–µ–º —Å–ª—É—á–∞–µ, –µ—Å–ª–∏ –≤—Å–µ —É–∑–ª—ã –Ω–∞—Ö–æ–¥—è—Ç—Å—è –Ω–∞ –æ–¥–Ω–æ–º —É—Ä–æ–≤–Ω–µ (–∏–ª–∏ –≤ —Å–ª—É—á–∞–µ —Å–∞–º–æ–π –≥–ª—É–±–æ–∫–æ–π –≤–ª–æ–∂–µ–Ω–Ω–æ—Å—Ç–∏), —Å—Ç–µ–∫ –º–æ–∂–µ—Ç —Ö—Ä–∞–Ω–∏—Ç—å –≤—Å–µ —É–∑–ª—ã –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ."},
    {"who": "sentryDispatch", "when": "2025-07-08 17:16:28", "text": "–î–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ä–µ—à–µ–Ω–∏—è –∑–∞–¥–∞—á–∏ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ –∞–Ω–∞–≥—Ä–∞–º–º, –º—ã –º–æ–∂–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–æ–¥—Å—á—ë—Ç —á–∞—Å—Ç–æ—Ç—ã —Å–∏–º–≤–æ–ª–æ–≤, –≤–º–µ—Å—Ç–æ —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏ —Å—Ç—Ä–æ–∫–∏. –≠—Ç–æ –ø–æ–¥—Ö–æ–¥ –ø–æ–∑–≤–æ–ª–∏—Ç —É–º–µ–Ω—å—à–∏—Ç—å —Å–ª–æ–∂–Ω–æ—Å—Ç—å –∞–ª–≥–æ—Ä–∏—Ç–º–∞.\n\n–ü–æ–¥—Å—á—ë—Ç —á–∞—Å—Ç–æ—Ç—ã —Å–∏–º–≤–æ–ª–æ–≤:\n–í–º–µ—Å—Ç–æ —Ç–æ–≥–æ —á—Ç–æ–±—ã —Å–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å —Å—Ç—Ä–æ–∫—É, –º–æ–∂–Ω–æ –ø–æ—Å—á–∏—Ç–∞—Ç—å —á–∞—Å—Ç–æ—Ç—É –ø–æ—è–≤–ª–µ–Ω–∏—è –∫–∞–∂–¥–æ–≥–æ —Å–∏–º–≤–æ–ª–∞.\n\n–ü–æ–ª—É—á–µ–Ω–Ω–∞—è —á–∞—Å—Ç–æ—Ç–∞ –±—É–¥–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω–æ–π –¥–ª—è –≤—Å–µ—Ö –∞–Ω–∞–≥—Ä–∞–º–º –æ–¥–Ω–æ–≥–æ –Ω–∞–±–æ—Ä–∞ —Å–∏–º–≤–æ–ª–æ–≤, –ø–æ—ç—Ç–æ–º—É —Ç–∞–∫–∏–µ —Å–ª–æ–≤–∞ –º–æ–∂–Ω–æ –±—É–¥–µ—Ç –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞—Ç—å.\n\n–ö–∞–∫ —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç:\n–ö–∞–∂–¥–æ–µ —Å–ª–æ–≤–æ –ø—Ä–µ–≤—Ä–∞—â–∞–µ–º –≤ —Å—Ç—Ä–æ–∫—É, –∫–æ—Ç–æ—Ä–∞—è –±—É–¥–µ—Ç –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—Ç—å —Å–æ–±–æ–π —á–∞—Å—Ç–æ—Ç—ã —Å–∏–º–≤–æ–ª–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –¥–ª—è \"—Ç—Ä–æ—Å\" –∏ \"—Å–æ—Ä—Ç\" —ç—Ç–æ –±—É–¥–µ—Ç –æ–¥–∏–Ω–∞–∫–æ–≤–∞—è —Å—Ç—Ä–æ–∫–∞).\n\n–°—Ç—Ä–æ–∫–∞, –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—â–∞—è —á–∞—Å—Ç–æ—Ç—ã, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–∞–∫ –∫–ª—é—á –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ –∞–Ω–∞–≥—Ä–∞–º–º."},
    {"who": "sentryDispatch", "when": "2025-07-08 17:07:22", "text": "function groupAnagrams(list) {\n  const map = new Map();\n\n  for (const word of list) {\n    // –ö–ª—é—á ‚Äî –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –±—É–∫–≤—ã —Å–ª–æ–≤–∞\n    const key = word.split('').sort().join('');\n    \n    // –î–æ–±–∞–≤–ª—è–µ–º —Å–ª–æ–≤–æ –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â—É—é –≥—Ä—É–ø–ø—É\n    if (!map.has(key)) {\n      map.set(key, []);\n    }\n    map.get(key).push(word);\n  }\n\n  // –í–æ–∑–≤—Ä–∞—â–∞–µ–º –º–∞—Å—Å–∏–≤ —Å–≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–ª–æ–≤\n  return Array.from(map.values());\n}"},
    {"who": "danimaxi54", "when": "2025-07-08 17:00:40", "text": "return pages.map(({id, titile, site_id}) => ({\n        id,\n        title,\n        site: sitesMap.get(site_id) // –î–æ—Å—Ç–∞–µ–º —Å–∞–π—Ç –∏–∑ Map –∑–∞ O(1)\n    }));"},
    {"who": "danimaxi54", "when": "2025-07-08 16:59:10", "text": "// –°–æ–∑–¥–∞–µ–º Map –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞ –∫ —Å–∞–π—Ç–∞–º –ø–æ id\n    const sitesMap = new Map();\n    sites.forEach(site => sitesMap.set(site.id, site));"},
    {"who": "danimaxi54", "when": "2025-07-08 16:58:08", "text": "—Å–∫–∞–∂–∏ —è —Ö–æ—á—É –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ —Å–¥–µ–ª–∞—Ç—å –∞–ª–≥–æ—Å"},
]

class ExtendedInterviewAnalyzer:
    def __init__(self):
        self.interview_keywords = [
            "—Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ", "–∏–Ω—Ç–µ—Ä–≤—å—é", "interview", "–∑–∞–ø–∏—Å—å", "–≤–∏–¥–µ–æ", 
            "–∞—É–¥–∏–æ", "—Ä–∞–∑–±–æ—Ä", "—Ä–µ–≤—å—é", "code review", "—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ",
            "–∑–∞–¥–∞—á–∞", "–∞–ª–≥–æ—Ä–∏—Ç–º", "live coding", "—Å–∫—Ä–∏–Ω", "–¥–µ–º–æ", "—Ç–µ—Å—Ç",
            "–ª–∞–π–≤–∫–æ–¥", "–≤–∞–∫–∞–Ω—Å–∏—è", "–∫–æ–º–ø–∞–Ω–∏—è", "hr", "–≤–∏–ª–∫–∞", "–∑–∞—Ä–ø–ª–∞—Ç–∞",
            "–≥—Ä–µ–π–¥", "–æ–ø—ã—Ç", "–ø—Ä–æ–µ–∫—Ç", "–∑–∞–¥–∞—á–∏", "—Å–ª–æ–∂–Ω–æ—Å—Ç—å", "—Å–µ–≤–µ—Ä—Å—Ç–∞–ª—å",
            "—è–Ω–¥–µ–∫—Å", "–∞–ª–≥–æ—Å—ã", "–ø–æ–º–æ–≥–∏—Ç–µ"
        ]
        
        self.company_keywords = [
            "sports.ru", "—Å–ø–æ—Ä—Ç—Å", "—Å–µ–≤–µ—Ä—Å—Ç–∞–ª—å", "—è–Ω–¥–µ–∫—Å", "google", 
            "microsoft", "meta", "amazon", "netflix", "uber", "airbnb"
        ]
        
        self.algorithm_keywords = [
            "o(n)", "o(1)", "—Å–ª–æ–∂–Ω–æ—Å—Ç—å", "–∞–ª–≥–æ—Ä–∏—Ç–º", "–¥–µ—Ä–µ–≤–æ", "—Å—Ç–µ–∫",
            "—Ö—ç—à", "map", "–º–∞—Å—Å–∏–≤", "–∏—Ç–µ—Ä–∞—Ü–∏—è", "—Ä–µ–∫—É—Ä—Å–∏—è", "dfs", "bfs"
        ]
        
        self.technical_keywords = [
            "react", "vue", "angular", "javascript", "typescript", "node.js",
            "python", "java", "c++", "golang", "rust", "algorithm", "–∞–ª–≥–æ—Ä–∏—Ç–º",
            "async", "await", "promise", "callback", "fetch", "api", "rest",
            "useeffect", "usestate", "component", "hook", "dom", "virtual dom",
            "html", "css", "cssom", "render tree", "layout", "painting"
        ]
    
    def extract_algorithms_and_tasks(self, messages: List[Dict]) -> List[Dict]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∞–ª–≥–æ—Ä–∏—Ç–º–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞—á–∏ –∏ –∏—Ö —Ä–µ—à–µ–Ω–∏—è"""
        algorithm_tasks = []
        
        for msg in messages:
            text = msg.get("text", "")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ –∞–ª–≥–æ—Ä–∏—Ç–º–∏—á–µ—Å–∫—É—é –∑–∞–¥–∞—á—É
            is_algorithm = any(keyword in text.lower() for keyword in self.algorithm_keywords)
            has_code = bool(re.search(r'function|const|let|var|class|=>', text))
            has_complexity = bool(re.search(r'o\([^)]+\)', text.lower()))
            
            if is_algorithm or has_code or has_complexity:
                task_info = {
                    "author": msg.get("who", "Unknown"),
                    "timestamp": msg.get("when", ""),
                    "text": text,
                    "complexity_mentioned": has_complexity,
                    "has_code": has_code,
                    "task_type": self.classify_task_type(text),
                    "technologies": [tech for tech in self.technical_keywords if tech in text.lower()]
                }
                algorithm_tasks.append(task_info)
        
        return algorithm_tasks
    
    def classify_task_type(self, text: str) -> str:
        """–ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç —Ç–∏–ø –∑–∞–¥–∞—á–∏"""
        text_lower = text.lower()
        
        if "–¥–µ—Ä–µ–≤–æ" in text_lower or "tree" in text_lower:
            return "Tree Traversal"
        elif "–∞–Ω–∞–≥—Ä–∞–º–º" in text_lower or "anagram" in text_lower:
            return "String Processing"
        elif "–ø–∞—Ä–∞–ª–ª–µ–ª" in text_lower or "parallel" in text_lower:
            return "Concurrency"
        elif "fetch" in text_lower or "–∑–∞–ø—Ä–æ—Å" in text_lower:
            return "Network/API"
        elif "map" in text_lower or "—Ö—ç—à" in text_lower:
            return "Data Structures"
        elif "–±—Ä–∞—É–∑–µ—Ä" in text_lower or "dom" in text_lower:
            return "Browser/Frontend"
        elif "singleton" in text_lower or "–ø–∞—Ç—Ç–µ—Ä–Ω" in text_lower:
            return "Design Patterns"
        else:
            return "General Algorithm"
    
    def extract_interview_questions(self, messages: List[Dict]) -> List[Dict]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –≤–æ–ø—Ä–æ—Å—ã —Å —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–π"""
        interview_questions = []
        
        for msg in messages:
            text = msg.get("text", "")
            
            # –ü–æ–∏—Å–∫ –Ω—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤
            questions = re.findall(r'^\d+\.\s(.+)$', text, re.MULTILINE)
            
            if questions:
                interview_info = {
                    "author": msg.get("who", "Unknown"),
                    "timestamp": msg.get("when", ""),
                    "company": self.extract_company(text),
                    "salary": self.extract_salary(text),
                    "questions": questions,
                    "total_questions": len(questions)
                }
                interview_questions.append(interview_info)
        
        return interview_questions
    
    def extract_company(self, text: str) -> Optional[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–æ–º–ø–∞–Ω–∏–∏"""
        company_match = re.search(r'–∫–æ–º–ø–∞–Ω–∏—è:\s*([^\\n]+)', text.lower())
        if company_match:
            return company_match.group(1).strip()
        
        for company in self.company_keywords:
            if company in text.lower():
                return company
        
        return None
    
    def extract_salary(self, text: str) -> Optional[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∑–∞—Ä–ø–ª–∞—Ç–Ω—É—é –≤–∏–ª–∫—É"""
        salary_match = re.search(r'(\d{2,3})-(\d{2,3})', text)
        if salary_match:
            return f"{salary_match.group(1)}-{salary_match.group(2)}k"
        return None
    
    def analyze_extended_data(self) -> Dict:
        """–ü—Ä–æ–≤–æ–¥–∏—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö"""
        print("üîç –ü—Ä–æ–≤–æ–¥–∏–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å–æ–±—Ä–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∞–ª–≥–æ—Ä–∏—Ç–º–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞—á–∏
        algorithm_tasks = self.extract_algorithms_and_tasks(EXTENDED_COLLECTED_MESSAGES)
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤–æ–ø—Ä–æ—Å—ã —Å —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–π
        interview_questions = self.extract_interview_questions(EXTENDED_COLLECTED_MESSAGES)
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –∞–≤—Ç–æ—Ä–∞–º
        by_author = {}
        for msg in EXTENDED_COLLECTED_MESSAGES:
            author = msg.get("who", "Unknown")
            if author not in by_author:
                by_author[author] = []
            by_author[author].append(msg)
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç–µ–º—ã
        tech_discussions = self.analyze_technical_discussions(EXTENDED_COLLECTED_MESSAGES)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        stats = {
            "total_messages": len(EXTENDED_COLLECTED_MESSAGES),
            "algorithm_tasks": len(algorithm_tasks),
            "interview_questions": len(interview_questions),
            "unique_authors": len(by_author),
            "tech_discussions": len(tech_discussions),
            "companies_mentioned": len(set(q["company"] for q in interview_questions if q["company"])),
            "analysis_date": datetime.now().isoformat()
        }
        
        return {
            "statistics": stats,
            "algorithm_tasks": algorithm_tasks,
            "interview_questions": interview_questions,
            "tech_discussions": tech_discussions,
            "messages_by_author": by_author,
            "all_messages": EXTENDED_COLLECTED_MESSAGES
        }
    
    def analyze_technical_discussions(self, messages: List[Dict]) -> List[Dict]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –æ–±—Å—É–∂–¥–µ–Ω–∏—è"""
        tech_discussions = []
        
        for msg in messages:
            text = msg.get("text", "")
            tech_terms = [term for term in self.technical_keywords if term in text.lower()]
            
            if len(tech_terms) >= 3 or len(text) > 200:  # –î–ª–∏–Ω–Ω—ã–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è
                discussion = {
                    "author": msg.get("who", "Unknown"),
                    "timestamp": msg.get("when", ""),
                    "text": text,
                    "tech_terms": tech_terms,
                    "topic": self.classify_topic(text),
                    "is_explanation": "–æ–±—ä—è—Å–Ω" in text.lower() or "—Ä–∞–±–æ—Ç–∞–µ—Ç" in text.lower()
                }
                tech_discussions.append(discussion)
        
        return tech_discussions
    
    def classify_topic(self, text: str) -> str:
        """–ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç —Ç–µ–º—É –æ–±—Å—É–∂–¥–µ–Ω–∏—è"""
        text_lower = text.lower()
        
        if "–±—Ä–∞—É–∑–µ—Ä" in text_lower or "dom" in text_lower or "render" in text_lower:
            return "Browser Internals"
        elif "react" in text_lower or "vue" in text_lower or "component" in text_lower:
            return "Frontend Frameworks"
        elif "async" in text_lower or "promise" in text_lower or "fetch" in text_lower:
            return "Asynchronous Programming"
        elif "–∞–ª–≥–æ—Ä–∏—Ç–º" in text_lower or "—Å–ª–æ–∂–Ω–æ—Å—Ç—å" in text_lower:
            return "Algorithms & Complexity"
        elif "–ø–∞—Ç—Ç–µ—Ä–Ω" in text_lower or "singleton" in text_lower:
            return "Design Patterns"
        else:
            return "General Programming"
    
    def save_extended_results(self, data: Dict, filename: str = "extended_interview_analysis.json"):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã"""
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        print(f"üìÅ –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {filename}")
    
    def print_extended_summary(self, data: Dict):
        """–í—ã–≤–æ–¥–∏—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—É—é —Å–≤–æ–¥–∫—É"""
        stats = data["statistics"]
        
        print("\n" + "="*90)
        print("üöÄ –†–ê–°–®–ò–†–ï–ù–ù–´–ô –ê–ù–ê–õ–ò–ó –ó–ê–ü–ò–°–ï–ô –°–û–ë–ï–°–ï–î–û–í–ê–ù–ò–ô - Frontend ‚Äì TO THE JOB")
        print("="*90)
        
        print(f"\nüìä –û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
        print(f"  –í—Å–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏–π: {stats['total_messages']}")
        print(f"  –ê–ª–≥–æ—Ä–∏—Ç–º–∏—á–µ—Å–∫–∏—Ö –∑–∞–¥–∞—á: {stats['algorithm_tasks']}")
        print(f"  –û—Ç—á–µ—Ç–æ–≤ –æ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏—è—Ö: {stats['interview_questions']}")
        print(f"  –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –æ–±—Å—É–∂–¥–µ–Ω–∏–π: {stats['tech_discussions']}")
        print(f"  –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∞–≤—Ç–æ—Ä–æ–≤: {stats['unique_authors']}")
        print(f"  –£–ø–æ–º—è–Ω—É—Ç—ã—Ö –∫–æ–º–ø–∞–Ω–∏–π: {stats['companies_mentioned']}")
        
        print(f"\nüßÆ –ê–õ–ì–û–†–ò–¢–ú–ò–ß–ï–°–ö–ò–ï –ó–ê–î–ê–ß–ò:")
        for task in data["algorithm_tasks"][:5]:
            print(f"\n  üìù {task['author']} ({task['timestamp']}):")
            print(f"     –¢–∏–ø: {task['task_type']}")
            if task['complexity_mentioned']:
                print(f"     ‚ö° –£–ø–æ–º—è–Ω—É—Ç–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç—å –∞–ª–≥–æ—Ä–∏—Ç–º–∞")
            if task['has_code']:
                print(f"     üíª –°–æ–¥–µ—Ä–∂–∏—Ç –∫–æ–¥")
            if task['technologies']:
                print(f"     üõ†Ô∏è –¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏: {', '.join(task['technologies'][:3])}")
            
            text_preview = task['text'][:150] + "..." if len(task['text']) > 150 else task['text']
            print(f"     üìÑ {text_preview}")
        
        print(f"\nüè¢ –û–¢–ß–ï–¢–´ –û –°–û–ë–ï–°–ï–î–û–í–ê–ù–ò–Ø–•:")
        for report in data["interview_questions"]:
            print(f"\n  üë§ {report['author']} ({report['timestamp']}):")
            if report['company']:
                print(f"     üè¢ –ö–æ–º–ø–∞–Ω–∏—è: {report['company']}")
            if report['salary']:
                print(f"     üí∞ –ó–∞—Ä–ø–ª–∞—Ç–∞: {report['salary']}")
            print(f"     ‚ùì –í–æ–ø—Ä–æ—Å–æ–≤: {report['total_questions']}")
            for i, question in enumerate(report['questions'][:3], 1):
                print(f"       {i}. {question}")
            if report['total_questions'] > 3:
                print(f"       ... –∏ –µ—â–µ {report['total_questions'] - 3} –≤–æ–ø—Ä–æ—Å–æ–≤")
        
        print(f"\nüî¨ –¢–ï–•–ù–ò–ß–ï–°–ö–ò–ï –û–ë–°–£–ñ–î–ï–ù–ò–Ø:")
        topics = {}
        for discussion in data["tech_discussions"]:
            topic = discussion['topic']
            topics[topic] = topics.get(topic, 0) + 1
        
        for topic, count in sorted(topics.items(), key=lambda x: x[1], reverse=True):
            print(f"  üìö {topic}: {count} –æ–±—Å—É–∂–¥–µ–Ω–∏–π")
        
        print(f"\nüë• –°–ê–ú–´–ï –ê–ö–¢–ò–í–ù–´–ï –£–ß–ê–°–¢–ù–ò–ö–ò:")
        author_counts = {}
        for msg in data["all_messages"]:
            author = msg.get("who", "Unknown")
            author_counts[author] = author_counts.get(author, 0) + 1
        
        for author, count in sorted(author_counts.items(), key=lambda x: x[1], reverse=True)[:8]:
            print(f"  {author}: {count} —Å–æ–æ–±—â–µ–Ω–∏–π")
        
        print(f"\nüìÖ –î–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞: {stats['analysis_date']}")
        print("="*90)

def main():
    analyzer = ExtendedInterviewAnalyzer()
    
    print("üîç –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –∑–∞–ø–∏—Å–µ–π —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–π")
    print("="*60)
    
    # –ü—Ä–æ–≤–æ–¥–∏–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑
    data = analyzer.analyze_extended_data()
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    analyzer.save_extended_results(data)
    
    # –í—ã–≤–æ–¥–∏–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—É—é —Å–≤–æ–¥–∫—É
    analyzer.print_extended_summary(data)
    
    print(f"\n‚úÖ –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω!")
    print(f"üìä –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {len(EXTENDED_COLLECTED_MESSAGES)} —Å–æ–æ–±—â–µ–Ω–∏–π")
    print("üìÅ –§–∞–π–ª: extended_interview_analysis.json")

if __name__ == "__main__":
    main() 