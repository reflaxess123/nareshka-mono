#!/usr/bin/env python3
"""
–£–ª—É—á—à–µ–Ω–Ω–∞—è —Ñ–∏–Ω–∞–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ —Å–ø–∏—Å–∫–∞ –∫–æ–º–ø–∞–Ω–∏–π
–ë–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –æ—Ç –º—É—Å–æ—Ä–∞ –∏ –¥—É–±–ª–µ–π
"""

import re
from typing import List, Dict, Set
from collections import defaultdict

def aggressive_normalize(name: str) -> str:
    """–ê–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–º–ø–∞–Ω–∏–∏"""
    if not name:
        return ""
    
    # –£–±–∏—Ä–∞–µ–º –Ω—É–º–µ—Ä–∞—Ü–∏—é –≤ –Ω–∞—á–∞–ª–µ
    name = re.sub(r'^\s*\d+\.\s*', '', name)
    
    # –£–±–∏—Ä–∞–µ–º –≤—Å–µ –ø—Ä–µ—Ñ–∏–∫—Å—ã –∏ –æ–±—Ä—ã–≤–∫–∏
    prefixes = [
        r'^[:\-\*\"\'\s]*',  # –ù–∞—á–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
        r'^–ö–æ–º–ø–∞–Ω–∏—è[:\s]*',
        r'^–ù–∞–∑–≤–∞–Ω–∏–µ[:\s]*', 
        r'^–∫–æ–º–ø–∞–Ω–∏—è[:\s]*',
        r'^–Ω–∞–∑–≤–∞–Ω–∏–µ[:\s]*',
        r'^–ö–æ–º–ø–∞–Ω–∏[:\s]*',
        r'^[a-zA-Z–∞-—è—ëA-–Ø–Å]*\s*:\s*',  # –õ—é–±—ã–µ —Å–ª–æ–≤–∞ —Å –¥–≤–æ–µ—Ç–æ—á–∏–µ–º
    ]
    for prefix in prefixes:
        name = re.sub(prefix, '', name, flags=re.IGNORECASE)
    
    # –£–±–∏—Ä–∞–µ–º –≤—Å–µ —á—Ç–æ –≤ —Å–∫–æ–±–∫–∞—Ö/–∫–∞–≤—ã—á–∫–∞—Ö –≤ –∫–æ–Ω—Ü–µ
    name = re.sub(r'\s*\([^)]*\)\s*$', '', name)
    name = re.sub(r'\s*\[[^\]]*\]\s*$', '', name)
    name = re.sub(r'\s*"[^"]*"\s*$', '', name)
    name = re.sub(r'\s*\*\*[^*]*\*\*\s*$', '', name)
    
    # –£–±–∏—Ä–∞–µ–º –æ–ø–∏—Å–∞–Ω–∏—è –ø–æ—Å–ª–µ —Ç–∏—Ä–µ/–∑–∞–ø—è—Ç–æ–π
    name = re.sub(r'\s*[-‚Äì‚Äî,]\s*.*$', '', name)
    
    # –£–±–∏—Ä–∞–µ–º HTML/Markdown —Å–∏–º–≤–æ–ª—ã
    name = re.sub(r'\*\*', '', name)
    name = name.replace('"', '').replace("'", '').replace('`', '')
    name = re.sub(r'[#\*]', '', name)
    
    # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ —Å–∏–º–≤–æ–ª—ã –≤ –Ω–∞—á–∞–ª–µ/–∫–æ–Ω—Ü–µ
    name = re.sub(r'^[:\-\s\*\"\']+', '', name)
    name = re.sub(r'[:\-\s\*\"\']+$', '', name)
    
    # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
    name = ' '.join(name.split())
    
    return name.strip()

def is_valid_company(name: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å—Ç—Ä–æ–∫–∞ –≤–∞–ª–∏–¥–Ω—ã–º –Ω–∞–∑–≤–∞–Ω–∏–µ–º –∫–æ–º–ø–∞–Ω–∏–∏"""
    if not name or len(name.strip()) < 2:
        return False
    
    name_clean = name.lower().strip()
    
    # –ú—É—Å–æ—Ä–Ω—ã–µ —Å–ª–æ–≤–∞/—Ñ—Ä–∞–∑—ã
    garbage_words = [
        'function', 'import', 'export', 'const', 'console', 'return',
        'typeof', 'async', 'await', 'promise', 'react', 'component',
        '—Ç–µ—Ö —Å–æ–±–µ—Å', '—Ç–µ—Ö—Å–æ–±–µ—Å', '–ª–∞–π–≤–∫–æ–¥–∏–Ω–≥', '—Å–∫—Ä–∏–Ω–∏–Ω–≥', '—ç—Ç–∞–ø',
        '—Ñ–∏–Ω–∞–ª', '–∏–Ω—Ç–µ—Ä–≤—å—é', '–∑–∞–¥–∞—á–∞', '–≤–æ–ø—Ä–æ—Å', '—Ä–µ—à–µ–Ω–∏–µ', '–∞–ª–≥–æ—Ä–∏—Ç–º',
        '—á—Ç–æ –≤—ã–≤–µ–¥–µ—Ç', '–Ω–∞–ø–∏—Å–∞—Ç—å', '—Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å', '–Ω–∞–π—Ç–∏', '—Å–æ–∑–¥–∞—Ç—å'
    ]
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –º—É—Å–æ—Ä–Ω—ã–µ —Å–ª–æ–≤–∞
    for word in garbage_words:
        if word in name_clean:
            return False
    
    # –°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –∏–ª–∏ —Å–æ—Å—Ç–æ—è—â–∏–µ —Ç–æ–ª—å–∫–æ –∏–∑ —Å–∏–º–≤–æ–ª–æ–≤
    if len(name) < 2 or not re.search(r'[–∞-—è—ëa-zA-Z]', name):
        return False
    
    # –î–∞—Ç—ã –∏ —á–∏—Å–ª–∞
    if re.match(r'^\d+[\.\-/]\d+', name) or re.match(r'^\d+$', name):
        return False
    
    # –¢–æ–ª—å–∫–æ —Å–∏–º–≤–æ–ª—ã –±–µ–∑ –±—É–∫–≤
    if re.match(r'^[^–∞-—è—ëa-zA-Z]*$', name):
        return False
    
    # –°–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–µ –æ–ø–∏—Å–∞–Ω–∏—è
    if len(name) > 60:
        return False
    
    # –û–±—Ä—ã–≤–∫–∏ —Å—Ç—Ä–æ–∫ (–Ω–∞—á–∏–Ω–∞—é—Ç—Å—è —Å —Å–∏–º–≤–æ–ª–æ–≤)
    if re.match(r'^[:\-\*\"\'\s]+', name):
        return False
    
    return True

def get_company_key(name: str) -> str:
    """–°–æ–∑–¥–∞–µ—Ç –∫–ª—é—á –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ –ø–æ—Ö–æ–∂–∏—Ö –∫–æ–º–ø–∞–Ω–∏–π"""
    # –£–ø—Ä–æ—â–µ–Ω–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏
    key = re.sub(r'[^–∞-—è—ëa-z0-9]', '', name.lower())
    
    # –û—Å–æ–±—ã–µ –ø—Ä–∞–≤–∏–ª–∞ –¥–ª—è –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –∫–æ–º–ø–∞–Ω–∏–π
    if '—Å–±–µ—Ä' in key:
        if '–±–∞–Ω–∫' in key or key == '—Å–±–µ—Ä' or key == '—Å–±–µ—Ä–±–∞–Ω–∫':
            return '—Å–±–µ—Ä'
        elif '—Ç–µ—Ö' in key:
            return '—Å–±–µ—Ä—Ç–µ—Ö'
        elif '–º–∞—Ä–∫–µ—Ç' in key:
            return '—Å–±–µ—Ä–º–∞—Ä–∫–µ—Ç'
        # –ò–Ω–∞—á–µ –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å –¥–ª—è –°–±–µ—Ä–ú–æ–±–∞–π–ª, –°–±–µ—Ä–ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –∏ —Ç.–¥.
    elif '–∞–ª—å—Ñ–∞' in key and ('–±–∞–Ω–∫' in key or key == '–∞–ª—å—Ñ–∞'):
        return '–∞–ª—å—Ñ–∞–±–∞–Ω–∫'
    elif key in ['—Ç–∏–Ω—å–∫–æ—Ñ—Ñ', '—Ç–±–∞–Ω–∫', '—Ç–±–∞–Ω–∫', '—Ç-–±–∞–Ω–∫']:
        return '—Ç–∏–Ω—å–∫–æ—Ñ—Ñ'
    elif key == '–º—Ç—Å':
        return '–º—Ç—Å'
    elif key == '–≤—Ç–±':
        return '–≤—Ç–±'
    elif '—è–Ω–¥–µ–∫—Å' in key:
        return '—è–Ω–¥–µ–∫—Å'
    elif '–≥–∞–∑–ø—Ä–æ–º' in key and '–±–∞–Ω–∫' in key:
        return '–≥–∞–∑–ø—Ä–æ–º–±–∞–Ω–∫'
    
    return key

def choose_best_name(names: List[str]) -> str:
    """–í—ã–±–∏—Ä–∞–µ—Ç –ª—É—á—à–µ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –∏–∑ –≥—Ä—É–ø–ø—ã –¥—É–±–ª–∏–∫–∞—Ç–æ–≤"""
    if not names:
        return ""
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º –≤–∞–ª–∏–¥–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è
    valid_names = [n for n in names if is_valid_company(n)]
    if not valid_names:
        return ""
    
    # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: –∫–æ—Ä–æ—Ç–∫–∏–µ, –±–µ–∑ —Å–∏–º–≤–æ–ª–æ–≤, –±–µ–∑ –æ–ø–∏—Å–∞–Ω–∏–π
    def name_score(name: str) -> tuple:
        length = len(name)
        has_symbols = bool(re.search(r'[^\w\s–∞-—è—ë–ê-–Ø–Å]', name))
        has_brackets = '(' in name or '[' in name
        has_quotes = '"' in name or "'" in name
        is_upper = name.isupper()
        has_description = any(word in name.lower() for word in ['–ø—Ä–æ–µ–∫—Ç', '–∞—É—Ç—Å—Ç–∞—Ñ—Ñ', '—ç—Ç–∞–ø'])
        
        return (has_description, has_brackets, has_quotes, has_symbols, is_upper, length)
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –∏ –≤—ã–±–∏—Ä–∞–µ–º –ª—É—á—à–∏–π
    sorted_names = sorted(valid_names, key=name_score)
    return sorted_names[0]

def ultra_clean_companies():
    """–£–ª—å—Ç—Ä–∞-–æ—á–∏—Å—Ç–∫–∞ —Å–ø–∏—Å–∫–∞ –∫–æ–º–ø–∞–Ω–∏–π"""
    
    print("üöÄ –£–õ–¨–¢–†–ê-–û–ß–ò–°–¢–ö–ê –°–ü–ò–°–ö–ê –ö–û–ú–ü–ê–ù–ò–ô")
    print("=" * 60)
    
    # –ß–∏—Ç–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Å–ø–∏—Å–æ–∫
    try:
        with open('clean_companies_list.txt', 'r', encoding='utf-8') as f:
            content = f.read()
    except FileNotFoundError:
        print("‚ùå –§–∞–π–ª clean_companies_list.txt –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–º–ø–∞–Ω–∏–∏ –∏–∑ —Å–µ–∫—Ü–∏–∏
    lines = content.split('\n')
    companies = []
    in_section = False
    
    for line in lines:
        line = line.strip()
        if '–ß–ò–°–¢–´–ô –°–ü–ò–°–û–ö –ö–û–ú–ü–ê–ù–ò–ô:' in line:
            in_section = True
            continue
        elif '–£–î–ê–õ–ï–ù–ù–´–ô –ú–£–°–û–†:' in line:
            break
        elif in_section and line and not line.startswith('-'):
            # –£–±–∏—Ä–∞–µ–º –Ω—É–º–µ—Ä–∞—Ü–∏—é
            clean_line = re.sub(r'^\s*\d+\.\s*', '', line)
            if clean_line:
                companies.append(clean_line)
    
    print(f"üìã –ò—Å—Ö–æ–¥–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π: {len(companies)}")
    
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∏ –≥—Ä—É–ø–ø–∏—Ä—É–µ–º
    groups = defaultdict(list)
    garbage_count = 0
    
    for company in companies:
        normalized = aggressive_normalize(company)
        
        if not is_valid_company(normalized):
            garbage_count += 1
            continue
        
        key = get_company_key(normalized)
        groups[key].append(normalized)
    
    # –°–æ–∑–¥–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫
    final_companies = []
    duplicates_removed = 0
    
    print(f"\nüîç –ù–ê–ô–î–ï–ù–ù–´–ï –î–£–ë–õ–ò–ö–ê–¢–´:")
    for key, group in groups.items():
        if len(group) > 1:
            print(f"  {key}: {group}")
            duplicates_removed += len(group) - 1
        
        best_name = choose_best_name(group)
        if best_name:
            final_companies.append(best_name)
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∞–ª—Ñ–∞–≤–∏—Ç—É
    final_companies.sort(key=lambda x: x.lower())
    
    print(f"\n‚úÖ –†–ï–ó–£–õ–¨–¢–ê–¢:")
    print(f"   –§–∏–Ω–∞–ª—å–Ω—ã—Ö –∫–æ–º–ø–∞–Ω–∏–π: {len(final_companies)}")
    print(f"   –£–¥–∞–ª–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {duplicates_removed}")
    print(f"   –£–¥–∞–ª–µ–Ω–æ –º—É—Å–æ—Ä–∞: {garbage_count}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    output_file = 'ultra_clean_companies.txt'
    
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("–£–õ–¨–¢–†–ê-–ß–ò–°–¢–´–ô –°–ü–ò–°–û–ö –ö–û–ú–ü–ê–ù–ò–ô\n")
        f.write("=" * 60 + "\n\n")
        f.write(f"–í—Å–µ–≥–æ –∫–æ–º–ø–∞–Ω–∏–π: {len(final_companies)}\n")
        f.write(f"–£–¥–∞–ª–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {duplicates_removed}\n") 
        f.write(f"–£–¥–∞–ª–µ–Ω–æ –º—É—Å–æ—Ä–∞: {garbage_count}\n\n")
        
        f.write("–¢–û–ü-30 –°–ê–ú–´–• –ü–û–ü–£–õ–Ø–†–ù–´–•:\n")
        f.write("-" * 30 + "\n")
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —É–ø–æ–º–∏–Ω–∞–Ω–∏—è
        mentions = defaultdict(int)
        for group in groups.values():
            mentions[choose_best_name(group)] = len(group)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç–∏
        popular = sorted(final_companies, key=lambda x: mentions.get(x, 1), reverse=True)
        
        for i, company in enumerate(popular[:30], 1):
            count = mentions.get(company, 1)
            f.write(f"{i:2d}. {company} ({count} —É–ø–æ–º–∏–Ω–∞–Ω–∏–π)\n")
        
        f.write(f"\n\n–ü–û–õ–ù–´–ô –°–ü–ò–°–û–ö ({len(final_companies)} –∫–æ–º–ø–∞–Ω–∏–π):\n")
        f.write("-" * 30 + "\n")
        
        for i, company in enumerate(final_companies, 1):
            f.write(f"{i:3d}. {company}\n")
    
    print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤: {output_file}")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –¢–û–ü-20
    print(f"\nüèÜ –¢–û–ü-20 –°–ê–ú–´–• –ß–ò–°–¢–´–• –ö–û–ú–ü–ê–ù–ò–ô:")
    for i, company in enumerate(final_companies[:20], 1):
        print(f"{i:2d}. {company}")

if __name__ == "__main__":
    ultra_clean_companies() 