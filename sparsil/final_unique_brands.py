#!/usr/bin/env python3
"""
–§–ò–ù–ê–õ–¨–ù–ê–Ø –≤–µ—Ä—Å–∏—è —Å–æ–∑–¥–∞–Ω–∏—è —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –±—Ä–µ–Ω–¥–æ–≤
–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –ø—Ä–æ—Å—Ç–∞—è –∏ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞
"""

import re
from typing import List, Dict
from collections import defaultdict

def extract_base_brand(company_name: str) -> str:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –±–∞–∑–æ–≤–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –±—Ä–µ–Ω–¥–∞ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ"""
    if not company_name:
        return ""
    
    # –£–±–∏—Ä–∞–µ–º –Ω—É–º–µ—Ä–∞—Ü–∏—é –≤ –Ω–∞—á–∞–ª–µ
    name = re.sub(r'^\s*\d+\.\s*', '', company_name)
    
    # –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û –ê–ì–†–ï–°–°–ò–í–ù–û —É–±–∏—Ä–∞–µ–º –≤—Å—ë —á—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –æ–ø–∏—Å–∞–Ω–∏–µ–º
    # –£–±–∏—Ä–∞–µ–º –≤—Å—ë –Ω–∞—á–∏–Ω–∞—è —Å –ø–µ—Ä–≤–æ–π —Å–∫–æ–±–∫–∏
    name = re.sub(r'\s*[\(\[].*$', '', name)
    
    # –£–±–∏—Ä–∞–µ–º –≤—Å—ë –ø–æ—Å–ª–µ —Ç–∏—Ä–µ, –∑–∞–ø—è—Ç–æ–π, –¥–≤–æ–µ—Ç–æ—á–∏—è
    name = re.sub(r'\s*[-‚Äì‚Äî,:;].*$', '', name)
    
    # –£–±–∏—Ä–∞–µ–º –≤—Å—ë –ø–æ—Å–ª–µ —Å—Ç–æ–ø-—Å–ª–æ–≤ (–≤ –ª—é–±–æ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ)
    stop_words = [
        '–Ω–∞', '–≤', '–¥–ª—è', '–æ—Ç', '—á–µ—Ä–µ–∑', '–∫', '—Å', '–ø–æ', '–∏–∑', '–æ', '–ø—Ä–æ',
        '–∞—É—Ç—Å—Ç–∞—Ñ—Ñ', '–∞—É—Ç—Å–æ—Ä—Å', '–ø—Ä–æ–µ–∫—Ç', '–∫–æ–º–∞–Ω–¥–∞', '–æ—Ç–¥–µ–ª', '—Å—Ç—Ä–∏–º', 
        '–ø–ª–∞—Ç—Ñ–æ—Ä–º–∞', '—Å–æ–±–µ—Å', '—Ç–µ—Ö', '—Ç–µ—Ö–Ω–∏—á–∫–∞', '—Å–∫—Ä–∏–Ω–∏–Ω–≥', '–∏–Ω—Ç–µ—Ä–≤—å—é',
        '—ç—Ç–∞–ø', '—Ñ–∏–Ω–∞–ª', '–≤—Å—Ç—Ä–µ—á–∞', '–∑–Ω–∞–∫–æ–º—Å—Ç–≤–æ', '—Ä–∞–∑–≥–æ–≤–æ—Ä', '—Å–æ–∑–≤–æ–Ω',
        'hr', '—ç–π—á–∞—Ä–∫–∞', '–Ω–∞–ø–∏—Å–∞–ª–∞', '—Å–∞–º–∞', '–ª–∏–¥', '–ª–∏–¥–æ–º', '–∫–æ–º–∞–Ω–¥—ã',
        '–≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π', '–≤–Ω—É—Ç—Ä–∏', '–≤–Ω–µ—à–Ω–∏–π', '–¥–æ—á–∫–∞', '—Ä–∞–Ω–µ–µ', '–±—ã–ª–æ'
    ]
    
    # –°–æ–∑–¥–∞–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å—Ç–æ–ø-—Å–ª–æ–≤ –∫–∞–∫ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Å–ª–æ–≤
    stop_pattern = r'\s+(?:' + '|'.join(re.escape(word) for word in stop_words) + r')\b.*$'
    name = re.sub(stop_pattern, '', name, flags=re.IGNORECASE)
    
    # –£–±–∏—Ä–∞–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã –≤ –Ω–∞—á–∞–ª–µ –∏ –∫–æ–Ω—Ü–µ
    name = re.sub(r'^[*"\'\s\-:]+', '', name)
    name = re.sub(r'[*"\'\s\-:\.]+$', '', name)
    
    # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
    name = ' '.join(name.split())
    
    return name.strip()

def normalize_brand_for_grouping(brand: str) -> str:
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –±—Ä–µ–Ω–¥ –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏"""
    if not brand:
        return ""
    
    # –£–±–∏—Ä–∞–µ–º –≤—Å–µ –∫—Ä–æ–º–µ –±—É–∫–≤ –∏ —Ü–∏—Ñ—Ä, –ø—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
    normalized = re.sub(r'[^–∞-—è—ëa-z0-9]', '', brand.lower())
    
    # –û—Å–æ–±—ã–µ —Å–ª—É—á–∞–∏ –¥–ª—è –∫—Ä—É–ø–Ω—ã—Ö –±—Ä–µ–Ω–¥–æ–≤
    brand_mapping = {
        '—Å–±–µ—Ä': '—Å–±–µ—Ä',
        '—Å–±–µ—Ä–±–∞–Ω–∫': '—Å–±–µ—Ä',
        '—Å–±–µ—Ä—Ç': '—Å–±–µ—Ä',
        '—Å–±–µ—Ä–∫–æ—Ä—É—Å': '—Å–±–µ—Ä',
        '–∞–ª—å—Ñ–∞': '–∞–ª—å—Ñ–∞–±–∞–Ω–∫',
        '–∞–ª—å—Ñ–∞–±–∞–Ω–∫': '–∞–ª—å—Ñ–∞–±–∞–Ω–∫',
        '—Ç–∏–Ω—å–∫–æ—Ñ—Ñ': '—Ç–∏–Ω—å–∫–æ—Ñ—Ñ',
        '—Ç–±–∞–Ω–∫': '—Ç–∏–Ω—å–∫–æ—Ñ—Ñ',
        '—è–Ω–¥–µ–∫—Å': '—è–Ω–¥–µ–∫—Å',
        'yandex': '—è–Ω–¥–µ–∫—Å',
        '–º—Ç—Å': '–º—Ç—Å',
        '–≤—Ç–±': '–≤—Ç–±',
        '–≥–∞–∑–ø—Ä–æ–º–±–∞–Ω–∫': '–≥–∞–∑–ø—Ä–æ–º–±–∞–Ω–∫',
        '–≥–∞–∑–ø—Ä–æ–º': '–≥–∞–∑–ø—Ä–æ–º–±–∞–Ω–∫',
        '–≥–ø–±': '–≥–∞–∑–ø—Ä–æ–º–±–∞–Ω–∫',
        'ozon': 'ozon',
        '–æ–∑–æ–Ω': 'ozon',
        'wildberries': 'wildberries',
        'wb': 'wildberries',
        '–∞–≤–∏—Ç–æ': '–∞–≤–∏—Ç–æ',
        'avito': '–∞–≤–∏—Ç–æ'
    }
    
    return brand_mapping.get(normalized, normalized)

def is_valid_brand_name(name: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —á—Ç–æ –Ω–∞–∑–≤–∞–Ω–∏–µ –≤–∞–ª–∏–¥–Ω–æ –∫–∞–∫ –±—Ä–µ–Ω–¥ –∫–æ–º–ø–∞–Ω–∏–∏"""
    if not name or len(name) < 2:
        return False
    
    # –î–æ–ª–∂–Ω—ã –±—ã—Ç—å –±—É–∫–≤—ã
    if not re.search(r'[–∞-—è—ëa-zA-Z]', name):
        return False
    
    # –ò—Å–∫–ª—é—á–∞–µ–º –æ—á–µ–≤–∏–¥–Ω—ã–π –º—É—Å–æ—Ä
    garbage_words = [
        '—Ç–µ—Ö', '—Å–æ–±–µ—Å', '—ç—Ç–∞–ø', '—Ñ–∏–Ω–∞–ª', 'hr', '—ç–π—á–∞—Ä–∫–∞', '—Å–∫—Ä–∏–Ω–∏–Ω–≥',
        '–∏–Ω—Ç–µ—Ä–≤—å—é', '–≤—Å—Ç—Ä–µ—á–∞', '–∑–Ω–∞–∫–æ–º—Å—Ç–≤–æ', '—Ä–∞–∑–≥–æ–≤–æ—Ä', '—Å–æ–∑–≤–æ–Ω',
        '–∞—É—Ç—Å—Ç–∞—Ñ—Ñ', '–∞—É—Ç—Å–æ—Ä—Å', '–ø—Ä–æ–µ–∫—Ç', '–∫–æ–º–∞–Ω–¥–∞', '–æ—Ç–¥–µ–ª', '—Å—Ç—Ä–∏–º',
        'function', 'import', 'export', 'const', 'console', 'return'
    ]
    
    name_lower = name.lower()
    if name_lower in garbage_words:
        return False
    
    # –ù–µ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–µ
    if len(name) > 30:
        return False
    
    return True

def select_best_brand_name(brand_variants: List[str]) -> str:
    """–í—ã–±–∏—Ä–∞–µ—Ç –ª—É—á—à–∏–π –≤–∞—Ä–∏–∞–Ω—Ç –Ω–∞–∑–≤–∞–Ω–∏—è –±—Ä–µ–Ω–¥–∞"""
    if not brand_variants:
        return ""
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º –≤–∞–ª–∏–¥–Ω—ã–µ
    valid_variants = [v for v in brand_variants if is_valid_brand_name(v)]
    if not valid_variants:
        return ""
    
    # –£–±–∏—Ä–∞–µ–º —Ç–æ—á–Ω—ã–µ –¥—É–±–ª–∏–∫–∞—Ç—ã
    unique_variants = list(set(valid_variants))
    
    # –ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –∫—Ä–∏—Ç–µ—Ä–∏–∏ (—á–µ–º –º–µ–Ω—å—à–µ, —Ç–µ–º –ª—É—á—à–µ)
    def quality_score(name: str) -> tuple:
        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: –∏–∑–≤–µ—Å—Ç–Ω—ã–µ –±—Ä–µ–Ω–¥—ã
        known_brands = ['–°–±–µ—Ä', '–Ø–Ω–¥–µ–∫—Å', '–ú–¢–°', '–í–¢–ë', '–¢–∏–Ω—å–∫–æ—Ñ—Ñ', '–ì–∞–∑–ø—Ä–æ–º–±–∞–Ω–∫', '–ê–≤–∏—Ç–æ', 'Ozon', 'IBS']
        is_known = name in known_brands
        
        # –ö–∞—á–µ—Å—Ç–≤–æ –Ω–∞–∑–≤–∞–Ω–∏—è
        length = len(name)
        has_symbols = bool(re.search(r'[^–∞-—è—ë–ê-–Ø–Åa-zA-Z0-9\s\.]', name))
        has_numbers = bool(re.search(r'\d', name))
        is_all_caps = name.isupper()
        has_dots = '.' in name and not name.endswith('.ru')
        
        return (not is_known, has_symbols, has_dots, has_numbers, is_all_caps, length)
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∫–∞—á–µ—Å—Ç–≤—É
    sorted_variants = sorted(unique_variants, key=quality_score)
    return sorted_variants[0]

def create_final_unique_brands():
    """–°–æ–∑–¥–∞–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –±—Ä–µ–Ω–¥–æ–≤"""
    
    print("üéØ –§–ò–ù–ê–õ–¨–ù–û–ï –°–û–ó–î–ê–ù–ò–ï –£–ù–ò–ö–ê–õ–¨–ù–´–• –ë–†–ï–ù–î–û–í")
    print("=" * 60)
    
    # –ß–∏—Ç–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Å–ø–∏—Å–æ–∫
    try:
        with open('ultra_clean_companies.txt', 'r', encoding='utf-8') as f:
            content = f.read()
    except FileNotFoundError:
        print("‚ùå –§–∞–π–ª ultra_clean_companies.txt –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤—Å–µ –∫–æ–º–ø–∞–Ω–∏–∏
    lines = content.split('\n')
    companies = []
    in_full_list = False
    
    for line in lines:
        line = line.strip()
        if '–ü–û–õ–ù–´–ô –°–ü–ò–°–û–ö' in line:
            in_full_list = True
            continue
        elif in_full_list and line and not line.startswith('-'):
            clean_line = re.sub(r'^\s*\d+\.\s*', '', line)
            if clean_line:
                companies.append(clean_line)
    
    print(f"üìã –ò—Å—Ö–æ–¥–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π: {len(companies)}")
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –±–∞–∑–æ–≤—ã–µ –±—Ä–µ–Ω–¥—ã –∏ –≥—Ä—É–ø–ø–∏—Ä—É–µ–º
    brand_groups = defaultdict(list)
    
    for company in companies:
        base_brand = extract_base_brand(company)
        if not base_brand or not is_valid_brand_name(base_brand):
            continue
        
        group_key = normalize_brand_for_grouping(base_brand)
        if group_key:
            brand_groups[group_key].append(base_brand)
    
    print(f"üìã –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –≥—Ä—É–ø–ø: {len(brand_groups)}")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫—Ä—É–ø–Ω—ã–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è
    print(f"\nüî• –ö–†–£–ü–ù–´–ï –û–ë–™–ï–î–ò–ù–ï–ù–ò–Ø (3+ –¥—É–±–ª–∏–∫–∞—Ç–∞):")
    large_merges = [(k, v) for k, v in brand_groups.items() if len(v) >= 3]
    large_merges.sort(key=lambda x: len(x[1]), reverse=True)
    
    for group_key, variants in large_merges[:15]:
        unique_variants = list(set(variants))
        if len(unique_variants) > 1:
            print(f"  {group_key}: {unique_variants} ({len(variants)} —É–ø–æ–º–∏–Ω–∞–Ω–∏–π)")
    
    # –°–æ–∑–¥–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫
    final_brands = []
    total_merged = 0
    
    for group_key, variants in brand_groups.items():
        if len(variants) > 1:
            total_merged += len(variants) - 1
        
        best_brand = select_best_brand_name(variants)
        if best_brand:
            final_brands.append(best_brand)
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º
    final_brands.sort(key=lambda x: x.lower())
    
    print(f"\n‚úÖ –ò–¢–û–ì–û–í–´–ô –†–ï–ó–£–õ–¨–¢–ê–¢:")
    print(f"   –§–∏–Ω–∞–ª—å–Ω—ã—Ö —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –±—Ä–µ–Ω–¥–æ–≤: {len(final_brands)}")
    print(f"   –û–±—ä–µ–¥–∏–Ω–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {total_merged}")
    print(f"   –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å: {(1 - len(final_brands)/len(companies))*100:.1f}%")
    
    # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç—å
    brand_popularity = {}
    for group_key, variants in brand_groups.items():
        best_brand = select_best_brand_name(variants)
        if best_brand:
            brand_popularity[best_brand] = len(variants)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    output_file = 'final_unique_brands.txt'
    
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("–§–ò–ù–ê–õ–¨–ù–´–ï –£–ù–ò–ö–ê–õ–¨–ù–´–ï –ë–†–ï–ù–î–´ –ö–û–ú–ü–ê–ù–ò–ô\n")
        f.write("=" * 60 + "\n\n")
        f.write(f"–í—Å–µ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –±—Ä–µ–Ω–¥–æ–≤: {len(final_brands)}\n")
        f.write(f"–û–±—ä–µ–¥–∏–Ω–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {total_merged}\n")
        f.write(f"–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å —Å–∂–∞—Ç–∏—è: {(1 - len(final_brands)/len(companies))*100:.1f}%\n\n")
        
        # –¢–û–ü –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö
        popular_brands = sorted(final_brands, key=lambda x: brand_popularity.get(x, 1), reverse=True)
        
        f.write("–¢–û–ü-30 –°–ê–ú–´–• –ü–û–ü–£–õ–Ø–†–ù–´–• –ë–†–ï–ù–î–û–í:\n")
        f.write("-" * 40 + "\n")
        for i, brand in enumerate(popular_brands[:30], 1):
            count = brand_popularity.get(brand, 1)
            f.write(f"{i:2d}. {brand} ({count} —É–ø–æ–º–∏–Ω–∞–Ω–∏–π)\n")
        
        f.write(f"\n\n–í–°–ï –£–ù–ò–ö–ê–õ–¨–ù–´–ï –ë–†–ï–ù–î–´ ({len(final_brands)}):\n")
        f.write("-" * 40 + "\n")
        
        for i, brand in enumerate(final_brands, 1):
            f.write(f"{i:3d}. {brand}\n")
    
    print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤: {output_file}")
    
    # –¢–û–ü-20 –¥–ª—è –≤—ã–≤–æ–¥–∞
    print(f"\nüèÜ –¢–û–ü-20 –°–ê–ú–´–• –ü–û–ü–£–õ–Ø–†–ù–´–• –ë–†–ï–ù–î–û–í:")
    top20 = sorted(final_brands, key=lambda x: brand_popularity.get(x, 1), reverse=True)[:20]
    for i, brand in enumerate(top20, 1):
        count = brand_popularity.get(brand, 1)
        print(f"{i:2d}. {brand} ({count} —É–ø–æ–º–∏–Ω–∞–Ω–∏–π)")

if __name__ == "__main__":
    create_final_unique_brands() 