import re
import os
import json
from collections import defaultdict

# –°–ø–∏—Å–æ–∫ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –∫–æ–º–ø–∞–Ω–∏–π –∏–∑ –Ω–∞—à–∏—Ö –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –∞–Ω–∞–ª–∏–∑–æ–≤
KNOWN_COMPANIES = {
    '—è–Ω–¥–µ–∫—Å', '—Å–±–µ—Ä', '—Ç–∏–Ω–∫–æ—Ñ—Ñ', '—Ç–∏–Ω–∫–æ—Ñ', '–ª–µ–º–º–∞', 'wb', '–∏–Ω–Ω–æ—Ç–µ—Ö', '–æ—Ç–ø', '–æ—Ç–ø –±–∞–Ω–∫', 
    '–≥–∞–∑–ø—Ä–æ–º', '–≥–∞–∑–ø—Ä–æ–º–±–∞–Ω–∫', 'profsoft', 'altenar', 'it-one', '—Å–±–µ—Ä—Ç–µ—Ö', '–∞–ª—å—Ñ–∞', 
    '–∞–ª—å—Ñ–∞–±–∞–Ω–∫', '–∞–ª—å—Ñ–∞-–±–∞–Ω–∫', '–≤–∫', '–∞–≤—Ç–æ–º–∞–∫–æ–Ω', '–º–æ–π—Å–∫–ª–∞–¥', '—Ü–µ–∑–∏–æ', 'qugo', 'ibs', 
    '—Ä–æ—Å–±–∞–Ω–∫', '–æ–æ–æ –º–æ–±–∞–π–ª–¥–µ–≤–µ–ª–æ–ø–º–µ–Ω—Ç', '—Å–∏–±—É—Ä', '–≥–∫ —Ç1', '–±–∏–ª–∞–π–Ω', 'kotelov', '–≤—Ç–±',
    'unisender', '–æ–∑–æ–Ω', '–ø–æ–ª–µ.—Ä—Ñ', 'artw', '–∞–≤–∏—Ç–æ', 'realweb', 'itfb', '–∫–∏–±–µ—Ä–ª–∞–±', 
    'portalbilet', 'marpla', '—Ä–æ—Å–≥–æ—Å—Å—Ç—Ä–∞—Ö', 'right line', 'quantum art', '–∞–ª–∞—Å–∫–∞—Ä —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏',
    '—Å–µ–ª–µ–∫—Ç–∏', '–ø—Ä–æ–º—Å–≤—è–∑—å–±–∞–Ω–∫', '—Å–±–µ—Ä–¥–µ–≤–∞–π—Å—ã', 'funbox', '—Ü—É–º', 'it baltic', '—Å–±–µ—Ä–∫–æ—Ä—É—Å',
    '—Ä—É—Ç—É–±', '–µ–≤—Ä–æ—Ç–µ—Ö–∫–ª–∏–º–∞—Ç', 'luxsoft', 'tilda', '–∞–Ω—Ç–∞—Ä–∞', '—Ñ–∏–Ω–∞–º', '–±–∞–ª–∞–Ω—Å –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞',
    '–ª–∞–± –∫–∞—Å–ø', '—è–Ω–¥–µ–∫—Å —Ç–∞–∫—Å–∏', 'click2money', 'kts', 'premium it solution', 'moex',
    'eesee', '–¥–æ–º.—Ä—Ñ', '–ª–∏–≥–∞ —Ü–∏—Ñ—Ä–æ–≤–æ–π —ç–∫–æ–Ω–æ–º–∏–∫–∏', '—è–Ω–¥–µ–∫—Å –ø—Ä–æ', 'coding team', '—é—Ç—ç–∏—Ä',
    'goinvest', 'yandex.pay', 'yandex.multitrack', '–±–∞—É–º', '–∫–æ–∫–æ—Å.group', '—Å–∫–≤–∞–¥',
    '—Ç–æ—á–∫–∞ –±–∞–Ω–∫', 'vision', 'sbertech', '–æ–Ω–ª–∞–π–Ω —à–∫–æ–ª–∞ —Ç–µ—Ç—Ä–∏–∫–∞', '—Å—Ñ–µ—Ä–∞', 'yandex',
    'mail.ru', 'kaspersky', '—Ä–∞–π—Ñ–∞–π–∑–µ–Ω', 'tele2', '—Ç–µ–ª–µ2', '—Ä—Å—Ö–±', '—Ä—Å—Ö–±-–∏–Ω—Ç–µ—Ö',
    '—Ç–µ—Ö–∑–æ—Ä', '—É—Ä–±–∞–Ω—Ç–µ—Ö', 'datsteam', 'dats team', 'unybrands', '–º—Ç—Å', 'northflank',
    '–∫—å—é–≥–æ', '–∫–æ–¥–∏–Ω–≥ —Ç–∏–º', '—Å—Ç—Ä–∏–º —Ç–µ–ª–µ–∫–æ–º', 'stream telecom', '–±–∞—É–º', 'realtime',
    '–∫–ª–∏–∫—Ç—É–º–∞–Ω–∏', 'click to money', '—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞', '—Ö–æ–ª–¥–∏–Ω–≥', '–±—Ñ—Ç',
    'ivi', '—Ä–∞—Å—á–µ—Ç–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è', '—Å–±–µ—Ä –¥–ª—è —ç–∫—Å–ø–µ—Ä—Ç–æ–≤', '–ø–æ—á—Ç–∞ —Ä–æ—Å—Å–∏–∏', '—Å–æ–≤–∫–æ–º–±–∞–Ω–∫',
    '—Å–µ–≤–µ—Ä—Å—Ç–∞–ª—å', '–∫–∞—Å–ø–µ—Ä—Å–∫–∏–π', '–Ω–µ—Ç–æ–ª–æ–≥–∏—è', 'skillbox', 'geekbrains', 'hexlet'
}

EXCLUSION_PATTERN = r"""^(—Ç–æ –µ—Å—Ç—å|–Ω–µ–ª—å–∑—è|–±–µ–∑|–Ω–∞–ø–∏—Å–∞—Ç—å|—á–∞—Å—Ç–æ|—Ä–µ—à–µ–Ω–æ|—Ä–∞–∑|–≤—Å—Ç—Ä–µ—á–∞–ª–æ—Å—å?|–ø–æ–ø–∞–¥–∞–ª–æ—Å—å?|–≤ —Ü–µ–ª–æ–º|
–ø—Ä–∏–º–µ—Ä|–∑–∞–¥–∞—á–∞|–∑–∞–¥–∞—á–∏|—Ä–µ—à–µ–Ω–∏–µ|—Ä–µ—à–µ–Ω–∏—è|–∫–∞–∫|–Ω–∞–¥–æ|–Ω—É–∂–Ω–æ|–∫–∞–∫–æ–π|–∫–∞–∫–∏–µ|–æ–ø–∏—Å–∞–Ω–∏–µ|—Å–º—ã—Å–ª|—á—Ç–æ|—á—Ç–æ–±—ã|–µ—Å–ª–∏|–∏–ª–∏|–ø—Ä–æ–≤–µ—Ä–∫–∞|–æ—à–∏–±–∫–∞|–æ—à–∏–±–∫–∏|—Ç–µ—Å—Ç|—Ç–µ—Å—Ç—ã|—à–∞–±–ª–æ–Ω|—à–∞–±–ª–æ–Ω—ã|–æ–±—ä–µ–∫—Ç|–º–∞—Å—Å–∏–≤|—Å—Ç—Ä–æ–∫–∞|—á–∏—Å–ª–æ|—Ñ—É–Ω–∫—Ü–∏—è|–∫–ª–∞—Å—Å—ã|—Ö—É–∫–∏|–ø–æ–ª—è|—Ç–∏–ø—ã|–∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ—Å—Ç—å|–ø—Ä–æ–º–∏—Å—ã|–∫–æ–ª–±—ç–∫–∏|–∑–∞–º—ã–∫–∞–Ω–∏—è|—Ä–µ–∫—É—Ä—Å–∏—è|–∞–ª–≥–æ—Ä–∏—Ç–º—ã|—Å—Ç—Ä—É–∫—Ç—É—Ä—ã|–¥–∞–Ω–Ω—ã–µ|—Å–µ—Ä–≤–µ—Ä|–∫–ª–∏–µ–Ω—Ç|—Ñ—Ä–æ–Ω—Ç–µ–Ω–¥|–±—ç–∫–µ–Ω–¥|api|–±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö|–±–¥|–æ–æ–ø|–ø–∞—Ç—Ç–µ—Ä–Ω—ã|–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞|–¥–∏–∑–∞–π–Ω|—Å–∏—Å—Ç–µ–º–∞|–∫–æ–º–∞–Ω–¥–∞|—Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ|–≤–æ–ø—Ä–æ—Å|–æ—Ç–≤–µ—Ç|–ø—Ä–∞–∫—Ç–∏–∫–∞|—Ç–µ–æ—Ä–∏—è|—Å—Ç–∞—Ç—å—è|–≥–ª–∞–≤–∞|—á–∞—Å—Ç—å|—á–∞—Å—Ç–æ|–ø—Ä–æ—Å—Ç–æ|—Å–ª–æ–∂–Ω–æ|–¥–ª—è|–æ—Ç|—Å|–∏–∑|–≤|–Ω–∞|–ø–æ|–∑–∞|–ø—Ä–∏|–¥–æ|–ø–æ—Å–ª–µ|—Å–æ|–ø—É—Ç—å|–¥–ª—è|–∫–ª—é—á|–∑–Ω–∞—á–µ–Ω–∏–µ|–∫–æ–¥|–∫–æ–¥–∞|—Ç–µ–∫—Å—Ç|—Ç–µ–∫—Å—Ç–∞|–∫–æ–º–ø–æ–Ω–µ–Ω—Ç|–∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã|–≤–∏–¥–∂–µ—Ç|–≤–∏–¥–∂–µ—Ç—ã|—Å—Ç—Ä–∞–Ω–∏—Ü–∞|—Å—Ç—Ä–∞–Ω–∏—Ü—ã|–º–æ–¥–µ–ª—å|–º–æ–¥–µ–ª–∏|—Å–ª–∞–π—Å|—Å–ª–∞–π—Å—ã|—Ö—É–∫|—Ö—É–∫–∏|—Å—Ç–∏–ª–∏|–∫–æ–Ω—Å—Ç–∞–Ω—Ç—ã|—É—Ç–∏–ª–∏—Ç—ã|–∫–æ–Ω—Ç–µ–∫—Å—Ç|—Ä–æ—É—Ç–µ—Ä|–ø—Ä–æ–≤–∞–π–¥–µ—Ä|—Ä–µ–¥–∞–∫—Å|redux|react|js|ts|python|sql|html|css|json|yaml|xml|git|docker|linux|windows|macos|api|ui|ux|npm|yarn|webpack|vite|babel|eslint|prettier|jest|cypress|storybook|graphql|rest|websocket|oop|fp|dry|kiss|solid|mvc|mvvm|mvp|mobx|zustand|rxjs|saga|thunk|middleware|nextjs|nuxtjs|angular|vue|svelte|node|express|django|flask|fastapi|spring|kotlin|java|c#|cpp|rust|go|php|ruby|swift|dart|flutter|android|ios|web|mobile|desktop|game|data science|ml|ai|blockchain|cloud|aws|azure|gcp|devops|ci|cd|agile|scrum|kanban|trello|jira|figma|photoshop|illustrator|sketch|vscode|intellij|sublime|atom|vim|emacs|bash|zsh|powershell|cmd|terminal|ssh|ftp|http|https|tcp|udp|ip|dns|vpn|ssl|tls|jwt|oauth|oidc|restful|microservices|monolith|serverless|kubernetes|docker compose|nginx|apache|redis|kafka|rabbitmq|postgresql|mysql|mongodb|elasticsearch|firebase|heroku|netlify|vercel|storybook|jest|redux-saga|redux-thunk|rtk query|axios|fetch|lodash|moment|dayjs|uuid|classnames|tailwind|material-ui|ant-design|bootstrap|semantic-ui|bulma|chakra-ui|radix-ui|headless-ui|react-query|swr|formik|react-hook-form|yup|zod|date-fns|immer|reselect|storybook|react-router|next-auth|graphql-request|apollo-client|urql|axios-mock-adapter|msw|enzyme|react-testing-library|jest-dom|eslint-plugin-react|typescript-eslint|prettier-plugin-tailwind|husky|lint-staged|commitlint|semantic-release|lerna|nx|rush|turborepo|pnpm|npm|yarn|vite-plugin-pwa|rollup|esbuild|parcel|browserify|rollup-plugin-node-resolve|rollup-plugin-commonjs|rollup-plugin-typescript2|rollup-plugin-terser|rollup-plugin-postcss|rollup-plugin-svg|rollup-plugin-json|rollup-plugin-url|rollup-plugin-peer-deps-external|rollup-plugin-clean|rollup-plugin-visualizer|rollup-plugin-analyzer|rollup-plugin-bundle-size|rollup-plugin-license|rollup-plugin-copy|rollup-plugin-gzip|rollup-plugin-brotli|rollup-plugin-filesize|rollup-plugin-progress|rollup-plugin-typescript)$"""

def clean_company_name(company: str) -> str:
    """–û—á–∏—â–∞–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–æ–º–ø–∞–Ω–∏–∏ –æ—Ç –º—É—Å–æ—Ä–∞, —Å—Ç–∞—Ä–∞—è—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ —á–∞—Å—Ç–∏ –Ω–∞–∑–≤–∞–Ω–∏—è."""
    company = company.lower().strip()
    
    # –£–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ —Å–∫–æ–±–∫–∏, –µ—Å–ª–∏ –æ–Ω–∏ –≤ —Å–∞–º–æ–º –∫–æ–Ω—Ü–µ —Å—Ç—Ä–æ–∫–∏ –∏ —Å–æ–¥–µ—Ä–∂–∞—Ç –ø–æ—è—Å–Ω–µ–Ω–∏—è.
    company = re.sub(r'\s*\([^)]*\)$|\[[^\]]*\]$', '', company).strip()
    
    # –£–¥–∞–ª—è–µ–º –æ—á–µ–Ω—å –æ–±—â–∏–µ —Ñ—Ä–∞–∑—ã, –∫–æ—Ç–æ—Ä—ã–µ —Ç–æ—á–Ω–æ –Ω–µ —è–≤–ª—è—é—Ç—Å—è —á–∞—Å—Ç—å—é –Ω–∞–∑–≤–∞–Ω–∏–π –∫–æ–º–ø–∞–Ω–∏–π
    cleanups_to_remove = [
        '–Ω–µ–ª—å–∑—è –∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å –º–∞—Å—Å–∏–≤, —Ç–æ –µ—Å—Ç—å inplace',
        '–±–µ–∑ set, —Å–∫–∞–∑–∞—Ç—å —Å–ª–æ–∂–Ω–æ—Å—Ç—å, –±—É–¥–µ—Ç –ª–∏ set —Ä–∞–±–æ—Ç–∞—Ç—å —Å –æ–±—ä–µ–∫—Ç–∞–º–∏',
        '–¥–ª—è —ç–∫—Å–ø–µ—Ä—Ç–æ–≤',
        '—Å–≤–∏—Å—Ç—É–Ω–æ–≤–∞ –µ–∫–∞—Ç–µ—Ä–∏–Ω–∞ –∞–ª–µ–∫—Å–∞–Ω–¥—Ä–æ–≤–Ω–∞',
        '—á–∞—Å—Ç–æ –≤ —Ü–µ–ª–æ–º', '–Ω–∞ –ª–∏—á–Ω–æ–º —Å–æ–±–µ—Å–µ', '–Ω–µ –º—É—Ç–∏—Ä—É–µ–º'
    ]
    
    for cleanup in cleanups_to_remove:
        company = re.sub(cleanup, '', company, flags=re.IGNORECASE).strip()
    
    # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–±–µ–ª—ã
    company = re.sub(r'[-‚Äì‚Äî_./]+', ' ', company).strip() # –î–æ–±–∞–≤–ª–µ–Ω—ã —Ç–æ—á–∫–∏ –∏ —Å–ª–µ—à–∏
    company = re.sub(r'\s+', ' ', company).strip()
    
    return company

def is_valid_company(company: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å—Ç—Ä–æ–∫–∞ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–º –Ω–∞–∑–≤–∞–Ω–∏–µ–º –∫–æ–º–ø–∞–Ω–∏–∏ (–±–æ–ª–µ–µ –º—è–≥–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞)."""
    original_company = company
    company = clean_company_name(company)
    
    if not company or len(company) < 2:
        return False
    
    # –ò—Å–∫–ª—é—á–∞–µ–º —è–≤–Ω—ã–π –º—É—Å–æ—Ä, –∫–æ—Ç–æ—Ä—ã–π —Ç–æ—á–Ω–æ –Ω–µ –∫–æ–º–ø–∞–Ω–∏—è
    # –≠—Ç–æ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –û–ß–ï–ù–¨ —Ç—â–∞—Ç–µ–ª—å–Ω–æ —Å–æ—Å—Ç–∞–≤–ª–µ–Ω, —á—Ç–æ–±—ã –Ω–µ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å —Ä–µ–∞–ª—å–Ω—ã–µ –∫–æ–º–ø–∞–Ω–∏–∏.
    # –°–æ—Å—Ä–µ–¥–æ—Ç–æ—á–∏–º—Å—è –Ω–∞ –ø—Ä–µ–¥–ª–æ–≥–∞—Ö, –≤–æ–ø—Ä–æ—Å–∏—Ç–µ–ª—å–Ω—ã—Ö —Å–ª–æ–≤–∞—Ö, –æ–±—â–∏—Ö –ø–æ–Ω—è—Ç–∏—è—Ö –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è.
    if re.match(EXCLUSION_PATTERN, company, re.IGNORECASE): # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ –º—É—Å–æ—Ä–∞
        return False
    
    # –ï—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ü–∏—Ñ—Ä—ã, –Ω–æ —Ç–∞–∫–∂–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ö–æ—Ç—è –±—ã 2 –±—É–∫–≤—ã –∏ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –ø—Ä–æ—Å—Ç–æ —á–∏—Å–ª–æ–º
    if re.search(r'\d', company) and len(re.findall(r'[–∞-—èa-z]', company)) >= 2 and not company.isdigit():
        return True

    # –ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã (–µ—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç —ç—Ç–∏ —Å–ª–æ–≤–∞, –æ–Ω–∞, –≤–µ—Ä–æ—è—Ç–Ω–æ, —è–≤–ª—è–µ—Ç—Å—è –∫–æ–º–ø–∞–Ω–∏–µ–π)
    if re.search(r'\b(–±–∞–Ω–∫|—Ç–µ—Ö|—Å–æ—Ñ—Ç|–ª–∞–±|–≥—Ä—É–ø–ø?|—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏|—Ä–µ—à–µ–Ω–∏—è|–ø–ª–∞—Ç—Ñ–æ—Ä–º–∞|—Å–∏—Å—Ç–µ–º—ã|—Å–µ—Ä–≤–∏—Å|—Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞|–∫–æ–º–ø–∞–Ω–∏|–∫–æ—Ä–ø–æ—Ä–∞—Ü–∏—è|—Ö–æ–ª–¥–∏–Ω–≥|–∞–æ|–æ–æ–æ|–ø–∫–∫|–Ω–∏–∏|–∫–±|–∑–∞–≤–æ–¥|—Ñ–∞–±—Ä–∏–∫–∞|—Ü–µ–Ω—Ç—Ä|–∏–Ω—Å—Ç–∏—Ç—É—Ç)\b', company, re.IGNORECASE):
        return True
    
    # –ï—Å–ª–∏ —ç—Ç–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–ª–æ–≤ –∏ —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ —Å–ª–æ–≤–æ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å –∑–∞–≥–ª–∞–≤–Ω–æ–π –±—É–∫–≤—ã (–≤ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π —Å—Ç—Ä–æ–∫–µ)
    if ' ' in original_company and any(word and word[0].isupper() for word in original_company.split()):
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –ø—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ–±—ã —ç—Ç–æ –Ω–µ –±—ã–ª –ø—Ä–æ—Å—Ç–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏–∑ –æ–¥–Ω–æ–≥–æ –∏–ª–∏ –¥–≤—É—Ö –æ–±—â–∏—Ö —Å–ª–æ–≤
        if len(original_company.split()) > 1 or original_company.lower() not in ['–∑–∞–¥–∞—á–∞', '–ø—Ä–∏–º–µ—Ä', '—Ä–µ—à–µ–Ω–∏–µ']:
            return True

    # Fallback: –ï—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –º—É—Å–æ—Ä–æ–º –∏ —Å–æ–¥–µ—Ä–∂–∏—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –±—É–∫–≤
    if re.match(r'^[–∞-—èa-z0-9\s-]+$', company) and len(re.findall(r'[–∞-—èa-z]', company)) >= 2:
        return True

    return False

def extract_companies_from_block(block_text: str) -> list[str]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–æ–º–ø–∞–Ω–∏–∏ –∏–∑ –±–ª–æ–∫–∞ "–≤—Å—Ç—Ä–µ—á–∞–ª–æ—Å—å –≤"""
    companies = []
    lines = block_text.split('\n')
    
    for line in lines[1:]:  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É
        # –£–±–∏—Ä–∞–µ–º –º–∞—Ä–∫–µ—Ä—ã —Å–ø–∏—Å–∫–æ–≤
        cleaned = re.sub(r'^[\t\s]*[-*+‚Ä¢]\s*', '', line).strip()
        cleaned = re.sub(r'^[\t\s]*\d+\.\s*', '', cleaned).strip()
        
        if not cleaned:
            continue
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –ø–æ –∑–∞–ø—è—Ç—ã–º, –µ—Å–ª–∏ –µ—Å—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫–æ–º–ø–∞–Ω–∏–π –≤ —Å—Ç—Ä–æ–∫–µ
        potential_companies = [c.strip() for c in re.split(r'[,;]', cleaned)]
        
        for company in potential_companies:
            if is_valid_company(company):
                clean_name = clean_company_name(company)
                if clean_name:
                    companies.append(clean_name)
    
    return companies

def extract_companies_from_headers(headers: list, context: str) -> list[str]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–æ–º–ø–∞–Ω–∏–∏ –∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ (–æ—Å–æ–±–µ–Ω–Ω–æ –¥–ª—è —Ñ–∞–π–ª–æ–≤ —Ç–∏–ø–∞ –†–µ—Ä–µ–Ω–¥–µ—Ä.md)"""
    companies = []
    
    for header in headers:
        header_text = header['text'].strip()
        header_lower = header_text.lower()
        
        # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –ª–æ–≥–∏–∫–∞ –¥–ª—è —Ñ–∞–π–ª–æ–≤ —Å –∫–æ–º–ø–∞–Ω–∏—è–º–∏ –≤ –∑–∞–≥–æ–ª–æ–≤–∫–∞—Ö
        if any(keyword in context.lower() for keyword in ['—Ä–µ—Ä–µ–Ω–¥–µ—Ä', '—Ä–µ—Ñ–∞–∫—Ç–æ—Ä']):
            # –í —ç—Ç–∏—Ö —Ñ–∞–π–ª–∞—Ö –∑–∞–≥–æ–ª–æ–≤–∫–∏ —á–∞—Å—Ç–æ —è–≤–ª—è—é—Ç—Å—è –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏ –∫–æ–º–ø–∞–Ω–∏–π
            if (header['level'] <= 3 and 
                len(header_text) < 50 and
                not re.match(r'^(–∑–∞–¥–∞—á|example|–ø—Ä–∏–º–µ—Ä|counter|todo|—Å–ø–∏—Å–∫–∏|—Ä–µ—Ñ–∞–∫—Ç–æ—Ä|—Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ|other|use|test|—Ä–µ—à–µ–Ω–∏|–º–∏–Ω–∏|–º–æ—â–Ω)', header_lower)):
                
                if is_valid_company(header_text):
                    clean_name = clean_company_name(header_text)
                    if clean_name:
                        companies.append(clean_name)
    
    return companies

def extract_all_from_md_file(file_path: str) -> dict:
    """–¢–æ—á–Ω–æ –∏–∑–≤–ª–µ–∫–∞–µ—Ç –∫–æ–º–ø–∞–Ω–∏–∏ –∏ –∑–∞–¥–∞—á–∏ –∏–∑ .md —Ñ–∞–π–ª–∞"""
    if not os.path.exists(file_path):
        return {}
    
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    result = {
        'file_path': file_path,
        'tasks': [],
        'companies': [],
        'all_headers': [],
        'statistics': {}
    }
    
    # 1. –ò–∑–≤–ª–µ–∫–∞–µ–º –≤—Å–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏
    all_headers = re.findall(r'^(#{1,6})\s*(.+)$', content, re.MULTILINE)
    for level, header_text in all_headers:
        result['all_headers'].append({
            'level': len(level),
            'text': header_text.strip(),
            'normalized': header_text.strip().lower()
        })
    
    # 2. –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–º–ø–∞–Ω–∏–∏ –∏–∑ –±–ª–æ–∫–æ–≤ "–≤—Å—Ç—Ä–µ—á–∞–ª–æ—Å—å –≤"
    company_block_patterns = [
        r'–≤—Å—Ç—Ä–µ—á–∞–ª–æ—Å—å –≤.*?(?=\n\S|\n#+|\n```|\Z)',
        r'–≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è –≤.*?(?=\n\S|\n#+|\n```|\Z)', 
        r'–≤—Å—Ç—Ä–µ—á–∞–ª—Å—è –≤.*?(?=\n\S|\n#+|\n```|\Z)',
        r'–ø–æ–ø–∞–¥–∞–ª–æ—Å—å –≤.*?(?=\n\S|\n#+|\n```|\Z)'
    ]
    
    all_companies = set()
    
    for pattern in company_block_patterns:
        blocks = re.findall(pattern, content, re.IGNORECASE | re.DOTALL)
        for block in blocks:
            companies_in_block = extract_companies_from_block(block)
            all_companies.update(companies_in_block)
    
    # 3. –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–º–ø–∞–Ω–∏–∏ –∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
    header_companies = extract_companies_from_headers(result['all_headers'], file_path)
    all_companies.update(header_companies)
    
    result['companies'] = sorted(list(all_companies))
    
    # 4. –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –∑–∞–¥–∞—á–∏
    sections = re.split(r'(^#{1,6}\s+.+)$', content, flags=re.MULTILINE)
    
    current_task = None
    current_content = ""
    
    for section in sections:
        if re.match(r'^#{1,6}\s+', section):
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–µ–¥—ã–¥—É—â—É—é –∑–∞–¥–∞—á—É
            if current_task and current_content:
                task_companies = set()
                
                # –ò—â–µ–º –∫–æ–º–ø–∞–Ω–∏–∏ –≤ –∫–æ–Ω—Ç–µ–Ω—Ç–µ –∑–∞–¥–∞—á–∏
                for pattern in company_block_patterns:
                    task_blocks = re.findall(pattern, current_content, re.IGNORECASE | re.DOTALL)
                    for block in task_blocks:
                        companies_in_task = extract_companies_from_block(block)
                        task_companies.update(companies_in_task)
                
                result['tasks'].append({
                    'title': current_task,
                    'normalized_title': re.sub(r'^#+\s*', '', current_task).strip().lower(),
                    'companies': sorted(list(task_companies)),
                    'content_length': len(current_content),
                    'has_code': '```' in current_content
                })
            
            # –ù–∞—á–∏–Ω–∞–µ–º –Ω–æ–≤—É—é –∑–∞–¥–∞—á—É
            current_task = section.strip()
            current_content = ""
        else:
            current_content += section
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –∑–∞–¥–∞—á—É
    if current_task and current_content:
        task_companies = set()
        for pattern in company_block_patterns:
            task_blocks = re.findall(pattern, current_content, re.IGNORECASE | re.DOTALL)
            for block in task_blocks:
                companies_in_task = extract_companies_from_block(block)
                task_companies.update(companies_in_task)
        
        result['tasks'].append({
            'title': current_task,
            'normalized_title': re.sub(r'^#+\s*', '', current_task).strip().lower(),
            'companies': sorted(list(task_companies)),
            'content_length': len(current_content),
            'has_code': '```' in current_content
        })
    
    # 5. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    result['statistics'] = {
        'total_headers': len(result['all_headers']),
        'total_tasks': len(result['tasks']),
        'tasks_with_companies': len([t for t in result['tasks'] if t['companies']]),
        'total_companies': len(result['companies'])
    }
    
    return result

def analyze_all_md_files():
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤—Å–µ .md —Ñ–∞–π–ª—ã —Ç–æ–ª—å–∫–æ –≤ –ø–∞–ø–∫–∞—Ö js, react, ts –≤ –∫–æ—Ä–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞"""
    
    # –ü–∞–ø–∫–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    target_dirs = [
        os.path.join('..', 'js'),
        os.path.join('..', 'react'),
        os.path.join('..', 'ts'),
    ]
    
    md_files = []
    for target_dir in target_dirs:
        for root, dirs, files in os.walk(target_dir):
            for file in files:
                if file.endswith('.md'):
                    md_files.append(os.path.join(root, file))
    
    print(f"üîç –ù–∞–π–¥–µ–Ω–æ .md —Ñ–∞–π–ª–æ–≤: {len(md_files)} (—Ç–æ–ª—å–∫–æ –≤ js, react, ts)")
    print("=" * 80)
    
    all_results = []
    all_companies = set()
    all_tasks = []
    
    for file_path in md_files:
        print(f"\nüìÑ –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º: {file_path}")
        result = extract_all_from_md_file(file_path)
        
        if result['tasks'] or result['companies']:
            all_results.append(result)
            
            # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∫–æ–º–ø–∞–Ω–∏–∏
            all_companies.update(result['companies'])
            
            # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –∑–∞–¥–∞—á–∏
            all_tasks.extend(result['tasks'])
            
            # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Ñ–∞–π–ª—É
            stats = result['statistics']
            print(f"   üìä –ó–∞–≥–æ–ª–æ–≤–∫–æ–≤: {stats['total_headers']}")
            print(f"   üìã –ó–∞–¥–∞—á: {stats['total_tasks']}")
            print(f"   üè¢ –ó–∞–¥–∞—á —Å –∫–æ–º–ø–∞–Ω–∏—è–º–∏: {stats['tasks_with_companies']}")
            print(f"   üè™ –í—Å–µ–≥–æ –∫–æ–º–ø–∞–Ω–∏–π –≤ —Ñ–∞–π–ª–µ: {stats['total_companies']}")
            
            if result['companies']:
                print(f"   üìù –ö–æ–º–ø–∞–Ω–∏–∏: {', '.join(result['companies'][:5])}")
                if len(result['companies']) > 5:
                    print(f"       ... –∏ –µ—â–µ {len(result['companies']) - 5}")
    
    print("\n" + "=" * 80)
    print("üìà –û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
    print(f"   üìÑ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(all_results)}")
    print(f"   üìã –í—Å–µ–≥–æ –∑–∞–¥–∞—á: {len(all_tasks)}")
    print(f"   üè¢ –ó–∞–¥–∞—á —Å –∫–æ–º–ø–∞–Ω–∏—è–º–∏: {len([t for t in all_tasks if t['companies']])}")
    print(f"   üè™ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–æ–º–ø–∞–Ω–∏–π: {len(all_companies)}")
    
    print(f"\nüè¢ –í–°–ï –ù–ê–ô–î–ï–ù–ù–´–ï –ö–û–ú–ü–ê–ù–ò–ò ({len(all_companies)}):")
    sorted_companies = sorted(list(all_companies))
    for i, company in enumerate(sorted_companies, 1):
        print(f"   {i:3d}. {company}")
    
    print(f"\nüìã –ü–†–ò–ú–ï–†–´ –ó–ê–î–ê–ß –° –ö–û–ú–ü–ê–ù–ò–Ø–ú–ò:")
    tasks_with_companies = [t for t in all_tasks if t['companies']][:15]  # –ü–µ—Ä–≤—ã–µ 15
    for i, task in enumerate(tasks_with_companies, 1):
        companies_str = ', '.join(task['companies'][:3])  # –ü–µ—Ä–≤—ã–µ 3 –∫–æ–º–ø–∞–Ω–∏–∏
        if len(task['companies']) > 3:
            companies_str += f" (–∏ –µ—â–µ {len(task['companies']) - 3})"
        print(f"   {i:2d}. '{task['normalized_title']}' -> [{companies_str}]")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ JSON
    output_data = {
        'summary': {
            'total_files': len(all_results),
            'total_tasks': len(all_tasks),
            'tasks_with_companies': len([t for t in all_tasks if t['companies']]),
            'unique_companies': len(all_companies)
        },
        'all_companies': sorted(list(all_companies)),
        'all_tasks': all_tasks,
        'file_results': all_results
    }
    
    with open('extraction_results_improved.json', 'w', encoding='utf-8') as f:
        json.dump(output_data, f, ensure_ascii=False, indent=2)
    
    print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ 'extraction_results_improved.json'")
    
    return output_data

if __name__ == "__main__":
    analyze_all_md_files() 