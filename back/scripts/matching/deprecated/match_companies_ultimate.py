import re
import os
import sys
from difflib import SequenceMatcher

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..' )))

from app.database import get_db
from app.models import ContentBlock

def normalize_title_ultimate(title: str) -> str:
    """–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —Ç–æ—á–Ω–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤"""
    # –£–¥–∞–ª—è–µ–º markdown —Å—Å—ã–ª–∫–∏ [text](url) -> text  
    title = re.sub(r'\[([^\]]+)\]\([^)]+\)', r'\1', title)
    
    # –£–¥–∞–ª—è–µ–º –Ω–æ–º–µ—Ä–∞ –≤ –Ω–∞—á–∞–ª–µ: "1. title", "22. title" -> "title"
    title = re.sub(r'^\d+\.\s*', '', title)
    
    # –£–¥–∞–ª—è–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã markdown
    title = re.sub(r'[#\-\*\+\[\]`]', '', title)
    
    # –ü—Ä–∏–≤–æ–¥–∏–º –∫ lowercase –∏ —É–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
    title = re.sub(r'\s+', ' ', title.lower().strip())
    
    return title

def similarity(a: str, b: str) -> float:
    """–í—ã—á–∏—Å–ª—è–µ—Ç —Å—Ö–æ–∂–µ—Å—Ç—å —Å—Ç—Ä–æ–∫ –æ—Ç 0 –¥–æ 1"""
    return SequenceMatcher(None, a, b).ratio()

def extract_companies_comprehensive(text: str, context: str = "") -> list[str]:
    """–í—Å–µ—Å—Ç–æ—Ä–æ–Ω–Ω–∏–π –ø–∞—Ä—Å–∏–Ω–≥ –∫–æ–º–ø–∞–Ω–∏–π –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
    companies = []
    
    # –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –∫–æ–º–ø–∞–Ω–∏–π –¥–ª—è –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ–≥–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è
    KNOWN_COMPANIES = {
        '—è–Ω–¥–µ–∫—Å', '—Å–±–µ—Ä', '—Ç–∏–Ω–∫–æ—Ñ—Ñ', '–ª–µ–º–º–∞', 'wb', '–∏–Ω–Ω–æ—Ç–µ—Ö', '–æ—Ç–ø', '–≥–∞–∑–ø—Ä–æ–º', 
        'profsoft', 'altenar', 'it-one', '—Å–±–µ—Ä—Ç–µ—Ö', '–∞–ª—å—Ñ–∞', '–≤–∫', '–∞–≤—Ç–æ–º–∞–∫–æ–Ω', 
        '–º–æ–π—Å–∫–ª–∞–¥', '—Ü–µ–∑–∏–æ', 'qugo', 'ibs', '—Ä–æ—Å–±–∞–Ω–∫', '–æ–æ–æ –º–æ–±–∞–π–ª–¥–µ–≤–µ–ª–æ–ø–º–µ–Ω—Ç', 
        '—Å–∏–±—É—Ä', '–≥–∫ —Ç1', '–±–∏–ª–∞–π–Ω', 'kotelov', 'unisender', '–æ–∑–æ–Ω', '–ø–æ–ª–µ.—Ä—Ñ', 
        'artw', '–∞–≤–∏—Ç–æ', 'realweb', 'itfb', '–∫–∏–±–µ—Ä–ª–∞–±', 'portalbilet', 'marpla',
        '—Ä–æ—Å–≥–æ—Å—Å—Ç—Ä–∞—Ö', 'right line', 'quantum art', '–∞–ª–∞—Å–∫–∞—Ä —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏', '—Å–µ–ª–µ–∫—Ç–∏',
        '–∞–ª—Ñ–∞–±–∞–Ω–∫', '–ø—Ä–æ–º—Å–≤—è–∑—å–±–∞–Ω–∫', '—Å–±–µ—Ä–¥–µ–≤–∞–π—Å—ã', 'funbox', '—Ü—É–º', 'it baltic',
        'c–±–µ—Ä–∫–æ—Ä—É—Å', '—Ä—É—Ç—É–±', '–µ–≤—Ä–æ—Ç–µ—Ö–∫–ª–∏–º–∞—Ç', 'luxsoft', 'tilda', '–ø—Ä–æ–º—Å–≤—è–∑—å–±–∞–Ω–∫ (–ø—Å–±)',
        '–∞–Ω—Ç–∞—Ä–∞', '–≤—Ç–± —á–µ—Ä–µ–∑ –Ω–µ—Ç–±–µ–ª–ª –∞–∫—Ä –ª–∞–±—Å', 'sber autotech', '—Ñ–∏–Ω–∞–º',
        '–±–∞–ª–∞–Ω—Å –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞', '–ª–∞–± –∫–∞—Å–ø', '—è–Ω–¥–µ–∫—Å —Ç–∞–∫—Å–∏', 'click2money', 'kts',
        'premium it solution', 'moex', 'eesee', '–¥–æ–º.—Ä—Ñ', '–ª–∏–≥–∞ —Ü–∏—Ñ—Ä–æ–≤–æ–π —ç–∫–æ–Ω–æ–º–∏–∫–∏',
        '–≤–±', '—è–Ω–¥–µ–∫—Å –ø—Ä–æ', 'coding team', '—é—Ç—ç–∏—Ä', 'goinvest', '—Å–±–µ—Ä', 'yandex.pay',
        'yandex.multitrack', '–±–∞—É–º', '–∫–æ–∫–æ—Å.group', '–∏–ø —Å–≤–∏—Å—Ç—É–Ω–æ–≤–∞ –µ–∫–∞—Ç–µ—Ä–∏–Ω–∞ –∞–ª–µ–∫—Å–∞–Ω–¥—Ä–æ–≤–Ω–∞ (—Å–±–µ—Ä)',
        '—Å–∫–≤–∞–¥ (squad)', '—Ç–æ—á–∫–∞ –±–∞–Ω–∫', 'strahovaya kompaniya puls', 'vision', 'itq group (proekt mkb)',
        'sbertech', '–æ–Ω–ª–∞–π–Ω —à–∫–æ–ª–∞ —Ç–µ—Ç—Ä–∏–∫–∞', '—Å—Ñ–µ—Ä–∞', 'yandex', 'mail.ru group', 'kaspersky', '—Ä–∞–π—Ñ–∞–π–∑–µ–Ω'
    }
    
    # 1. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–∑ –±–ª–æ–∫–æ–≤ "–≤—Å—Ç—Ä–µ—á–∞–ª–æ—Å—å –≤" —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º –ø–∞—Ä—Å–∏–Ω–≥–æ–º
    company_blocks = re.findall(
        r'–≤—Å—Ç—Ä–µ—á–∞–ª[–∞–æ—Å—å]+ –≤.*?(?=\n\S|\n#+|\n```|\Z)', 
        text, 
        re.IGNORECASE | re.DOTALL
    )
    
    for block in company_blocks:
        lines = block.split('\n')
        for line in lines[1:]:  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É "–≤—Å—Ç—Ä–µ—á–∞–ª–æ—Å—å –≤"
            # –£–±–∏—Ä–∞–µ–º —Ç–∞–±—É–ª—è—Ü–∏—é –∏ –ø—Ä–æ–±–µ–ª—ã –≤ –Ω–∞—á–∞–ª–µ
            cleaned_line = re.sub(r'^[\t\s]*-\s*', '', line).strip()
            if cleaned_line and len(cleaned_line) > 1:
                # –§–∏–ª—å—Ç—Ä—É–µ–º –º—É—Å–æ—Ä –∏ –¥–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –∏–∑–≤–µ—Å—Ç–Ω—ã–µ –∫–æ–º–ø–∞–Ω–∏–∏
                normalized_company = cleaned_line.lower()
                # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
                normalized_company = normalized_company.replace('(–Ω–µ–ª—å–∑—è –∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å –º–∞—Å—Å–∏–≤, —Ç–æ –µ—Å—Ç—å inplace)', '').strip()
                normalized_company = normalized_company.replace('(–±–µ–∑ set, —Å–∫–∞–∑–∞—Ç—å —Å–ª–æ–∂–Ω–æ—Å—Ç—å, –±—É–¥–µ—Ç –ª–∏ set —Ä–∞–±–æ—Ç–∞—Ç—å —Å –æ–±—ä–µ–∫—Ç–∞–º–∏)', '').strip()
                normalized_company = normalized_company.replace('(–ø—Ä–æ–µ–∫—Ç –º—Ç—Å)', '').strip()
                normalized_company = normalized_company.replace('(platform v ui kits)', '').strip()
                normalized_company = normalized_company.replace('(–ø—Å–±)', '').strip()
                normalized_company = normalized_company.replace('(–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ o(1))', '').strip()
                normalized_company = normalized_company.replace('(–ø—Ä–æ–µ–∫—Ç –º–∫–±)', '').strip()
                normalized_company = normalized_company.replace('—á–µ—Ä–µ–∑ –Ω–µ—Ç–±–µ–ª–ª –∞–∫—Ä –ª–∞–±—Å', '').strip()
                normalized_company = normalized_company.replace('–¥–ª—è —ç–∫—Å–ø–µ—Ä—Ç–æ–≤', '').strip()
                normalized_company = normalized_company.replace('—Å–≤–∏—Å—Ç—É–Ω–æ–≤–∞ –µ–∫–∞—Ç–µ—Ä–∏–Ω–∞ –∞–ª–µ–∫—Å–∞–Ω–¥—Ä–æ–≤–Ω–∞', '').strip()
                normalized_company = normalized_company.replace('–≥—Ä—É–ø–ø', '').strip()
                normalized_company = normalized_company.replace('auto tech', 'autotech').strip()
                
                if normalized_company in KNOWN_COMPANIES or \
                   any(comp in normalized_company for comp in KNOWN_COMPANIES): # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Ö–æ–∂–¥–µ–Ω–∏–µ
                    companies.append(normalized_company)
    
    # 2. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ–º–ø–∞–Ω–∏–π –∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ (# –∫–æ–º–ø–∞–Ω–∏—è)
    header_companies = re.findall(r'^#{1,3}\s*([^#\n]+)$', text, re.MULTILINE)
    
    for company in header_companies:
        company_text = company.strip().lower()
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–¥–µ—Ä–∂–∏—Ç—Å—è –ª–∏ –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–æ–º–ø–∞–Ω–∏–∏ –∏–∑ KNOWN_COMPANIES –≤ –∑–∞–≥–æ–ª–æ–≤–∫–µ
        for known_company in KNOWN_COMPANIES:
            if known_company in company_text and len(known_company) > 1 and \
               not re.match(r'(–∑–∞–¥–∞—á|example|–ø—Ä–∏–º–µ—Ä|counter|todo|—Å–ø–∏—Å–∫–∏|—Ä–µ—Ñ–∞–∫—Ç–æ—Ä|—Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ|other|use|module)', company_text, re.IGNORECASE):
                companies.append(known_company)
    
    # 3. –ß–∏—Å—Ç–∫–∞ –∏ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è
    cleaned_companies = []
    for company in companies:
        company = company.strip().replace(' ', '') # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã –¥–ª—è –ª—É—á—à–µ–π –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏
        if company and company not in cleaned_companies:
            cleaned_companies.append(company)
    
    return cleaned_companies

def parse_md_file_advanced(file_path: str) -> dict:
    """–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –ø–∞—Ä—Å–∏–Ω–≥ .md —Ñ–∞–π–ª–∞ —Å –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ–º –∑–∞–¥–∞—á –∏ –∫–æ–º–ø–∞–Ω–∏–π"""
    if not os.path.exists(file_path):
        return {}
    
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    tasks = {}
    
    # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —Å–µ–∫—Ü–∏–∏ –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º
    sections = re.split(r'(^#{1,4}\s+.+)$', content, flags=re.MULTILINE)
    
    current_title = None
    current_content = ""
    
    for section in sections:
        if re.match(r'^#{1,4}\s+', section):
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–µ–¥—ã–¥—É—â—É—é —Å–µ–∫—Ü–∏—é
            if current_title and current_content:
                normalized_title = normalize_title_ultimate(current_title)
                companies = extract_companies_comprehensive(current_content, file_path)
                
                if normalized_title and (companies or len(current_content) > 50):
                    tasks[normalized_title] = {
                        'original_title': current_title,
                        'companies': companies,
                        'content': current_content[:500]  # –ü–µ—Ä–≤—ã–µ 500 —Å–∏–º–≤–æ–ª–æ–≤ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
                    }
            
            # –ù–∞—á–∏–Ω–∞–µ–º –Ω–æ–≤—É—é —Å–µ–∫—Ü–∏—é
            current_title = re.sub(r'^#+\s*', '', section).strip()
            current_content = ""
        else:
            current_content += section
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Å–µ–∫—Ü–∏—é
    if current_title and current_content:
        normalized_title = normalize_title_ultimate(current_title)
        companies = extract_companies_comprehensive(current_content, file_path)
        
        if normalized_title and (companies or len(current_content) > 50):
            tasks[normalized_title] = {
                'original_title': current_title,
                'companies': companies,
                'content': current_content[:500]
            }
    
    return tasks

def match_and_update_ultimate():
    """–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —Ç–æ—á–Ω–æ–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ"""
    
    # –ü—É—Ç—å –∫ .md —Ñ–∞–π–ª–∞–º
    md_files = [
        '../react/–†–µ–∞–∫—Ç –ú–∏–Ω–∏ –ê–ø–ø.md',
        '../react/–†–µ–∞–∫—Ç –†–µ—Ä–µ–Ω–¥–µ—Ä.md', 
        '../react/–†–µ–∞–∫—Ç –†–µ—Ñ–∞–∫—Ç–æ—Ä.md',
        '../react/–†–µ–∞–∫—Ç –•—É–∫–∏.md',
        '../js/–û—Å–Ω–æ–≤–Ω—ã–µ –∑–∞–¥–∞—á–∏/–º–∞—Å—Å–∏–≤—ã.md',
        '../js/–û—Å–Ω–æ–≤–Ω—ã–µ –∑–∞–¥–∞—á–∏/–ø—Ä–æ–º–∏—Å—ã.md',
        '../js/–û—Å–Ω–æ–≤–Ω—ã–µ –∑–∞–¥–∞—á–∏/—Å—Ç—Ä–æ–∫–∏.md',
        '../js/–û—Å–Ω–æ–≤–Ω—ã–µ –∑–∞–¥–∞—á–∏/—á–∏—Å–ª–∞.md'
    ]
    
    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –∑–∞–¥–∞—á–∏ –∏–∑ .md —Ñ–∞–π–ª–æ–≤
    all_md_tasks = {}
    
    print("üîç –ü–∞—Ä—Å–∏–Ω–≥ .md —Ñ–∞–π–ª–æ–≤...")
    for file_path in md_files:
        if os.path.exists(file_path):
            print(f"  üìÑ {file_path}")
            tasks = parse_md_file_advanced(file_path)
            all_md_tasks.update(tasks)
            print(f"     –ù–∞–π–¥–µ–Ω–æ –∑–∞–¥–∞—á: {len(tasks)}")
    
    print(f"\nüìä –í—Å–µ–≥–æ –∑–∞–¥–∞—á –≤ .md —Ñ–∞–π–ª–∞—Ö: {len(all_md_tasks)}")
    
    # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ –ë–î
    db = next(get_db())
    
    try:
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∑–∞–¥–∞—á–∏ –∏–∑ –ë–î
        db_tasks = db.query(ContentBlock).all()
        print(f"üìä –í—Å–µ–≥–æ –∑–∞–¥–∞—á –≤ –ë–î: {len(db_tasks)}")
        
        matched_count = 0
        company_updates = 0
        
        print("\nüîó –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –∑–∞–¥–∞—á...")
        
        for db_task in db_tasks:
            if not db_task.blockTitle:
                continue
                
            normalized_db_title = normalize_title_ultimate(db_task.blockTitle)
            best_match = None
            best_score = 0
            
            # –ò—â–µ–º –ª—É—á—à–µ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
            for md_title, md_data in all_md_tasks.items():
                score = similarity(normalized_db_title, md_title)
                
                # –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
                if score >= 0.9:
                    best_match = md_data
                    best_score = score
                    break
                # –ß–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
                elif score > best_score and score >= 0.7:
                    best_match = md_data
                    best_score = score
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –æ–¥–Ω–æ–≥–æ –≤ –¥—Ä—É–≥–æ–º
                elif (md_title in normalized_db_title or 
                      normalized_db_title in md_title) and score >= 0.5:
                    best_match = md_data
                    best_score = score
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–º–ø–∞–Ω–∏–∏ –µ—Å–ª–∏ –Ω–∞—à–ª–∏ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
            if best_match and best_match['companies']:
                # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –∏ –æ—á–∏—â–∞–µ–º –∫–æ–º–ø–∞–Ω–∏–∏
                unique_companies = []
                for company in best_match['companies']:
                    if company not in unique_companies:
                        unique_companies.append(company)
                
                db_task.companies = unique_companies
                company_updates += 1
                matched_count += 1
                
                print(f"  ‚úÖ '{db_task.blockTitle}' -> {unique_companies} (score: {best_score:.2f})")
            
            elif best_match:
                matched_count += 1
                print(f"  üìù '{db_task.blockTitle}' -> —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∞, –Ω–æ –±–µ–∑ –∫–æ–º–ø–∞–Ω–∏–π (score: {best_score:.2f})")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è
        if company_updates > 0:
            db.commit()
            print(f"\nüíæ –û–±–Ω–æ–≤–ª–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π –≤ –ë–î: {company_updates}")
        else:
            print("\n‚ö†Ô∏è –ù–µ—Ç –∑–∞–ø–∏—Å–µ–π –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è")
        
        print(f"\nüìà –ò–¢–û–ì–ò:")
        print(f"   üéØ –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–æ –∑–∞–¥–∞—á: {matched_count}/{len(db_tasks)}")
        print(f"   üè¢ –ó–∞–¥–∞—á —Å –∫–æ–º–ø–∞–Ω–∏—è–º–∏: {company_updates}")
        print(f"   üìä –ü—Ä–æ—Ü–µ–Ω—Ç –ø–æ–∫—Ä—ã—Ç–∏—è: {(company_updates/len(db_tasks)*100):.1f}%")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        db.rollback()
    finally:
        db.close()

if __name__ == "__main__":
    match_and_update_ultimate() 