import re
import os
import sys
from difflib import SequenceMatcher

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..' )))

from app.database import get_db
from app.models import ContentBlock

def normalize_title_ultimate(title: str) -> str:
    """ĞœĞ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾ Ñ‚Ğ¾Ñ‡Ğ½Ğ°Ñ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²ĞºĞ¾Ğ²"""
    # Ğ£Ğ´Ğ°Ğ»ÑĞµĞ¼ markdown ÑÑÑ‹Ğ»ĞºĞ¸ [text](url) -> text  
    title = re.sub(r'\[([^\]]+)\]\([^)]+\)', r'\1', title)
    
    # Ğ£Ğ´Ğ°Ğ»ÑĞµĞ¼ Ğ½Ğ¾Ğ¼ĞµÑ€Ğ° Ğ² Ğ½Ğ°Ñ‡Ğ°Ğ»Ğµ: "1. title", "22. title" -> "title"
    title = re.sub(r'^\d+\.\s*', '', title)
    
    # Ğ£Ğ´Ğ°Ğ»ÑĞµĞ¼ ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ñ‹ markdown
    title = re.sub(r'[#\-\*\+\[\]`]', '', title)
    
    # ĞŸÑ€Ğ¸Ğ²Ğ¾Ğ´Ğ¸Ğ¼ Ğº lowercase Ğ¸ ÑƒĞ±Ğ¸Ñ€Ğ°ĞµĞ¼ Ğ»Ğ¸ÑˆĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ğ±ĞµĞ»Ñ‹
    title = re.sub(r'\s+', ' ', title.lower().strip())
    
    return title

def similarity(a: str, b: str) -> float:
    """Ğ’Ñ‹Ñ‡Ğ¸ÑĞ»ÑĞµÑ‚ ÑÑ…Ğ¾Ğ¶ĞµÑÑ‚ÑŒ ÑÑ‚Ñ€Ğ¾Ğº Ğ¾Ñ‚ 0 Ğ´Ğ¾ 1"""
    return SequenceMatcher(None, a, b).ratio()

def extract_companies_comprehensive(text: str, context: str = "") -> list[str]:
    """Ğ’ÑĞµÑÑ‚Ğ¾Ñ€Ğ¾Ğ½Ğ½Ğ¸Ğ¹ Ğ¿Ğ°Ñ€ÑĞ¸Ğ½Ğ³ ĞºĞ¾Ğ¼Ğ¿Ğ°Ğ½Ğ¸Ğ¹ Ğ¸Ğ· Ñ‚ĞµĞºÑÑ‚Ğ°"""
    companies = []
    
    # ĞŸÑ€ĞµĞ´Ğ²Ğ°Ñ€Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ¸Ğ·Ğ²ĞµÑÑ‚Ğ½Ñ‹Ñ… ĞºĞ¾Ğ¼Ğ¿Ğ°Ğ½Ğ¸Ğ¹ Ğ´Ğ»Ñ Ğ±Ğ¾Ğ»ĞµĞµ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾Ğ³Ğ¾ Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ñ
    KNOWN_COMPANIES = {
        'ÑĞ½Ğ´ĞµĞºÑ', 'ÑĞ±ĞµÑ€', 'Ñ‚Ğ¸Ğ½ĞºĞ¾Ñ„Ñ„', 'Ğ»ĞµĞ¼Ğ¼Ğ°', 'wb', 'Ğ¸Ğ½Ğ½Ğ¾Ñ‚ĞµÑ…', 'Ğ¾Ñ‚Ğ¿', 'Ğ³Ğ°Ğ·Ğ¿Ñ€Ğ¾Ğ¼', 
        'profsoft', 'altenar', 'it-one', 'ÑĞ±ĞµÑ€Ñ‚ĞµÑ…', 'Ğ°Ğ»ÑŒÑ„Ğ°', 'Ğ²Ğº', 'Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°ĞºĞ¾Ğ½', 
        'Ğ¼Ğ¾Ğ¹ÑĞºĞ»Ğ°Ğ´', 'Ñ†ĞµĞ·Ğ¸Ğ¾', 'qugo', 'ibs', 'Ñ€Ğ¾ÑĞ±Ğ°Ğ½Ğº', 'Ğ¾Ğ¾Ğ¾ Ğ¼Ğ¾Ğ±Ğ°Ğ¹Ğ»Ğ´ĞµĞ²ĞµĞ»Ğ¾Ğ¿Ğ¼ĞµĞ½Ñ‚', 
        'ÑĞ¸Ğ±ÑƒÑ€', 'Ğ³Ğº Ñ‚1', 'Ğ±Ğ¸Ğ»Ğ°Ğ¹Ğ½', 'kotelov', 'unisender', 'Ğ¾Ğ·Ğ¾Ğ½', 'Ğ¿Ğ¾Ğ»Ğµ.Ñ€Ñ„', 
        'artw', 'Ğ°Ğ²Ğ¸Ñ‚Ğ¾', 'realweb', 'itfb', 'ĞºĞ¸Ğ±ĞµÑ€Ğ»Ğ°Ğ±', 'portalbilet', 'marpla',
        'Ñ€Ğ¾ÑĞ³Ğ¾ÑÑÑ‚Ñ€Ğ°Ñ…', 'right line', 'quantum art', 'Ğ°Ğ»Ğ°ÑĞºĞ°Ñ€ Ñ‚ĞµÑ…Ğ½Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ğ¸', 'ÑĞµĞ»ĞµĞºÑ‚Ğ¸',
        'Ğ°Ğ»Ñ„Ğ°Ğ±Ğ°Ğ½Ğº', 'Ğ¿Ñ€Ğ¾Ğ¼ÑĞ²ÑĞ·ÑŒĞ±Ğ°Ğ½Ğº', 'ÑĞ±ĞµÑ€Ğ´ĞµĞ²Ğ°Ğ¹ÑÑ‹', 'funbox', 'Ñ†ÑƒĞ¼', 'it baltic',
        'cĞ±ĞµÑ€ĞºĞ¾Ñ€ÑƒÑ', 'Ñ€ÑƒÑ‚ÑƒĞ±', 'ĞµĞ²Ñ€Ğ¾Ñ‚ĞµÑ…ĞºĞ»Ğ¸Ğ¼Ğ°Ñ‚', 'luxsoft', 'tilda', 'Ğ¿Ñ€Ğ¾Ğ¼ÑĞ²ÑĞ·ÑŒĞ±Ğ°Ğ½Ğº (Ğ¿ÑĞ±)',
        'Ğ°Ğ½Ñ‚Ğ°Ñ€Ğ°', 'Ğ²Ñ‚Ğ± Ñ‡ĞµÑ€ĞµĞ· Ğ½ĞµÑ‚Ğ±ĞµĞ»Ğ» Ğ°ĞºÑ€ Ğ»Ğ°Ğ±Ñ', 'sber autotech', 'Ñ„Ğ¸Ğ½Ğ°Ğ¼',
        'Ğ±Ğ°Ğ»Ğ°Ğ½Ñ Ğ¿Ğ»Ğ°Ñ‚Ñ„Ğ¾Ñ€Ğ¼Ğ°', 'Ğ»Ğ°Ğ± ĞºĞ°ÑĞ¿', 'ÑĞ½Ğ´ĞµĞºÑ Ñ‚Ğ°ĞºÑĞ¸', 'click2money', 'kts',
        'premium it solution', 'moex', 'eesee', 'Ğ´Ğ¾Ğ¼.Ñ€Ñ„', 'Ğ»Ğ¸Ğ³Ğ° Ñ†Ğ¸Ñ„Ñ€Ğ¾Ğ²Ğ¾Ğ¹ ÑĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸ĞºĞ¸',
        'Ğ²Ğ±', 'ÑĞ½Ğ´ĞµĞºÑ Ğ¿Ñ€Ğ¾', 'coding team', 'ÑÑ‚ÑĞ¸Ñ€', 'goinvest', 'ÑĞ±ĞµÑ€', 'yandex.pay',
        'yandex.multitrack', 'Ğ±Ğ°ÑƒĞ¼', 'ĞºĞ¾ĞºĞ¾Ñ.group', 'Ğ¸Ğ¿ ÑĞ²Ğ¸ÑÑ‚ÑƒĞ½Ğ¾Ğ²Ğ° ĞµĞºĞ°Ñ‚ĞµÑ€Ğ¸Ğ½Ğ° Ğ°Ğ»ĞµĞºÑĞ°Ğ½Ğ´Ñ€Ğ¾Ğ²Ğ½Ğ° (ÑĞ±ĞµÑ€)',
        'ÑĞºĞ²Ğ°Ğ´ (squad)', 'Ñ‚Ğ¾Ñ‡ĞºĞ° Ğ±Ğ°Ğ½Ğº', 'strahovaya kompaniya puls', 'vision', 'itq group (proekt mkb)',
        'sbertech', 'Ğ¾Ğ½Ğ»Ğ°Ğ¹Ğ½ ÑˆĞºĞ¾Ğ»Ğ° Ñ‚ĞµÑ‚Ñ€Ğ¸ĞºĞ°', 'ÑÑ„ĞµÑ€Ğ°', 'yandex', 'mail.ru group', 'kaspersky', 'Ñ€Ğ°Ğ¹Ñ„Ğ°Ğ¹Ğ·ĞµĞ½'
    }
    
    # 1. Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ğµ Ğ¸Ğ· Ğ±Ğ»Ğ¾ĞºĞ¾Ğ² "Ğ²ÑÑ‚Ñ€ĞµÑ‡Ğ°Ğ»Ğ¾ÑÑŒ Ğ²" Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ½Ñ‹Ğ¼ Ğ¿Ğ°Ñ€ÑĞ¸Ğ½Ğ³Ğ¾Ğ¼
    company_blocks = re.findall(
        r'Ğ²ÑÑ‚Ñ€ĞµÑ‡Ğ°Ğ»[Ğ°Ğ¾ÑÑŒ]+ Ğ².*?(?=\n\S|\n#+|\n```|\Z)', 
        text, 
        re.IGNORECASE | re.DOTALL
    )
    
    for block in company_blocks:
        lines = block.split('\n')
        for line in lines[1:]:  # ĞŸÑ€Ğ¾Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ Ğ¿ĞµÑ€Ğ²ÑƒÑ ÑÑ‚Ñ€Ğ¾ĞºÑƒ "Ğ²ÑÑ‚Ñ€ĞµÑ‡Ğ°Ğ»Ğ¾ÑÑŒ Ğ²"
            # Ğ£Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ Ñ‚Ğ°Ğ±ÑƒĞ»ÑÑ†Ğ¸Ñ Ğ¸ Ğ¿Ñ€Ğ¾Ğ±ĞµĞ»Ñ‹ Ğ² Ğ½Ğ°Ñ‡Ğ°Ğ»Ğµ
            cleaned_line = re.sub(r'^[\t\s]*-\s*', '', line).strip()
            if cleaned_line and len(cleaned_line) > 1:
                # Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€ÑƒĞµĞ¼ Ğ¼ÑƒÑĞ¾Ñ€ Ğ¸ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¸Ğ·Ğ²ĞµÑÑ‚Ğ½Ñ‹Ğµ ĞºĞ¾Ğ¼Ğ¿Ğ°Ğ½Ğ¸Ğ¸
                normalized_company = cleaned_line.lower()
                # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ´Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸
                normalized_company = normalized_company.replace('(Ğ½ĞµĞ»ÑŒĞ·Ñ ĞºĞ¾Ğ¿Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¼Ğ°ÑÑĞ¸Ğ², Ñ‚Ğ¾ ĞµÑÑ‚ÑŒ inplace)', '').strip()
                normalized_company = normalized_company.replace('(Ğ±ĞµĞ· set, ÑĞºĞ°Ğ·Ğ°Ñ‚ÑŒ ÑĞ»Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ, Ğ±ÑƒĞ´ĞµÑ‚ Ğ»Ğ¸ set Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ñ‚ÑŒ Ñ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ°Ğ¼Ğ¸)', '').strip()
                normalized_company = normalized_company.replace('(Ğ¿Ñ€Ğ¾ĞµĞºÑ‚ Ğ¼Ñ‚Ñ)', '').strip()
                normalized_company = normalized_company.replace('(platform v ui kits)', '').strip()
                normalized_company = normalized_company.replace('(Ğ¿ÑĞ±)', '').strip()
                normalized_company = normalized_company.replace('(Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ğµ o(1))', '').strip()
                normalized_company = normalized_company.replace('(Ğ¿Ñ€Ğ¾ĞµĞºÑ‚ Ğ¼ĞºĞ±)', '').strip()
                normalized_company = normalized_company.replace('Ñ‡ĞµÑ€ĞµĞ· Ğ½ĞµÑ‚Ğ±ĞµĞ»Ğ» Ğ°ĞºÑ€ Ğ»Ğ°Ğ±Ñ', '').strip()
                normalized_company = normalized_company.replace('Ğ´Ğ»Ñ ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğ¾Ğ²', '').strip()
                normalized_company = normalized_company.replace('ÑĞ²Ğ¸ÑÑ‚ÑƒĞ½Ğ¾Ğ²Ğ° ĞµĞºĞ°Ñ‚ĞµÑ€Ğ¸Ğ½Ğ° Ğ°Ğ»ĞµĞºÑĞ°Ğ½Ğ´Ñ€Ğ¾Ğ²Ğ½Ğ°', '').strip()
                normalized_company = normalized_company.replace('Ğ³Ñ€ÑƒĞ¿Ğ¿', '').strip()
                normalized_company = normalized_company.replace('auto tech', 'autotech').strip()
                
                if normalized_company in KNOWN_COMPANIES or \
                   any(comp in normalized_company for comp in KNOWN_COMPANIES): # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ²Ñ…Ğ¾Ğ¶Ğ´ĞµĞ½Ğ¸Ğµ
                    companies.append(normalized_company)
    
    # 2. Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ğµ ĞºĞ¾Ğ¼Ğ¿Ğ°Ğ½Ğ¸Ğ¹ Ğ¸Ğ· Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²ĞºĞ¾Ğ² (# ĞºĞ¾Ğ¼Ğ¿Ğ°Ğ½Ğ¸Ñ)
    header_companies = re.findall(r'^#{1,3}\s*([^#\n]+)$', text, re.MULTILINE)
    
    for company in header_companies:
        company_text = company.strip().lower()
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼, ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ÑÑ Ğ»Ğ¸ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ ĞºĞ¾Ğ¼Ğ¿Ğ°Ğ½Ğ¸Ğ¸ Ğ¸Ğ· KNOWN_COMPANIES Ğ² Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²ĞºĞµ
        for known_company in KNOWN_COMPANIES:
            if known_company in company_text and len(known_company) > 1 and \
               not re.match(r'(Ğ·Ğ°Ğ´Ğ°Ñ‡|example|Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€|counter|todo|ÑĞ¿Ğ¸ÑĞºĞ¸|Ñ€ĞµÑ„Ğ°ĞºÑ‚Ğ¾Ñ€|Ñ‚Ñ€ĞµĞ½Ğ¸Ñ€Ğ¾Ğ²Ğ¾Ñ‡Ğ½Ñ‹Ğµ|other|use|module)', company_text, re.IGNORECASE):
                companies.append(known_company)
    
    # 3. Ğ§Ğ¸ÑÑ‚ĞºĞ° Ğ¸ Ğ´ĞµĞ´ÑƒĞ¿Ğ»Ğ¸ĞºĞ°Ñ†Ğ¸Ñ
    cleaned_companies = []
    for company in companies:
        company = company.strip().replace(' ', '') # Ğ£Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ Ğ¿Ñ€Ğ¾Ğ±ĞµĞ»Ñ‹ Ğ´Ğ»Ñ Ğ»ÑƒÑ‡ÑˆĞµĞ¹ Ğ´ĞµĞ´ÑƒĞ¿Ğ»Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸
        if company and company not in cleaned_companies:
            cleaned_companies.append(company)
    
    return cleaned_companies

def parse_md_file_advanced(file_path: str) -> dict:
    """ĞŸÑ€Ğ¾Ğ´Ğ²Ğ¸Ğ½ÑƒÑ‚Ñ‹Ğ¹ Ğ¿Ğ°Ñ€ÑĞ¸Ğ½Ğ³ .md Ñ„Ğ°Ğ¹Ğ»Ğ° Ñ Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸ĞµĞ¼ Ğ·Ğ°Ğ´Ğ°Ñ‡ Ğ¸ ĞºĞ¾Ğ¼Ğ¿Ğ°Ğ½Ğ¸Ğ¹"""
    if not os.path.exists(file_path):
        return {}
    
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    tasks = {}
    
    # Ğ Ğ°Ğ·Ğ±Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ½Ğ° ÑĞµĞºÑ†Ğ¸Ğ¸ Ğ¿Ğ¾ Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²ĞºĞ°Ğ¼
    sections = re.split(r'(^#{1,4}\s+.+)$', content, flags=re.MULTILINE)
    
    current_title = None
    current_content = ""
    
    for section in sections:
        if re.match(r'^#{1,4}\s+', section):
            # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰ÑƒÑ ÑĞµĞºÑ†Ğ¸Ñ
            if current_title and current_content:
                normalized_title = normalize_title_ultimate(current_title)
                companies = extract_companies_comprehensive(current_content, file_path)
                
                if normalized_title and (companies or len(current_content) > 50):
                    tasks[normalized_title] = {
                        'original_title': current_title,
                        'companies': companies,
                        'content': current_content[:500]  # ĞŸĞµÑ€Ğ²Ñ‹Ğµ 500 ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ² Ğ´Ğ»Ñ Ğ¾Ñ‚Ğ»Ğ°Ğ´ĞºĞ¸
                    }
            
            # ĞĞ°Ñ‡Ğ¸Ğ½Ğ°ĞµĞ¼ Ğ½Ğ¾Ğ²ÑƒÑ ÑĞµĞºÑ†Ğ¸Ñ
            current_title = re.sub(r'^#+\s*', '', section).strip()
            current_content = ""
        else:
            current_content += section
    
    # ĞĞ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ÑÑ ÑĞµĞºÑ†Ğ¸Ñ
    if current_title and current_content:
        normalized_title = normalize_title_ultimate(current_title)
        companies = extract_companies_comprehensive(current_content, file_path)
        
        if normalized_title and (companies or len(current_content) > 50):
            tasks[normalized_title] = {
                'original_title': current_title,
                'companies': companies,
                'content': current_content[:500]
            }
    
    return tasks

def match_and_update_ultimate():
    """ĞœĞ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾Ğµ ÑĞ¾Ğ¿Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ¸ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ"""
    
    # ĞŸÑƒÑ‚ÑŒ Ğº .md Ñ„Ğ°Ğ¹Ğ»Ğ°Ğ¼
    md_files = [
        '../react/Ğ ĞµĞ°ĞºÑ‚ ĞœĞ¸Ğ½Ğ¸ ĞĞ¿Ğ¿.md',
        '../react/Ğ ĞµĞ°ĞºÑ‚ Ğ ĞµÑ€ĞµĞ½Ğ´ĞµÑ€.md', 
        '../react/Ğ ĞµĞ°ĞºÑ‚ Ğ ĞµÑ„Ğ°ĞºÑ‚Ğ¾Ñ€.md',
        '../react/Ğ ĞµĞ°ĞºÑ‚ Ğ¥ÑƒĞºĞ¸.md',
        '../js/ĞÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ğµ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸/Ğ¼Ğ°ÑÑĞ¸Ğ²Ñ‹.md',
        '../js/ĞÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ğµ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸/Ğ¿Ñ€Ğ¾Ğ¼Ğ¸ÑÑ‹.md',
        '../js/ĞÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ğµ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸/ÑÑ‚Ñ€Ğ¾ĞºĞ¸.md',
        '../js/ĞÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ğµ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸/Ñ‡Ğ¸ÑĞ»Ğ°.md'
    ]
    
    # Ğ¡Ğ¾Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ Ğ²ÑĞµ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ Ğ¸Ğ· .md Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²
    all_md_tasks = {}
    
    print("ğŸ” ĞŸĞ°Ñ€ÑĞ¸Ğ½Ğ³ .md Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²...")
    for file_path in md_files:
        if os.path.exists(file_path):
            print(f"  ğŸ“„ {file_path}")
            tasks = parse_md_file_advanced(file_path)
            all_md_tasks.update(tasks)
            print(f"     ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾ Ğ·Ğ°Ğ´Ğ°Ñ‡: {len(tasks)}")
    
    print(f"\nğŸ“Š Ğ’ÑĞµĞ³Ğ¾ Ğ·Ğ°Ğ´Ğ°Ñ‡ Ğ² .md Ñ„Ğ°Ğ¹Ğ»Ğ°Ñ…: {len(all_md_tasks)}")
    
    # ĞŸĞ¾Ğ´ĞºĞ»ÑÑ‡Ğ°ĞµĞ¼ÑÑ Ğº Ğ‘Ğ”
    db = next(get_db())
    
    try:
        # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ğ²ÑĞµ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ Ğ¸Ğ· Ğ‘Ğ”
        db_tasks = db.query(ContentBlock).all()
        print(f"ğŸ“Š Ğ’ÑĞµĞ³Ğ¾ Ğ·Ğ°Ğ´Ğ°Ñ‡ Ğ² Ğ‘Ğ”: {len(db_tasks)}")
        
        matched_count = 0
        company_updates = 0
        
        print("\nğŸ”— Ğ¡Ğ¾Ğ¿Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ·Ğ°Ğ´Ğ°Ñ‡...")
        
        for db_task in db_tasks:
            if not db_task.blockTitle:
                continue
                
            normalized_db_title = normalize_title_ultimate(db_task.blockTitle)
            best_match = None
            best_score = 0
            
            # Ğ˜Ñ‰ĞµĞ¼ Ğ»ÑƒÑ‡ÑˆĞµĞµ ÑĞ¾Ğ²Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ğµ
            for md_title, md_data in all_md_tasks.items():
                score = similarity(normalized_db_title, md_title)
                
                # Ğ¢Ğ¾Ñ‡Ğ½Ğ¾Ğµ ÑĞ¾Ğ²Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ğµ
                if score >= 0.9:
                    best_match = md_data
                    best_score = score
                    break
                # Ğ§Ğ°ÑÑ‚Ğ¸Ñ‡Ğ½Ğ¾Ğµ ÑĞ¾Ğ²Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ğµ
                elif score > best_score and score >= 0.7:
                    best_match = md_data
                    best_score = score
                # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ½Ğ° ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ°Ğ½Ğ¸Ğµ Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ Ğ² Ğ´Ñ€ÑƒĞ³Ğ¾Ğ¼
                elif (md_title in normalized_db_title or 
                      normalized_db_title in md_title) and score >= 0.5:
                    best_match = md_data
                    best_score = score
            
            # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ ĞºĞ¾Ğ¼Ğ¿Ğ°Ğ½Ğ¸Ğ¸ ĞµÑĞ»Ğ¸ Ğ½Ğ°ÑˆĞ»Ğ¸ ÑĞ¾Ğ²Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ğµ
            if best_match and best_match['companies']:
                # Ğ£Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ Ğ´ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ‚Ñ‹ Ğ¸ Ğ¾Ñ‡Ğ¸Ñ‰Ğ°ĞµĞ¼ ĞºĞ¾Ğ¼Ğ¿Ğ°Ğ½Ğ¸Ğ¸
                unique_companies = []
                for company in best_match['companies']:
                    if company not in unique_companies:
                        unique_companies.append(company)
                
                db_task.companies = unique_companies
                company_updates += 1
                matched_count += 1
                
                print(f"  âœ… '{db_task.blockTitle}' -> {unique_companies} (score: {best_score:.2f})")
            
            elif best_match:
                matched_count += 1
                print(f"  ğŸ“ '{db_task.blockTitle}' -> ÑĞ¾Ğ¿Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ°, Ğ½Ğ¾ Ğ±ĞµĞ· ĞºĞ¾Ğ¼Ğ¿Ğ°Ğ½Ğ¸Ğ¹ (score: {best_score:.2f})")
        
        # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ
        if company_updates > 0:
            db.commit()
            print(f"\nğŸ’¾ ĞĞ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¾ Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹ Ğ² Ğ‘Ğ”: {company_updates}")
        else:
            print("\nâš ï¸ ĞĞµÑ‚ Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹ Ğ´Ğ»Ñ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ")
        
        print(f"\nğŸ“ˆ Ğ˜Ğ¢ĞĞ“Ğ˜:")
        print(f"   ğŸ¯ Ğ¡Ğ¾Ğ¿Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¾ Ğ·Ğ°Ğ´Ğ°Ñ‡: {matched_count}/{len(db_tasks)}")
        print(f"   ğŸ¢ Ğ—Ğ°Ğ´Ğ°Ñ‡ Ñ ĞºĞ¾Ğ¼Ğ¿Ğ°Ğ½Ğ¸ÑĞ¼Ğ¸: {company_updates}")
        print(f"   ğŸ“Š ĞŸÑ€Ğ¾Ñ†ĞµĞ½Ñ‚ Ğ¿Ğ¾ĞºÑ€Ñ‹Ñ‚Ğ¸Ñ: {(company_updates/len(db_tasks)*100):.1f}%")
        
    except Exception as e:
        print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ°: {e}")
        db.rollback()
    finally:
        db.close()

if __name__ == "__main__":
    match_and_update_ultimate() 