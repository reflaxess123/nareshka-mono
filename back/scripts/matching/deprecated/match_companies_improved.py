import re
import os
import sys

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..' )))

from app.database import get_db
from app.models import ContentBlock

def normalize_title_smart(title: str) -> str:
    """–£–º–Ω–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤"""
    # –£–¥–∞–ª—è–µ–º markdown —Å—Å—ã–ª–∫–∏ [text](url) -> text
    title = re.sub(r'\[([^\]]+)\]\([^)]+\)', r'\1', title)
    
    # –£–¥–∞–ª—è–µ–º –Ω–æ–º–µ—Ä–∞ –≤ –Ω–∞—á–∞–ª–µ: "1. title" -> "title"
    title = re.sub(r'^\d+\.\s*', '', title)
    
    # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –ø—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
    title = re.sub(r'\s+', ' ', title.lower().strip())
    
    # –£–¥–∞–ª—è–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã, –Ω–æ –æ—Å—Ç–∞–≤–ª—è–µ–º –≤–∞–∂–Ω—ã–µ
    title = re.sub(r'[#\-\*\+\[\]]', '', title)
    
    return title.strip()

def extract_companies_from_md_text(text: str) -> list[str]:
    """–£–ª—É—á—à–µ–Ω–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ–º–ø–∞–Ω–∏–π –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
    companies = []
    
    # –ü–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –∑–∞—Ö–≤–∞—Ç–∞ –≤—Å–µ–≥–æ –±–ª–æ–∫–∞ –ø–æ—Å–ª–µ "–≤—Å—Ç—Ä–µ—á–∞–ª–æ—Å—å –≤"
    # –ò—â–µ–º "–≤—Å—Ç—Ä–µ—á–∞–ª–æ—Å—å –≤" –∏ –≤—Å–µ —Å—Ç—Ä–æ–∫–∏ –ø–æ—Å–ª–µ –Ω–µ–≥–æ –¥–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ä–∞–∑–¥–µ–ª–∞
    patterns = [
        r'–≤—Å—Ç—Ä–µ—á–∞–ª–æ—Å—å –≤\s*[-\s]*\n((?:\s*[-\t]+\s*[^\n]+\n?)*)',
        r'–≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è –≤\s*[-\s]*\n((?:\s*[-\t]+\s*[^\n]+\n?)*)',
        r'–≤—Å—Ç—Ä–µ—á–∞–ª—Å—è –≤\s*[-\s]*\n((?:\s*[-\t]+\s*[^\n]+\n?)*)',
        # –¢–∞–∫–∂–µ –ª–æ–≤–∏–º —Å–ª—É—á–∞–∏ –∫–æ–≥–¥–∞ –≤—Å–µ –Ω–∞ –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–µ
        r'–≤—Å—Ç—Ä–µ—á–∞–ª–æ—Å—å –≤\s*[-\s]*([^\n]+)',
        r'–≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è –≤\s*[-\s]*([^\n]+)', 
        r'–≤—Å—Ç—Ä–µ—á–∞–ª—Å—è –≤\s*[-\s]*([^\n]+)'
    ]
    
    for pattern in patterns:
        matches = re.findall(pattern, text, re.IGNORECASE | re.MULTILINE)
        for match in matches:
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –º–Ω–æ–≥–æ—Å—Ç—Ä–æ—á–Ω—ã–π –±–ª–æ–∫
            lines = match.split('\n')
            for line in lines:
                # –£–¥–∞–ª—è–µ–º —Ç–∞–±—É–ª—è—Ü–∏–∏, —Ç–∏—Ä–µ, –ø—Ä–æ–±–µ–ª—ã –≤ –Ω–∞—á–∞–ª–µ
                line = re.sub(r'^[\s\t\-]+', '', line.strip())
                if line:
                    # –†–∞–∑–±–∏–≤–∞–µ–º –ø–æ –∑–∞–ø—è—Ç—ã–º –µ—Å–ª–∏ –µ—Å—Ç—å
                    sub_companies = re.split(r'[,;]', line)
                    for company in sub_companies:
                        company = company.strip().lower()
                        # –§–∏–ª—å—Ç—Ä—É–µ–º –º—É—Å–æ—Ä
                        if (company and len(company) > 2 and 
                            not company.startswith('(') and 
                            company not in ['—Ç–æ –µ—Å—Ç—å', '–Ω–µ–ª—å–∑—è –∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å –º–∞—Å—Å–∏–≤', 'inplace)', '–Ω–µ–ª—å–∑—è –º—É—Ç–∏—Ä–æ–≤–∞—Ç—å']):
                            companies.append(company)
    
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –∏—â–µ–º –∫–æ–º–ø–∞–Ω–∏–∏ –≤ –±–æ–ª–µ–µ –ø—Ä–æ—Å—Ç—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö
    # "–∫–æ–º–ø–∞–Ω–∏—è:" –≤ –Ω–∞—á–∞–ª–µ —Å—Ç—Ä–æ–∫–∏
    company_lines = re.findall(r'^[\s\t]*[-‚Ä¢]\s*(.+)$', text, re.MULTILINE)
    for line in company_lines:
        line = line.strip().lower()
        if any(keyword in text.lower() for keyword in ['–≤—Å—Ç—Ä–µ—á–∞–ª–æ—Å—å', '–≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è', '–≤—Å—Ç—Ä–µ—á–∞–ª—Å—è']):
            # –¢–æ–ª—å–∫–æ –µ—Å–ª–∏ –≤ —Ç–µ–∫—Å—Ç–µ –µ—Å—Ç—å —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ –æ –≤—Å—Ç—Ä–µ—á–∞—Ö
            if (line and len(line) > 2 and 
                not line.startswith('—Ä–µ—à–µ–Ω–æ') and 
                not re.match(r'\d+\s*—Ä–∞–∑', line)):
                companies.append(line)
    
    return list(set(companies))

def parse_md_files_improved():
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ .md —Ñ–∞–π–ª–æ–≤"""
    tasks = []
    base_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
    
    folders = [
        os.path.join(base_dir, 'js', '–û—Å–Ω–æ–≤–Ω—ã–µ –∑–∞–¥–∞—á–∏'), 
        os.path.join(base_dir, 'js', '—Ä–µ—à–µ–Ω–∏—è'), 
        os.path.join(base_dir, 'react'), 
        os.path.join(base_dir, 'ts', '–ó–∞–¥–∞—á–∏')
    ]
    
    for folder_path in folders:
        if not os.path.exists(folder_path):
            continue
            
        for root, _, files in os.walk(folder_path):
            for file_name in files:
                if file_name.endswith('.md'):
                    file_path = os.path.join(root, file_name)
                    try:
                        with open(file_path, 'r', encoding='utf-8') as f:
                            content = f.read()
                        
                        # –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
                        lines = content.split('\n')
                        current_title = None
                        current_content = ""
                        
                        for line in lines:
                            header_match = re.match(r'^(#{1,6})\s+(.+)$', line.strip())
                            if header_match:
                                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–µ–¥—ã–¥—É—â—É—é –∑–∞–¥–∞—á—É
                                if current_title and current_content.strip():
                                    companies = extract_companies_from_md_text(current_content)
                                    if companies:
                                        tasks.append({
                                            'title': current_title,
                                            'content': current_content.strip(),
                                            'companies': companies,
                                            'file': file_name,
                                            'normalized': normalize_title_smart(current_title)
                                        })
                                
                                current_title = header_match.group(2).strip()
                                current_content = ""
                            else:
                                current_content += line + "\n"
                        
                        # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –∑–∞–¥–∞—á—É
                        if current_title and current_content.strip():
                            companies = extract_companies_from_md_text(current_content)
                            if companies:
                                tasks.append({
                                    'title': current_title,
                                    'content': current_content.strip(),
                                    'companies': companies,
                                    'file': file_name,
                                    'normalized': normalize_title_smart(current_title)
                                })
                                
                    except Exception as e:
                        print(f"Error reading file {file_path}: {e}")
    
    return tasks

def similarity_score(str1: str, str2: str) -> float:
    """–í—ã—á–∏—Å–ª—è–µ—Ç –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Å—Ö–æ–¥—Å—Ç–≤–∞ –º–µ–∂–¥—É —Å—Ç—Ä–æ–∫–∞–º–∏"""
    if not str1 or not str2:
        return 0.0
    
    # –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
    if str1 == str2:
        return 1.0
    
    # –û–¥–Ω–∞ —Å—Ç—Ä–æ–∫–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç—Å—è –≤ –¥—Ä—É–≥–æ–π
    if str1 in str2 or str2 in str1:
        shorter = min(len(str1), len(str2))
        longer = max(len(str1), len(str2))
        return shorter / longer
    
    # Similarity –ø–æ —Å–ª–æ–≤–∞–º
    words1 = set(str1.split())
    words2 = set(str2.split())
    
    if not words1 or not words2:
        return 0.0
    
    intersection = len(words1.intersection(words2))
    union = len(words1.union(words2))
    
    return intersection / union if union > 0 else 0.0

def find_best_match(md_task: dict, db_blocks: list, threshold: float = 0.5):
    """–ù–∞—Ö–æ–¥–∏—Ç –ª—É—á—à–µ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –¥–ª—è –∑–∞–¥–∞—á–∏ –∏–∑ .md"""
    best_match = None
    best_score = 0.0
    
    md_normalized = md_task['normalized']
    
    for block in db_blocks:
        db_normalized = normalize_title_smart(block.blockTitle)
        score = similarity_score(md_normalized, db_normalized)
        
        if score > best_score and score >= threshold:
            best_score = score
            best_match = block
    
    return best_match, best_score

def match_and_update_improved():
    """–£–ª—É—á—à–µ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è"""
    db = next(get_db())
    
    print("üîç –ü–∞—Ä—Å–∏–Ω–≥ .md —Ñ–∞–π–ª–æ–≤...")
    md_tasks = parse_md_files_improved()
    print(f"üìù –ù–∞–π–¥–µ–Ω–æ {len(md_tasks)} –∑–∞–¥–∞—á —Å –∫–æ–º–ø–∞–Ω–∏—è–º–∏ –≤ .md —Ñ–∞–π–ª–∞—Ö")
    
    print("üóÑÔ∏è –ü–æ–ª—É—á–µ–Ω–∏–µ ContentBlocks –∏–∑ –ë–î...")
    db_blocks = db.query(ContentBlock).all()
    print(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(db_blocks)} –±–ª–æ–∫–æ–≤ –≤ –ë–î")
    
    matches = []
    no_matches = []
    
    print("\nüéØ –ü–æ–∏—Å–∫ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π...")
    
    for md_task in md_tasks:
        best_match, score = find_best_match(md_task, db_blocks, threshold=0.3)
        
        if best_match:
            matches.append({
                'md_task': md_task,
                'db_block': best_match,
                'score': score
            })
            print(f"‚úÖ [{score:.2f}] '{md_task['title'][:50]}...' -> '{best_match.blockTitle}' -> {md_task['companies']}")
        else:
            no_matches.append(md_task)
            print(f"‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ: '{md_task['title'][:50]}...' -> {md_task['companies']}")
    
    print(f"\nüìà –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
    print(f"   ‚Ä¢ –ù–∞–π–¥–µ–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π: {len(matches)}")
    print(f"   ‚Ä¢ –ù–µ –Ω–∞–π–¥–µ–Ω–æ: {len(no_matches)}")
    
    if matches:
        print(f"\nüíæ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö...")
        updated_count = 0
        
        for match in matches:
            db_block = match['db_block']
            companies = match['md_task']['companies']
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ
            if sorted(db_block.companies) != sorted(companies):
                db_block.companies = companies
                updated_count += 1
        
        try:
            db.commit()
            print(f"üéâ –£—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω–æ {updated_count} –±–ª–æ–∫–æ–≤ –≤ –ë–î!")
        except Exception as e:
            db.rollback()
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –ë–î: {e}")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ª—É—á—à–∏–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
    if matches:
        print(f"\nüèÜ –¢–û–ü-10 –ª—É—á—à–∏—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π:")
        sorted_matches = sorted(matches, key=lambda x: x['score'], reverse=True)
        for i, match in enumerate(sorted_matches[:10]):
            print(f"   {i+1}. [{match['score']:.2f}] {match['md_task']['title']} -> {match['db_block'].blockTitle}")
    
    db.close()
    
    return {
        'total_md_tasks': len(md_tasks),
        'total_db_blocks': len(db_blocks),
        'matches_found': len(matches),
        'no_matches': len(no_matches),
        'updated_count': updated_count if matches else 0
    }

if __name__ == "__main__":
    result = match_and_update_improved()
    print(f"\nüéØ –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    print(f"   üìÅ –ó–∞–¥–∞—á –≤ .md: {result['total_md_tasks']}")
    print(f"   üóÑÔ∏è –ë–ª–æ–∫–æ–≤ –≤ –ë–î: {result['total_db_blocks']}")
    print(f"   ‚úÖ –ù–∞–π–¥–µ–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π: {result['matches_found']}")
    print(f"   üíæ –û–±–Ω–æ–≤–ª–µ–Ω–æ –≤ –ë–î: {result['updated_count']}")
    print(f"   üìä –ü—Ä–æ—Ü–µ–Ω—Ç –ø–æ–∫—Ä—ã—Ç–∏—è: {result['matches_found']/result['total_md_tasks']*100:.1f}%") 