import re
import os
import sys

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..' )))

from app.database import get_db
from app.models import ContentBlock

def normalize_title_smart(title: str) -> str:
    """Ğ£Ğ¼Ğ½Ğ°Ñ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²ĞºĞ¾Ğ²"""
    # Ğ£Ğ´Ğ°Ğ»ÑĞµĞ¼ markdown ÑÑÑ‹Ğ»ĞºĞ¸ [text](url) -> text
    title = re.sub(r'\[([^\]]+)\]\([^)]+\)', r'\1', title)
    
    # Ğ£Ğ´Ğ°Ğ»ÑĞµĞ¼ Ğ½Ğ¾Ğ¼ĞµÑ€Ğ° Ğ² Ğ½Ğ°Ñ‡Ğ°Ğ»Ğµ: "1. title" -> "title"
    title = re.sub(r'^\d+\.\s*', '', title)
    
    # Ğ£Ğ´Ğ°Ğ»ÑĞµĞ¼ Ğ»Ğ¸ÑˆĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ğ±ĞµĞ»Ñ‹ Ğ¸ Ğ¿Ñ€Ğ¸Ğ²Ğ¾Ğ´Ğ¸Ğ¼ Ğº Ğ½Ğ¸Ğ¶Ğ½ĞµĞ¼Ñƒ Ñ€ĞµĞ³Ğ¸ÑÑ‚Ñ€Ñƒ
    title = re.sub(r'\s+', ' ', title.lower().strip())
    
    # Ğ£Ğ´Ğ°Ğ»ÑĞµĞ¼ ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ñ‹, Ğ½Ğ¾ Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ²Ğ°Ğ¶Ğ½Ñ‹Ğµ
    title = re.sub(r'[#\-\*\+\[\]]', '', title)
    
    return title.strip()

def extract_companies_from_md_text(text: str) -> list[str]:
    """Ğ£Ğ»ÑƒÑ‡ÑˆĞµĞ½Ğ½Ğ¾Ğµ Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ğµ ĞºĞ¾Ğ¼Ğ¿Ğ°Ğ½Ğ¸Ğ¹ Ğ¸Ğ· Ñ‚ĞµĞºÑÑ‚Ğ°"""
    companies = []
    
    # ĞŸĞ°Ñ‚Ñ‚ĞµÑ€Ğ½ Ğ´Ğ»Ñ Ğ·Ğ°Ñ…Ğ²Ğ°Ñ‚Ğ° Ğ²ÑĞµĞ³Ğ¾ Ğ±Ğ»Ğ¾ĞºĞ° Ğ¿Ğ¾ÑĞ»Ğµ "Ğ²ÑÑ‚Ñ€ĞµÑ‡Ğ°Ğ»Ğ¾ÑÑŒ Ğ²"
    # Ğ˜Ñ‰ĞµĞ¼ "Ğ²ÑÑ‚Ñ€ĞµÑ‡Ğ°Ğ»Ğ¾ÑÑŒ Ğ²" Ğ¸ Ğ²ÑĞµ ÑÑ‚Ñ€Ğ¾ĞºĞ¸ Ğ¿Ğ¾ÑĞ»Ğµ Ğ½ĞµĞ³Ğ¾ Ğ´Ğ¾ ÑĞ»ĞµĞ´ÑƒÑÑ‰ĞµĞ³Ğ¾ Ñ€Ğ°Ğ·Ğ´ĞµĞ»Ğ°
    patterns = [
        r'Ğ²ÑÑ‚Ñ€ĞµÑ‡Ğ°Ğ»Ğ¾ÑÑŒ Ğ²\s*[-\s]*\n((?:\s*[-\t]+\s*[^\n]+\n?)*)',
        r'Ğ²ÑÑ‚Ñ€ĞµÑ‡Ğ°ĞµÑ‚ÑÑ Ğ²\s*[-\s]*\n((?:\s*[-\t]+\s*[^\n]+\n?)*)',
        r'Ğ²ÑÑ‚Ñ€ĞµÑ‡Ğ°Ğ»ÑÑ Ğ²\s*[-\s]*\n((?:\s*[-\t]+\s*[^\n]+\n?)*)',
        # Ğ¢Ğ°ĞºĞ¶Ğµ Ğ»Ğ¾Ğ²Ğ¸Ğ¼ ÑĞ»ÑƒÑ‡Ğ°Ğ¸ ĞºĞ¾Ğ³Ğ´Ğ° Ğ²ÑĞµ Ğ½Ğ° Ğ¾Ğ´Ğ½Ğ¾Ğ¹ ÑÑ‚Ñ€Ğ¾ĞºĞµ
        r'Ğ²ÑÑ‚Ñ€ĞµÑ‡Ğ°Ğ»Ğ¾ÑÑŒ Ğ²\s*[-\s]*([^\n]+)',
        r'Ğ²ÑÑ‚Ñ€ĞµÑ‡Ğ°ĞµÑ‚ÑÑ Ğ²\s*[-\s]*([^\n]+)', 
        r'Ğ²ÑÑ‚Ñ€ĞµÑ‡Ğ°Ğ»ÑÑ Ğ²\s*[-\s]*([^\n]+)'
    ]
    
    for pattern in patterns:
        matches = re.findall(pattern, text, re.IGNORECASE | re.MULTILINE)
        for match in matches:
            # ĞĞ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ¼Ğ½Ğ¾Ğ³Ğ¾ÑÑ‚Ñ€Ğ¾Ñ‡Ğ½Ñ‹Ğ¹ Ğ±Ğ»Ğ¾Ğº
            lines = match.split('\n')
            for line in lines:
                # Ğ£Ğ´Ğ°Ğ»ÑĞµĞ¼ Ñ‚Ğ°Ğ±ÑƒĞ»ÑÑ†Ğ¸Ğ¸, Ñ‚Ğ¸Ñ€Ğµ, Ğ¿Ñ€Ğ¾Ğ±ĞµĞ»Ñ‹ Ğ² Ğ½Ğ°Ñ‡Ğ°Ğ»Ğµ
                line = re.sub(r'^[\s\t\-]+', '', line.strip())
                if line:
                    # Ğ Ğ°Ğ·Ğ±Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ¿Ğ¾ Ğ·Ğ°Ğ¿ÑÑ‚Ñ‹Ğ¼ ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ
                    sub_companies = re.split(r'[,;]', line)
                    for company in sub_companies:
                        company = company.strip().lower()
                        # Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€ÑƒĞµĞ¼ Ğ¼ÑƒÑĞ¾Ñ€
                        if (company and len(company) > 2 and 
                            not company.startswith('(') and 
                            company not in ['Ñ‚Ğ¾ ĞµÑÑ‚ÑŒ', 'Ğ½ĞµĞ»ÑŒĞ·Ñ ĞºĞ¾Ğ¿Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¼Ğ°ÑÑĞ¸Ğ²', 'inplace)', 'Ğ½ĞµĞ»ÑŒĞ·Ñ Ğ¼ÑƒÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ']):
                            companies.append(company)
    
    # Ğ”Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ¸Ñ‰ĞµĞ¼ ĞºĞ¾Ğ¼Ğ¿Ğ°Ğ½Ğ¸Ğ¸ Ğ² Ğ±Ğ¾Ğ»ĞµĞµ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ‹Ñ… Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ°Ñ…
    # "ĞºĞ¾Ğ¼Ğ¿Ğ°Ğ½Ğ¸Ñ:" Ğ² Ğ½Ğ°Ñ‡Ğ°Ğ»Ğµ ÑÑ‚Ñ€Ğ¾ĞºĞ¸
    company_lines = re.findall(r'^[\s\t]*[-â€¢]\s*(.+)$', text, re.MULTILINE)
    for line in company_lines:
        line = line.strip().lower()
        if any(keyword in text.lower() for keyword in ['Ğ²ÑÑ‚Ñ€ĞµÑ‡Ğ°Ğ»Ğ¾ÑÑŒ', 'Ğ²ÑÑ‚Ñ€ĞµÑ‡Ğ°ĞµÑ‚ÑÑ', 'Ğ²ÑÑ‚Ñ€ĞµÑ‡Ğ°Ğ»ÑÑ']):
            # Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ ĞµÑĞ»Ğ¸ Ğ² Ñ‚ĞµĞºÑÑ‚Ğµ ĞµÑÑ‚ÑŒ ÑƒĞ¿Ğ¾Ğ¼Ğ¸Ğ½Ğ°Ğ½Ğ¸Ğµ Ğ¾ Ğ²ÑÑ‚Ñ€ĞµÑ‡Ğ°Ñ…
            if (line and len(line) > 2 and 
                not line.startswith('Ñ€ĞµÑˆĞµĞ½Ğ¾') and 
                not re.match(r'\d+\s*Ñ€Ğ°Ğ·', line)):
                companies.append(line)
    
    return list(set(companies))

def parse_md_files_improved():
    """Ğ£Ğ»ÑƒÑ‡ÑˆĞµĞ½Ğ½Ñ‹Ğ¹ Ğ¿Ğ°Ñ€ÑĞ¸Ğ½Ğ³ .md Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²"""
    tasks = []
    base_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
    
    folders = [
        os.path.join(base_dir, 'js', 'ĞÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ğµ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸'), 
        os.path.join(base_dir, 'js', 'Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ'), 
        os.path.join(base_dir, 'react'), 
        os.path.join(base_dir, 'ts', 'Ğ—Ğ°Ğ´Ğ°Ñ‡Ğ¸')
    ]
    
    for folder_path in folders:
        if not os.path.exists(folder_path):
            continue
            
        for root, _, files in os.walk(folder_path):
            for file_name in files:
                if file_name.endswith('.md'):
                    file_path = os.path.join(root, file_name)
                    try:
                        with open(file_path, 'r', encoding='utf-8') as f:
                            content = f.read()
                        
                        # ĞŸĞ°Ñ€ÑĞ¸Ğ½Ğ³ Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²ĞºĞ¾Ğ²
                        lines = content.split('\n')
                        current_title = None
                        current_content = ""
                        
                        for line in lines:
                            header_match = re.match(r'^(#{1,6})\s+(.+)$', line.strip())
                            if header_match:
                                # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰ÑƒÑ Ğ·Ğ°Ğ´Ğ°Ñ‡Ñƒ
                                if current_title and current_content.strip():
                                    companies = extract_companies_from_md_text(current_content)
                                    if companies:
                                        tasks.append({
                                            'title': current_title,
                                            'content': current_content.strip(),
                                            'companies': companies,
                                            'file': file_name,
                                            'normalized': normalize_title_smart(current_title)
                                        })
                                
                                current_title = header_match.group(2).strip()
                                current_content = ""
                            else:
                                current_content += line + "\n"
                        
                        # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ÑÑ Ğ·Ğ°Ğ´Ğ°Ñ‡Ñƒ
                        if current_title and current_content.strip():
                            companies = extract_companies_from_md_text(current_content)
                            if companies:
                                tasks.append({
                                    'title': current_title,
                                    'content': current_content.strip(),
                                    'companies': companies,
                                    'file': file_name,
                                    'normalized': normalize_title_smart(current_title)
                                })
                                
                    except Exception as e:
                        print(f"Error reading file {file_path}: {e}")
    
    return tasks

def similarity_score(str1: str, str2: str) -> float:
    """Ğ’Ñ‹Ñ‡Ğ¸ÑĞ»ÑĞµÑ‚ ĞºĞ¾ÑÑ„Ñ„Ğ¸Ñ†Ğ¸ĞµĞ½Ñ‚ ÑÑ…Ğ¾Ğ´ÑÑ‚Ğ²Ğ° Ğ¼ĞµĞ¶Ğ´Ñƒ ÑÑ‚Ñ€Ğ¾ĞºĞ°Ğ¼Ğ¸"""
    if not str1 or not str2:
        return 0.0
    
    # Ğ¢Ğ¾Ñ‡Ğ½Ğ¾Ğµ ÑĞ¾Ğ²Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ğµ
    if str1 == str2:
        return 1.0
    
    # ĞĞ´Ğ½Ğ° ÑÑ‚Ñ€Ğ¾ĞºĞ° ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ÑÑ Ğ² Ğ´Ñ€ÑƒĞ³Ğ¾Ğ¹
    if str1 in str2 or str2 in str1:
        shorter = min(len(str1), len(str2))
        longer = max(len(str1), len(str2))
        return shorter / longer
    
    # Similarity Ğ¿Ğ¾ ÑĞ»Ğ¾Ğ²Ğ°Ğ¼
    words1 = set(str1.split())
    words2 = set(str2.split())
    
    if not words1 or not words2:
        return 0.0
    
    intersection = len(words1.intersection(words2))
    union = len(words1.union(words2))
    
    return intersection / union if union > 0 else 0.0

def find_best_match(md_task: dict, db_blocks: list, threshold: float = 0.5):
    """ĞĞ°Ñ…Ğ¾Ğ´Ğ¸Ñ‚ Ğ»ÑƒÑ‡ÑˆĞµĞµ ÑĞ¾Ğ²Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ğµ Ğ´Ğ»Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ Ğ¸Ğ· .md"""
    best_match = None
    best_score = 0.0
    
    md_normalized = md_task['normalized']
    
    for block in db_blocks:
        db_normalized = normalize_title_smart(block.blockTitle)
        score = similarity_score(md_normalized, db_normalized)
        
        if score > best_score and score >= threshold:
            best_score = score
            best_match = block
    
    return best_match, best_score

def match_and_update_improved():
    """Ğ£Ğ»ÑƒÑ‡ÑˆĞµĞ½Ğ½Ğ°Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ ÑĞ¾Ğ¿Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ¸ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ"""
    db = next(get_db())
    
    print("ğŸ” ĞŸĞ°Ñ€ÑĞ¸Ğ½Ğ³ .md Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²...")
    md_tasks = parse_md_files_improved()
    print(f"ğŸ“ ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾ {len(md_tasks)} Ğ·Ğ°Ğ´Ğ°Ñ‡ Ñ ĞºĞ¾Ğ¼Ğ¿Ğ°Ğ½Ğ¸ÑĞ¼Ğ¸ Ğ² .md Ñ„Ğ°Ğ¹Ğ»Ğ°Ñ…")
    
    print("ğŸ—„ï¸ ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ ContentBlocks Ğ¸Ğ· Ğ‘Ğ”...")
    db_blocks = db.query(ContentBlock).all()
    print(f"ğŸ“Š ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾ {len(db_blocks)} Ğ±Ğ»Ğ¾ĞºĞ¾Ğ² Ğ² Ğ‘Ğ”")
    
    matches = []
    no_matches = []
    
    print("\nğŸ¯ ĞŸĞ¾Ğ¸ÑĞº ÑĞ¾Ğ²Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ğ¹...")
    
    for md_task in md_tasks:
        best_match, score = find_best_match(md_task, db_blocks, threshold=0.3)
        
        if best_match:
            matches.append({
                'md_task': md_task,
                'db_block': best_match,
                'score': score
            })
            print(f"âœ… [{score:.2f}] '{md_task['title'][:50]}...' -> '{best_match.blockTitle}' -> {md_task['companies']}")
        else:
            no_matches.append(md_task)
            print(f"âŒ ĞĞµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾: '{md_task['title'][:50]}...' -> {md_task['companies']}")
    
    print(f"\nğŸ“ˆ Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹:")
    print(f"   â€¢ ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾ ÑĞ¾Ğ²Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ğ¹: {len(matches)}")
    print(f"   â€¢ ĞĞµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾: {len(no_matches)}")
    
    if matches:
        print(f"\nğŸ’¾ ĞĞ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ±Ğ°Ğ·Ñ‹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…...")
        updated_count = 0
        
        for match in matches:
            db_block = match['db_block']
            companies = match['md_task']['companies']
            
            # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼, Ğ½ÑƒĞ¶Ğ½Ğ¾ Ğ»Ğ¸ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ
            if sorted(db_block.companies) != sorted(companies):
                db_block.companies = companies
                updated_count += 1
        
        try:
            db.commit()
            print(f"ğŸ‰ Ğ£ÑĞ¿ĞµÑˆĞ½Ğ¾ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¾ {updated_count} Ğ±Ğ»Ğ¾ĞºĞ¾Ğ² Ğ² Ğ‘Ğ”!")
        except Exception as e:
            db.rollback()
            print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğ¸ Ğ‘Ğ”: {e}")
    
    # ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ»ÑƒÑ‡ÑˆĞ¸Ğµ ÑĞ¾Ğ²Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ñ
    if matches:
        print(f"\nğŸ† Ğ¢ĞĞŸ-10 Ğ»ÑƒÑ‡ÑˆĞ¸Ñ… ÑĞ¾Ğ²Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ğ¹:")
        sorted_matches = sorted(matches, key=lambda x: x['score'], reverse=True)
        for i, match in enumerate(sorted_matches[:10]):
            print(f"   {i+1}. [{match['score']:.2f}] {match['md_task']['title']} -> {match['db_block'].blockTitle}")
    
    db.close()
    
    return {
        'total_md_tasks': len(md_tasks),
        'total_db_blocks': len(db_blocks),
        'matches_found': len(matches),
        'no_matches': len(no_matches),
        'updated_count': updated_count if matches else 0
    }

if __name__ == "__main__":
    result = match_and_update_improved()
    print(f"\nğŸ¯ Ğ˜Ñ‚Ğ¾Ğ³Ğ¾Ğ²Ğ°Ñ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ°:")
    print(f"   ğŸ“ Ğ—Ğ°Ğ´Ğ°Ñ‡ Ğ² .md: {result['total_md_tasks']}")
    print(f"   ğŸ—„ï¸ Ğ‘Ğ»Ğ¾ĞºĞ¾Ğ² Ğ² Ğ‘Ğ”: {result['total_db_blocks']}")
    print(f"   âœ… ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾ ÑĞ¾Ğ²Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ğ¹: {result['matches_found']}")
    print(f"   ğŸ’¾ ĞĞ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¾ Ğ² Ğ‘Ğ”: {result['updated_count']}")
    print(f"   ğŸ“Š ĞŸÑ€Ğ¾Ñ†ĞµĞ½Ñ‚ Ğ¿Ğ¾ĞºÑ€Ñ‹Ñ‚Ğ¸Ñ: {result['matches_found']/result['total_md_tasks']*100:.1f}%") 