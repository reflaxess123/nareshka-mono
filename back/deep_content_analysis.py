#!/usr/bin/env python3

import logging
import re
import json
from collections import defaultdict, Counter
from typing import List, Dict, Any, Tuple, Set
from dataclasses import dataclass, asdict
from sqlalchemy.orm import sessionmaker
from sqlalchemy import create_engine
import difflib

from app.config import settings
from app.models import ContentBlock, ContentFile, UserContentProgress

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class TaskAnalysis:
    """–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –æ–¥–Ω–æ–π –∑–∞–¥–∞—á–∏"""
    id: str
    title: str
    category: str
    subcategory: str
    path_titles: List[str]
    
    # –ö–æ–Ω—Ç–µ–Ω—Ç
    text_content: str
    code_content: str
    code_language: str
    code_lines: int
    
    # –ê–Ω–∞–ª–∏–∑ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
    complexity_score: float
    difficulty_factors: List[str]
    
    # –ö–æ–Ω—Ü–µ–ø—Ü–∏–∏ –∏ —Ç–µ–º—ã
    programming_concepts: List[str]
    js_features_used: List[str]
    keywords: Set[str]
    
    # –°–≤—è–∑–∏ —Å –¥—Ä—É–≥–∏–º–∏ –∑–∞–¥–∞—á–∞–º–∏
    similar_tasks: List[str]
    prerequisite_concepts: List[str]
    
    # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    estimated_time_minutes: int
    target_skill_level: str
    
    # –ù–û–í–´–ï –ü–û–õ–Ø –¥–ª—è –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
    path_depth: int
    order_in_file: int
    pedagogical_type: str  # "explanation", "example", "exercise", "challenge"
    text_complexity: float
    user_success_rate: float
    avg_solve_time: float

@dataclass
class ConceptCluster:
    """–ö–ª–∞—Å—Ç–µ—Ä –∑–∞–¥–∞—á –ø–æ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏"""
    concept_name: str
    task_ids: List[str]
    difficulty_range: Tuple[float, float]
    common_patterns: List[str]
    learning_sequence: List[str]

@dataclass
class PathStructureAnalysis:
    """–ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã pathTitles"""
    full_path: str
    depth: int
    parent_path: str
    task_count: int
    avg_complexity: float
    completion_rate: float
    recommended_order: List[str]

class DeepContentAnalyzer:
    """–ì–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è –∑–∞–¥–∞—á –¥–ª—è mindmap"""
    
    def __init__(self):
        self.js_concepts = {
            # –ë–∞–∑–æ–≤—ã–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏
            'variables': ['let', 'const', 'var'],
            'functions': ['function', '=>', 'return'],
            'conditionals': ['if', 'else', 'switch', 'case'],
            'loops': ['for', 'while', 'forEach', 'map', 'filter'],
            
            # –°—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö
            'arrays': ['Array', r'\[\]', 'push', 'pop', 'slice', 'splice', 'indexOf'],
            'objects': ['Object', r'\{\}', 'keys', 'values', 'entries'],
            'strings': ['String', 'charAt', 'substring', 'split', 'join'],
            
            # –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏
            'classes': ['class', 'constructor', 'extends', 'super'],
            'async': ['async', 'await', 'Promise', r'\.then', r'\.catch'],
            'closures': ['closure', 'lexical', 'scope'],
            'destructuring': [r'\.\.\.', r'\{.*\}.*=', r'\[.*\].*='],
            'modules': ['import', 'export', 'require'],
            
            # ES6+ —Ñ–∏—á–∏
            'arrow_functions': ['=>'],
            'template_literals': ['`', r'\$\{'],
            'spread_operator': [r'\.\.\.'],
            'rest_parameters': [r'\.\.\.\\w+\)'],
            
            # DOM –∏ Web APIs
            'dom': ['document', 'getElementById', 'querySelector'],
            'events': ['addEventListener', 'onClick', 'onSubmit'],
            
            # –ê–ª–≥–æ—Ä–∏—Ç–º—ã
            'sorting': ['sort', 'bubble', 'quick', 'merge'],
            'searching': ['find', 'search', 'binary', 'linear'],
            'recursion': ['recursive', 'recursion', 'factorial'],
            
            # –ü–∞—Ç—Ç–µ—Ä–Ω—ã
            'error_handling': ['try', 'catch', 'throw', 'finally'],
            'regex': ['RegExp', r'\/.*\/', 'test', 'match'],
            'functional': ['map', 'filter', 'reduce', 'curry'],
        }
        
        self.complexity_indicators = {
            'high': ['async', 'Promise', 'class', 'prototype', 'closure', 'recursive', 'regex'],
            'medium': ['forEach', 'map', 'filter', 'destructuring', '=>', 'template'],
            'low': ['if', 'for', 'function', 'return', 'console']
        }

    def analyze_all_tasks(self) -> Dict[str, Any]:
        """–ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –≤—Å–µ—Ö –∑–∞–¥–∞—á"""
        # –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
        db_url = settings.database_url
        if db_url.startswith("postgres://"):
            db_url = db_url.replace("postgres://", "postgresql://", 1)
        
        engine = create_engine(db_url)
        SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
        db = SessionLocal()
        
        try:
            logger.info("üîç –ù–ê–ß–ò–ù–ê–ï–ú –ì–õ–£–ë–û–ö–ò–ô –ê–ù–ê–õ–ò–ó –°–û–î–ï–†–ñ–ê–ù–ò–Ø –ó–ê–î–ê–ß...")
            
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –±–ª–æ–∫–∏ —Å –∫–æ–¥–æ–º –ò –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –ø—Ä–æ–≥—Ä–µ—Å—Å
            blocks = db.query(ContentBlock).filter(
                ContentBlock.codeContent.isnot(None),
                ContentBlock.codeContent != ""
            ).all()
            
            # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
            user_stats = self.get_user_statistics(db, blocks)
            
            logger.info(f"üìä –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º {len(blocks)} –±–ª–æ–∫–æ–≤...")
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—É—é –∑–∞–¥–∞—á—É –¥–µ—Ç–∞–ª—å–Ω–æ
            task_analyses = []
            for i, block in enumerate(blocks):
                if i % 50 == 0:
                    logger.info(f"   –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {i}/{len(blocks)}...")
                
                analysis = self.analyze_single_task(block, user_stats.get(block.id, {}))
                task_analyses.append(analysis)
            
            logger.info("üß† –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–≤—è–∑–∏ –º–µ–∂–¥—É –∑–∞–¥–∞—á–∞–º–∏...")
            
            # –ù–∞—Ö–æ–¥–∏–º —Å–≤—è–∑–∏ –º–µ–∂–¥—É –∑–∞–¥–∞—á–∞–º–∏
            task_connections = self.find_task_connections(task_analyses)
            
            # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –∑–∞–¥–∞—á–∏ –ø–æ –∫–æ–Ω—Ü–µ–ø—Ü–∏—è–º
            concept_clusters = self.create_concept_clusters(task_analyses)
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏–∑—É—á–µ–Ω–∏—è
            learning_sequences = self.determine_learning_sequences(task_analyses, concept_clusters)
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É pathTitles –î–ï–¢–ê–õ–¨–ù–û
            path_structure = self.analyze_path_structure_detailed(task_analyses)
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–µ–¥–∞–≥–æ–≥–∏—á–µ—Å–∫–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
            pedagogical_analysis = self.analyze_pedagogical_patterns(task_analyses)
            
            # –ù–û–í–ê–Ø –§–£–ù–ö–¶–ò–Ø: –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–æ —Ç–µ–º–∞–º
            logger.info("üéØ –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–æ –æ—Å–Ω–æ–≤–Ω—ã–º —Ç–µ–º–∞–º...")
            topic_structure = self.create_topic_based_structure(task_analyses)
            
            return {
                'task_analyses': task_analyses,
                'task_connections': task_connections,
                'concept_clusters': concept_clusters,
                'learning_sequences': learning_sequences,
                'path_structure': path_structure,
                'pedagogical_analysis': pedagogical_analysis,
                'user_statistics': user_stats,
                'summary_stats': self.generate_summary_stats(task_analyses),
                'topic_structure': topic_structure  # –ù–æ–≤–æ–µ –ø–æ–ª–µ
            }
            
        finally:
            db.close()

    def get_user_statistics(self, db, blocks: List[ContentBlock]) -> Dict[str, Dict]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –ø–æ –∑–∞–¥–∞—á–∞–º"""
        user_stats = {}
        block_ids = [block.id for block in blocks]
        
        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
        progress_records = db.query(UserContentProgress).filter(
            UserContentProgress.blockId.in_(block_ids)
        ).all()
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –±–ª–æ–∫–∞–º
        from collections import defaultdict
        block_progress = defaultdict(list)
        for progress in progress_records:
            block_progress[progress.blockId].append(progress)
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –±–ª–æ–∫–∞
        for block_id, progresses in block_progress.items():
            total_users = len(progresses)
            solved_users = len([p for p in progresses if p.solvedCount > 0])
            success_rate = solved_users / total_users if total_users > 0 else 0.0
            
            user_stats[block_id] = {
                'total_users': total_users,
                'solved_users': solved_users,
                'success_rate': success_rate,
                'avg_attempts': sum(p.solvedCount for p in progresses) / total_users if total_users > 0 else 0.0
            }
        
        return user_stats

    def analyze_single_task(self, block: ContentBlock, user_stats: Dict) -> TaskAnalysis:
        """–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –æ–¥–Ω–æ–π –∑–∞–¥–∞—á–∏"""
        
        # –ë–∞–∑–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        file_info = block.file if hasattr(block, 'file') and block.file else None
        category = file_info.mainCategory if file_info else "Unknown"
        subcategory = file_info.subCategory if file_info else "Unknown"
        
        # –ê–Ω–∞–ª–∏–∑ –∫–æ–¥–∞
        code_content = block.codeContent or ""
        text_content = block.textContent or ""
        code_lines = len([line for line in code_content.split('\n') if line.strip()])
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏
        programming_concepts = self.identify_concepts(code_content, text_content)
        js_features = self.identify_js_features(code_content)
        
        # –ê–Ω–∞–ª–∏–∑ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
        complexity_score, difficulty_factors = self.calculate_complexity(code_content, text_content)
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
        keywords = self.extract_keywords(code_content, text_content, block.blockTitle)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Ä–æ–≤–µ–Ω—å –Ω–∞–≤—ã–∫–æ–≤
        target_skill_level = self.determine_skill_level(complexity_score, programming_concepts)
        
        # –û—Ü–µ–Ω–∫–∞ –≤—Ä–µ–º–µ–Ω–∏
        estimated_time = self.estimate_time(code_content, text_content, complexity_score)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–µ—Ä–µ–∫–≤–∏–∑–∏—Ç—ã
        prerequisites = self.identify_prerequisites(programming_concepts, js_features)
        
        # –ù–û–í–´–ï –ü–û–õ–Ø –¥–ª—è –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        path_depth = len(block.pathTitles) if block.pathTitles else 0
        order_in_file = block.orderInFile if hasattr(block, 'orderInFile') else 0
        pedagogical_type = self.determine_pedagogical_type(text_content, code_content, block.blockTitle)
        text_complexity = self.calculate_text_complexity(text_content)
        user_success_rate = user_stats.get('success_rate', 0.0)
        avg_solve_time = user_stats.get('avg_attempts', 0.0)
        
        return TaskAnalysis(
            id=block.id,
            title=block.blockTitle,
            category=category,
            subcategory=subcategory,
            path_titles=block.pathTitles or [],
            text_content=text_content[:500] + "..." if len(text_content) > 500 else text_content,
            code_content=code_content,
            code_language=block.codeLanguage or "js",
            code_lines=code_lines,
            complexity_score=complexity_score,
            difficulty_factors=difficulty_factors,
            programming_concepts=programming_concepts,
            js_features_used=js_features,
            keywords=keywords,
            similar_tasks=[],  # –ó–∞–ø–æ–ª–Ω–∏–º –ø–æ–∑–∂–µ
            prerequisite_concepts=prerequisites,
            estimated_time_minutes=estimated_time,
            target_skill_level=target_skill_level,
            path_depth=path_depth,
            order_in_file=order_in_file,
            pedagogical_type=pedagogical_type,
            text_complexity=text_complexity,
            user_success_rate=user_success_rate,
            avg_solve_time=avg_solve_time
        )

    def identify_concepts(self, code: str, text: str) -> List[str]:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ø—Ä–æ–≥—Ä–∞–º–º–∏—Å—Ç—Å–∫–∏–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏ –≤ –∑–∞–¥–∞—á–µ"""
        content = (code + " " + text).lower()
        found_concepts = []
        
        for concept, patterns in self.js_concepts.items():
            for pattern in patterns:
                if re.search(pattern, content, re.IGNORECASE):
                    found_concepts.append(concept)
                    break
        
        return found_concepts

    def identify_js_features(self, code: str) -> List[str]:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ JS —Ñ–∏—á–∏"""
        features = []
        
        # ES6+ —Ñ–∏—á–∏
        if '=>' in code:
            features.append('arrow_functions')
        if '...' in code:
            features.append('spread_operator')
        if '`' in code and '${' in code:
            features.append('template_literals')
        if re.search(r'const\s*\{.*\}\s*=', code):
            features.append('object_destructuring')
        if re.search(r'const\s*\[.*\]\s*=', code):
            features.append('array_destructuring')
        
        # Async/await
        if 'async' in code or 'await' in code:
            features.append('async_await')
        if 'Promise' in code:
            features.append('promises')
        
        # –ö–ª–∞—Å—Å—ã
        if 'class ' in code:
            features.append('es6_classes')
        if 'constructor' in code:
            features.append('constructor')
        if 'extends' in code:
            features.append('inheritance')
        
        # –§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ
        fp_methods = ['map', 'filter', 'reduce', 'forEach', 'find', 'some', 'every']
        for method in fp_methods:
            if f'.{method}(' in code:
                features.append(f'array_{method}')
        
        return features

    def calculate_complexity(self, code: str, text: str) -> Tuple[float, List[str]]:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Å–ª–æ–∂–Ω–æ—Å—Ç—å –∑–∞–¥–∞—á–∏ –∏ —Ñ–∞–∫—Ç–æ—Ä—ã —Å–ª–æ–∂–Ω–æ—Å—Ç–∏"""
        complexity = 0.0
        factors = []
        
        # –ë–∞–∑–æ–≤–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å –æ—Ç –¥–ª–∏–Ω—ã –∫–æ–¥–∞
        lines = len([line for line in code.split('\n') if line.strip()])
        if lines > 50:
            complexity += 2.0
            factors.append(f"–î–ª–∏–Ω–Ω—ã–π –∫–æ–¥ ({lines} —Å—Ç—Ä–æ–∫)")
        elif lines > 20:
            complexity += 1.0
            factors.append(f"–°—Ä–µ–¥–Ω–∏–π –∫–æ–¥ ({lines} —Å—Ç—Ä–æ–∫)")
        
        # –°–ª–æ–∂–Ω–æ—Å—Ç—å –æ—Ç –≤–ª–æ–∂–µ–Ω–Ω–æ—Å—Ç–∏
        brace_depth = 0
        max_depth = 0
        for char in code:
            if char == '{':
                brace_depth += 1
                max_depth = max(max_depth, brace_depth)
            elif char == '}':
                brace_depth -= 1
        
        if max_depth > 4:
            complexity += 2.0
            factors.append(f"–ì–ª—É–±–æ–∫–∞—è –≤–ª–æ–∂–µ–Ω–Ω–æ—Å—Ç—å ({max_depth})")
        elif max_depth > 2:
            complexity += 1.0
            factors.append(f"–°—Ä–µ–¥–Ω—è—è –≤–ª–æ–∂–µ–Ω–Ω–æ—Å—Ç—å ({max_depth})")
        
        # –°–ª–æ–∂–Ω–æ—Å—Ç—å –æ—Ç –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
        content = (code + " " + text).lower()
        for level, indicators in self.complexity_indicators.items():
            count = sum(1 for indicator in indicators if indicator in content)
            if level == 'high':
                complexity += count * 1.5
                if count > 0:
                    factors.append(f"–°–ª–æ–∂–Ω—ã–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏ ({count})")
            elif level == 'medium':
                complexity += count * 0.5
                if count > 2:
                    factors.append(f"–°—Ä–µ–¥–Ω–∏–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏ ({count})")
        
        # –ê–ª–≥–æ—Ä–∏—Ç–º–∏—á–µ—Å–∫–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å
        if any(word in content for word in ['recursive', 'recursion', 'fibonacci', 'factorial']):
            complexity += 3.0
            factors.append("–†–µ–∫—É—Ä—Å–∏—è")
        
        if any(word in content for word in ['sort', 'bubble', 'quick', 'merge', 'heap']):
            complexity += 2.0
            factors.append("–ê–ª–≥–æ—Ä–∏—Ç–º—ã —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏")
        
        if any(word in content for word in ['tree', 'graph', 'linked list', 'queue', 'stack']):
            complexity += 2.5
            factors.append("–°—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö")
        
        return round(complexity, 2), factors

    def extract_keywords(self, code: str, text: str, title: str) -> Set[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ –∑–∞–¥–∞—á–∏"""
        content = f"{title} {text} {code}".lower()
        
        # –£–±–∏—Ä–∞–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –∏ —Å—Ç—Ä–æ–∫–∏
        content = re.sub(r'//.*$', '', content, flags=re.MULTILINE)
        content = re.sub(r'/\*.*?\*/', '', content, flags=re.DOTALL)
        content = re.sub(r'"[^"]*"', '', content)
        content = re.sub(r"'[^']*'", '', content)
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–ª–æ–≤–∞
        words = re.findall(r'\b[a-zA-Z]{3,}\b', content)
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º —Å—Ç–æ–ø-—Å–ª–æ–≤–∞
        stop_words = {
            'function', 'return', 'const', 'let', 'var', 'for', 'while', 'if', 'else',
            'true', 'false', 'null', 'undefined', 'this', 'new', 'class', 'extends',
            'console', 'log', 'length', 'push', 'pop', 'shift', 'unshift'
        }
        
        keywords = set(word for word in words if word not in stop_words and len(word) > 2)
        return keywords

    def determine_skill_level(self, complexity: float, concepts: List[str]) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ü–µ–ª–µ–≤–æ–π —É—Ä–æ–≤–µ–Ω—å –Ω–∞–≤—ã–∫–æ–≤"""
        advanced_concepts = ['classes', 'async', 'closures', 'recursion', 'modules']
        
        if complexity >= 5.0 or any(concept in advanced_concepts for concept in concepts):
            return "advanced"
        elif complexity >= 2.0 or len(concepts) >= 4:
            return "intermediate"
        else:
            return "beginner"

    def estimate_time(self, code: str, text: str, complexity: float) -> int:
        """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç –≤—Ä–µ–º—è –∏–∑—É—á–µ–Ω–∏—è –≤ –º–∏–Ω—É—Ç–∞—Ö"""
        base_time = 15  # –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è
        
        # –í—Ä–µ–º—è –Ω–∞ —á—Ç–µ–Ω–∏–µ
        text_words = len(text.split()) if text else 0
        reading_time = text_words / 3  # 3 —Å–ª–æ–≤–∞ –≤ —Å–µ–∫—É–Ω–¥—É, –ø–µ—Ä–µ–≤–æ–¥–∏–º –≤ –º–∏–Ω—É—Ç—ã
        
        # –í—Ä–µ–º—è –Ω–∞ –∞–Ω–∞–ª–∏–∑ –∫–æ–¥–∞
        code_lines = len([line for line in code.split('\n') if line.strip()])
        code_time = code_lines * 0.5  # 30 —Å–µ–∫—É–Ω–¥ –Ω–∞ —Å—Ç—Ä–æ–∫—É
        
        # –ú–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
        complexity_modifier = 1 + (complexity / 10)
        
        total_time = int((base_time + reading_time + code_time) * complexity_modifier)
        return min(max(total_time, 10), 120)  # –æ—Ç 10 –¥–æ 120 –º–∏–Ω—É—Ç

    def identify_prerequisites(self, concepts: List[str], features: List[str]) -> List[str]:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –∑–Ω–∞–Ω–∏—è"""
        prerequisites = []
        
        # –ë–∞–∑–æ–≤—ã–µ –ø—Ä–µ—Ä–µ–∫–≤–∏–∑–∏—Ç—ã
        concept_deps = {
            'arrays': ['variables', 'functions'],
            'objects': ['variables', 'functions'],
            'classes': ['objects', 'functions'],
            'async': ['functions', 'objects'],
            'closures': ['functions', 'variables'],
            'modules': ['functions', 'objects']
        }
        
        for concept in concepts:
            if concept in concept_deps:
                prerequisites.extend(concept_deps[concept])
        
        return list(set(prerequisites))

    def find_task_connections(self, analyses: List[TaskAnalysis]) -> Dict[str, List[str]]:
        """–ù–∞—Ö–æ–¥–∏—Ç —Å–≤—è–∑–∏ –º–µ–∂–¥—É –∑–∞–¥–∞—á–∞–º–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∞–ª—å–Ω–æ–≥–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è"""
        connections = {}
        
        for i, task in enumerate(analyses):
            task_connections = []
            
            # 1. –°–≤—è–∑–∏ –ø–æ pathTitles (–æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ –ø—É—Ç–∏)
            same_path_tasks = [
                other.id for other in analyses 
                if other.id != task.id and other.path_titles == task.path_titles
            ]
            task_connections.extend(same_path_tasks[:3])  # –º–∞–∫—Å–∏–º—É–º 3
            
            # 2. –°–≤—è–∑–∏ –ø–æ –∫–æ–Ω—Ü–µ–ø—Ü–∏—è–º (–æ–±—â–∏–µ JS features)
            concept_similarity_tasks = []
            for other in analyses:
                if other.id != task.id:
                    common_concepts = set(task.js_features_used) & set(other.js_features_used)
                    if len(common_concepts) >= 2:  # –º–∏–Ω–∏–º—É–º 2 –æ–±—â–∏—Ö –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏
                        concept_similarity_tasks.append((other.id, len(common_concepts)))
            
            # –ë–µ—Ä–µ–º —Ç–æ–ø-3 –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –æ–±—â–∏—Ö –∫–æ–Ω—Ü–µ–ø—Ü–∏–π
            concept_similarity_tasks.sort(key=lambda x: x[1], reverse=True)
            task_connections.extend([task_id for task_id, _ in concept_similarity_tasks[:3]])
            
            # 3. –°–≤—è–∑–∏ –ø–æ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ (–ø–æ—Ö–æ–∂–∏–µ –ø–æ —É—Ä–æ–≤–Ω—é)
            similar_complexity_tasks = [
                other.id for other in analyses 
                if other.id != task.id and 
                abs(other.complexity_score - task.complexity_score) <= 0.3
            ]
            task_connections.extend(similar_complexity_tasks[:2])  # –º–∞–∫—Å–∏–º—É–º 2
            
            # 4. –°–≤—è–∑–∏ –ø–æ –ø–µ–¥–∞–≥–æ–≥–∏—á–µ—Å–∫–æ–º—É —Ç–∏–ø—É
            same_pedagogy_tasks = [
                other.id for other in analyses 
                if other.id != task.id and other.pedagogical_type == task.pedagogical_type
            ]
            task_connections.extend(same_pedagogy_tasks[:2])  # –º–∞–∫—Å–∏–º—É–º 2
            
            # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –∏ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º
            connections[task.id] = list(set(task_connections))[:5]  # –º–∞–∫—Å–∏–º—É–º 5 —Å–≤—è–∑–µ–π
            
        return connections

    def create_concept_clusters(self, analyses: List[TaskAnalysis]) -> Dict[str, List[str]]:
        """–ì—Ä—É–ø–ø–∏—Ä—É–µ—Ç –∑–∞–¥–∞—á–∏ –ø–æ –∫–æ–Ω—Ü–µ–ø—Ü–∏—è–º –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
        clusters = {}
        
        # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ –æ—Å–Ω–æ–≤–Ω—ã–º JS –∫–æ–Ω—Ü–µ–ø—Ü–∏—è–º
        main_concepts = ['arrays', 'functions', 'objects', 'strings', 'async', 'classes', 'regex']
        
        for concept in main_concepts:
            # –ù–∞—Ö–æ–¥–∏–º –∑–∞–¥–∞—á–∏, –∫–æ—Ç–æ—Ä—ã–µ —Å–æ–¥–µ—Ä–∂–∞—Ç —ç—Ç—É –∫–æ–Ω—Ü–µ–ø—Ü–∏—é
            tasks_with_concept = [
                analysis.id for analysis in analyses 
                if concept in analysis.programming_concepts
            ]
            
            if tasks_with_concept:
                clusters[concept] = tasks_with_concept
        
        # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ pathTitles (–ø–µ—Ä–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç –ø—É—Ç–∏)
        path_clusters = {}
        for analysis in analyses:
            if analysis.path_titles:
                main_path = analysis.path_titles[0]
                if main_path not in path_clusters:
                    path_clusters[main_path] = []
                path_clusters[main_path].append(analysis.id)
        
        # –î–æ–±–∞–≤–ª—è–µ–º path-based –∫–ª–∞—Å—Ç–µ—Ä—ã
        for path_name, task_ids in path_clusters.items():
            if len(task_ids) >= 3:  # –º–∏–Ω–∏–º—É–º 3 –∑–∞–¥–∞—á–∏ –≤ –∫–ª–∞—Å—Ç–µ—Ä–µ
                clusters[f"path_{path_name}"] = task_ids
        
        # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
        beginner_tasks = [a.id for a in analyses if a.complexity_score <= 1.0]
        intermediate_tasks = [a.id for a in analyses if 1.0 < a.complexity_score <= 2.5]
        advanced_tasks = [a.id for a in analyses if a.complexity_score > 2.5]
        
        if beginner_tasks:
            clusters['difficulty_beginner'] = beginner_tasks
        if intermediate_tasks:
            clusters['difficulty_intermediate'] = intermediate_tasks
        if advanced_tasks:
            clusters['difficulty_advanced'] = advanced_tasks
        
        return clusters

    def determine_learning_sequences(self, analyses: List[TaskAnalysis], 
                                   concept_clusters: Dict[str, List[str]]) -> Dict[str, List[str]]:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏–∑—É—á–µ–Ω–∏—è"""
        sequences = {}
        
        # 1. –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø–æ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –≤–Ω—É—Ç—Ä–∏ –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Ç–µ—Ä–∞
        for cluster_name, task_ids in concept_clusters.items():
            if cluster_name.startswith('path_') or cluster_name in ['arrays', 'functions', 'objects']:
                # –°–æ—Ä—Ç–∏—Ä—É–µ–º –∑–∞–¥–∞—á–∏ –≤ –∫–ª–∞—Å—Ç–µ—Ä–µ –ø–æ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
                cluster_tasks = [a for a in analyses if a.id in task_ids]
                cluster_tasks.sort(key=lambda x: (x.complexity_score, x.path_depth, x.order_in_file))
                
                sequences[f"sequence_{cluster_name}"] = [task.id for task in cluster_tasks]
        
        # 2. –û–±—â–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏–∑—É—á–µ–Ω–∏—è –∫–æ–Ω—Ü–µ–ø—Ü–∏–π
        concept_prerequisites = {
            'variables': [],
            'functions': ['variables'],
            'arrays': ['variables', 'functions'],
            'objects': ['variables', 'functions'],
            'strings': ['variables', 'functions'],
            'loops': ['variables', 'functions', 'arrays'],
            'conditionals': ['variables'],
            'classes': ['variables', 'functions', 'objects'],
            'async': ['variables', 'functions', 'objects'],
            'regex': ['strings', 'functions']
        }
        
        # –°–æ–∑–¥–∞–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º—É—é –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å
        recommended_sequence = []
        for concept in ['variables', 'functions', 'conditionals', 'arrays', 'objects', 'strings', 'classes', 'async']:
            if concept in concept_clusters:
                # –ë–µ—Ä–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–∞–º—ã—Ö –ø—Ä–æ—Å—Ç—ã—Ö –∑–∞–¥–∞—á –∏–∑ –∫–∞–∂–¥–æ–π –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏
                concept_tasks = [a for a in analyses if a.id in concept_clusters[concept]]
                concept_tasks.sort(key=lambda x: x.complexity_score)
                recommended_sequence.extend([task.id for task in concept_tasks[:3]])  # —Ç–æ–ø-3 –ø—Ä–æ—Å—Ç—ã—Ö
        
        sequences['recommended_learning_path'] = recommended_sequence
        
        return sequences

    def analyze_path_structure_detailed(self, analyses: List[TaskAnalysis]) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É pathTitles"""
        path_analysis = {
            'depth_distribution': defaultdict(int),
            'common_paths': defaultdict(int),
            'path_hierarchies': defaultdict(list)
        }
        
        for analysis in analyses:
            path_depth = len(analysis.path_titles)
            path_analysis['depth_distribution'][path_depth] += 1
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –æ–±—â–∏–µ –ø—É—Ç–∏
            for i in range(1, len(analysis.path_titles) + 1):
                partial_path = ' > '.join(analysis.path_titles[:i])
                path_analysis['common_paths'][partial_path] += 1
            
            # –°—Ç—Ä–æ–∏–º –∏–µ—Ä–∞—Ä—Ö–∏–∏
            if analysis.path_titles:
                root = analysis.path_titles[0]
                path_analysis['path_hierarchies'][root].append(analysis.id)
        
        return path_analysis

    def analyze_pedagogical_patterns(self, analyses: List[TaskAnalysis]) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø–µ–¥–∞–≥–æ–≥–∏—á–µ—Å–∫–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã"""
        pedagogical_analysis = {
            'explanation_count': 0,
            'example_count': 0,
            'exercise_count': 0,
            'challenge_count': 0,
            'practice_count': 0
        }
        
        for analysis in analyses:
            if analysis.pedagogical_type == "explanation":
                pedagogical_analysis['explanation_count'] += 1
            elif analysis.pedagogical_type == "example":
                pedagogical_analysis['example_count'] += 1
            elif analysis.pedagogical_type == "exercise":
                pedagogical_analysis['exercise_count'] += 1
            elif analysis.pedagogical_type == "challenge":
                pedagogical_analysis['challenge_count'] += 1
            else:
                pedagogical_analysis['practice_count'] += 1
        
        return pedagogical_analysis

    def generate_summary_stats(self, analyses: List[TaskAnalysis]) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å–≤–æ–¥–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"""
        return {
            'total_tasks': len(analyses),
            'by_category': Counter(a.category for a in analyses),
            'by_skill_level': Counter(a.target_skill_level for a in analyses),
            'complexity_distribution': {
                'min': min(a.complexity_score for a in analyses),
                'max': max(a.complexity_score for a in analyses),
                'avg': sum(a.complexity_score for a in analyses) / len(analyses)
            },
            'most_common_concepts': Counter(
                concept for a in analyses for concept in a.programming_concepts
            ).most_common(20),
            'most_common_features': Counter(
                feature for a in analyses for feature in a.js_features_used
            ).most_common(20),
            'estimated_total_time_hours': sum(a.estimated_time_minutes for a in analyses) / 60
        }

    def print_detailed_report(self, analysis_result: Dict[str, Any]):
        """–í—ã–≤–æ–¥–∏—Ç –¥–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç –∞–Ω–∞–ª–∏–∑–∞"""
        analyses = analysis_result['task_analyses']
        clusters = analysis_result['concept_clusters']
        sequences = analysis_result['learning_sequences']
        stats = analysis_result['summary_stats']
        
        print("\n" + "="*80)
        print("üîç –î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –°–û–î–ï–†–ñ–ê–ù–ò–Ø –ó–ê–î–ê–ß NARESHKA")
        print("="*80)
        
        # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        print(f"\nüìä –û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
        print(f"   –í—Å–µ–≥–æ –∑–∞–¥–∞—á: {stats['total_tasks']}")
        print(f"   –û–±—â–µ–µ –≤—Ä–µ–º—è –∏–∑—É—á–µ–Ω–∏—è: {stats['estimated_total_time_hours']:.1f} —á–∞—Å–æ–≤")
        print(f"   –°—Ä–µ–¥–Ω—è—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å: {stats['complexity_distribution']['avg']:.2f}")
        
        # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —É—Ä–æ–≤–Ω—è–º
        print(f"\nüéØ –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï –ü–û –£–†–û–í–ù–Ø–ú:")
        for level, count in stats['by_skill_level'].items():
            percentage = (count / stats['total_tasks']) * 100
            print(f"   {level.capitalize()}: {count} –∑–∞–¥–∞—á ({percentage:.1f}%)")
        
        # –¢–æ–ø –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏
        print(f"\nüß† –¢–û–ü-10 –ö–û–ù–¶–ï–ü–¶–ò–ô:")
        for concept, count in stats['most_common_concepts'][:10]:
            print(f"   {concept}: {count} –∑–∞–¥–∞—á")
        
        # –ü—Ä–∏–º–µ—Ä—ã –∑–∞–¥–∞—á –ø–æ —É—Ä–æ–≤–Ω—è–º
        print(f"\nüìù –ü–†–ò–ú–ï–†–´ –ó–ê–î–ê–ß –ü–û –£–†–û–í–ù–Ø–ú:")
        
        for level in ['beginner', 'intermediate', 'advanced']:
            level_tasks = [a for a in analyses if a.target_skill_level == level]
            if level_tasks:
                print(f"\n--- {level.upper()} –£–†–û–í–ï–ù–¨ ---")
                for i, task in enumerate(level_tasks[:3]):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º 3 –ø—Ä–∏–º–µ—Ä–∞
                    print(f"\n{i+1}. {task.title}")
                    print(f"   ID: {task.id}")
                    print(f"   –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {task.category} / {task.subcategory}")
                    print(f"   –°–ª–æ–∂–Ω–æ—Å—Ç—å: {task.complexity_score}")
                    print(f"   –ö–æ–Ω—Ü–µ–ø—Ü–∏–∏: {', '.join(task.programming_concepts[:5])}")
                    print(f"   JS —Ñ–∏—á–∏: {', '.join(task.js_features_used[:5])}")
                    print(f"   –í—Ä–µ–º—è –∏–∑—É—á–µ–Ω–∏—è: {task.estimated_time_minutes} –º–∏–Ω")
                    
                    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–æ–¥ (–ø–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫)
                    code_lines = task.code_content.split('\n')[:5]
                    print(f"   –ö–æ–¥:")
                    for j, line in enumerate(code_lines, 1):
                        if line.strip():
                            print(f"      {j}: {line}")
                    total_lines = len(task.code_content.split('\n'))
                    if total_lines > 5:
                        remaining_lines = total_lines - 5
                        print(f"      ... (–µ—â–µ {remaining_lines} —Å—Ç—Ä–æ–∫)")
        
        # –ö–ª–∞—Å—Ç–µ—Ä—ã –∫–æ–Ω—Ü–µ–ø—Ü–∏–π
        print(f"\nüéØ –ö–õ–ê–°–¢–ï–†–´ –ö–û–ù–¶–ï–ü–¶–ò–ô:")
        for cluster_name, task_ids in list(clusters.items())[:10]:
            print(f"\n--- {cluster_name.upper()} ---")
            print(f"   –ó–∞–¥–∞—á: {len(task_ids)}")
            
            # –í—ã—á–∏—Å–ª—è–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∞
            cluster_tasks = [a for a in analyses if a.id in task_ids]
            if cluster_tasks:
                min_complexity = min(task.complexity_score for task in cluster_tasks)
                max_complexity = max(task.complexity_score for task in cluster_tasks)
                print(f"   –°–ª–æ–∂–Ω–æ—Å—Ç—å: {min_complexity:.1f} - {max_complexity:.1f}")
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã –∑–∞–¥–∞—á –∫–ª–∞—Å—Ç–µ—Ä–∞
                for task in cluster_tasks[:3]:
                    print(f"      ‚Ä¢ {task.title} (—Å–ª–æ–∂–Ω–æ—Å—Ç—å: {task.complexity_score})")
        
        # –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        print(f"\nüìö –†–ï–ö–û–ú–ï–ù–î–£–ï–ú–´–ï –ü–û–°–õ–ï–î–û–í–ê–¢–ï–õ–¨–ù–û–°–¢–ò –ò–ó–£–ß–ï–ù–ò–Ø:")
        
        skill_sequences = sequences.get('by_skill_level', {})
        for level, task_ids in skill_sequences.items():
            if task_ids:
                print(f"\n--- {level.upper()} –ü–£–¢–¨ ---")
                level_tasks = [a for a in analyses if a.id in task_ids[:5]]
                for i, task in enumerate(level_tasks, 1):
                    print(f"   {i}. {task.title} (—Å–ª–æ–∂–Ω–æ—Å—Ç—å: {task.complexity_score})")
        
        # –î–µ—Ç–∞–ª—å–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã—Ö –∑–∞–¥–∞—á
        print(f"\nüî• –ò–ù–¢–ï–†–ï–°–ù–´–ï –ó–ê–î–ê–ß–ò –î–õ–Ø MINDMAP:")
        
        # –°–∞–º–∞—è –ø—Ä–æ—Å—Ç–∞—è –∑–∞–¥–∞—á–∞
        simplest = min(analyses, key=lambda a: a.complexity_score)
        print(f"\n--- –°–ê–ú–ê–Ø –ü–†–û–°–¢–ê–Ø –ó–ê–î–ê–ß–ê ---")
        self.print_task_detail(simplest)
        
        # –°–∞–º–∞—è —Å–ª–æ–∂–Ω–∞—è –∑–∞–¥–∞—á–∞
        most_complex = max(analyses, key=lambda a: a.complexity_score)
        print(f"\n--- –°–ê–ú–ê–Ø –°–õ–û–ñ–ù–ê–Ø –ó–ê–î–ê–ß–ê ---")
        self.print_task_detail(most_complex)
        
        # –ó–∞–¥–∞—á–∞ —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –∫–æ–Ω—Ü–µ–ø—Ü–∏–π
        most_concepts = max(analyses, key=lambda a: len(a.programming_concepts))
        print(f"\n--- –ó–ê–î–ê–ß–ê –° –ù–ê–ò–ë–û–õ–¨–®–ò–ú –ö–û–õ–ò–ß–ï–°–¢–í–û–ú –ö–û–ù–¶–ï–ü–¶–ò–ô ---")
        self.print_task_detail(most_concepts)

    def print_task_detail(self, task: TaskAnalysis):
        """–í—ã–≤–æ–¥–∏—Ç –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∑–∞–¥–∞—á–µ"""
        print(f"   –ù–∞–∑–≤–∞–Ω–∏–µ: {task.title}")
        print(f"   ID: {task.id}")
        print(f"   –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {task.category} / {task.subcategory}")
        print(f"   –ü—É—Ç—å: {' > '.join(task.path_titles) if task.path_titles else '–ù–µ—Ç'}")
        print(f"   –°–ª–æ–∂–Ω–æ—Å—Ç—å: {task.complexity_score}")
        print(f"   –§–∞–∫—Ç–æ—Ä—ã —Å–ª–æ–∂–Ω–æ—Å—Ç–∏: {', '.join(task.difficulty_factors)}")
        print(f"   –ö–æ–Ω—Ü–µ–ø—Ü–∏–∏: {', '.join(task.programming_concepts)}")
        print(f"   JS —Ñ–∏—á–∏: {', '.join(task.js_features_used)}")
        print(f"   –ü—Ä–µ—Ä–µ–∫–≤–∏–∑–∏—Ç—ã: {', '.join(task.prerequisite_concepts)}")
        print(f"   –í—Ä–µ–º—è –∏–∑—É—á–µ–Ω–∏—è: {task.estimated_time_minutes} –º–∏–Ω")
        print(f"   –£—Ä–æ–≤–µ–Ω—å: {task.target_skill_level}")
        
        if task.text_content:
            print(f"   –û–ø–∏—Å–∞–Ω–∏–µ: {task.text_content[:200]}...")
        
        print(f"   –ö–æ–¥ ({task.code_lines} —Å—Ç—Ä–æ–∫):")
        code_lines = task.code_content.split('\n')[:8]
        for i, line in enumerate(code_lines, 1):
            if line.strip():
                print(f"      {i}: {line}")
        total_lines = len(task.code_content.split('\n'))
        if total_lines > 8:
            remaining_lines = total_lines - 8
            print(f"      ... (–µ—â–µ {remaining_lines} —Å—Ç—Ä–æ–∫)")

    def calculate_text_complexity(self, text: str) -> float:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–ª–æ–∂–Ω–æ—Å—Ç—å —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è"""
        if not text:
            return 0.0
        
        complexity = 0.0
        
        # –î–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞
        word_count = len(text.split())
        complexity += min(word_count / 100, 2.0)  # –¥–æ 2 –±–∞–ª–ª–æ–≤ –∑–∞ –¥–ª–∏–Ω—É
        
        # –°–ª–æ–∂–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã
        complex_terms = [
            '–∞–ª–≥–æ—Ä–∏—Ç–º', '—Ä–µ–∫—É—Ä—Å–∏—è', '–∏—Ç–µ—Ä–∞—Ü–∏—è', '—Å–ª–æ–∂–Ω–æ—Å—Ç—å', '–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è',
            '–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞', '–ø–∞—Ç—Ç–µ—Ä–Ω', '–ø–æ–ª–∏–º–æ—Ä—Ñ–∏–∑–º', '–∏–Ω–∫–∞–ø—Å—É–ª—è—Ü–∏—è', '–Ω–∞—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ',
            '–∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ—Å—Ç—å', '–ø—Ä–æ–º–∏—Å', '–∫–æ–ª–±—ç–∫', '–∑–∞–º—ã–∫–∞–Ω–∏–µ', '–ø—Ä–æ—Ç–æ—Ç–∏–ø'
        ]
        
        text_lower = text.lower()
        complex_term_count = sum(1 for term in complex_terms if term in text_lower)
        complexity += complex_term_count * 0.5
        
        # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –∫–æ–¥–∞ –≤ —Ç–µ–∫—Å—Ç–µ
        code_examples = text.count('```') + text.count('`')
        complexity += code_examples * 0.3
        
        # –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ —Ñ–æ—Ä–º—É–ª—ã –∏–ª–∏ —Å–ª–æ–∂–Ω—ã–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è
        math_indicators = ['O(', 'Œ∏(', '–≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è', '–ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å']
        math_count = sum(1 for indicator in math_indicators if indicator in text_lower)
        complexity += math_count * 1.0
        
        return round(complexity, 2)

    def determine_pedagogical_type(self, text: str, code: str, title: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ø–µ–¥–∞–≥–æ–≥–∏—á–µ—Å–∫–∏–π —Ç–∏–ø –∑–∞–¥–∞—á–∏"""
        content = (text + " " + title).lower()
        
        # –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã —Ç–∏–ø–æ–≤
        if any(word in content for word in ['–æ–±—ä—è—Å–Ω–µ–Ω–∏–µ', '–ø–æ–Ω—è—Ç–∏–µ', '—á—Ç–æ —Ç–∞–∫–æ–µ', '–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ']):
            return "explanation"
        elif any(word in content for word in ['–ø—Ä–∏–º–µ—Ä', '—Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º', '–¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è']):
            return "example"
        elif any(word in content for word in ['–∑–∞–¥–∞—á–∞', '—Ä–µ–∞–ª–∏–∑—É–π—Ç–µ', '—Å–æ–∑–¥–∞–π—Ç–µ', '–Ω–∞–ø–∏—à–∏—Ç–µ']):
            return "exercise"
        elif any(word in content for word in ['—Å–ª–æ–∂–Ω–∞—è', 'advanced', '—ç–∫—Å–ø–µ—Ä—Ç–Ω—ã–π', 'challenge']):
            return "challenge"
        else:
            return "practice"

    def create_topic_based_structure(self, analyses: List[TaskAnalysis]) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –Ω–∞ –æ—Å–Ω–æ–≤–µ 10 –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ç–µ–º JavaScript"""
        
        # 10 –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ç–µ–º —Å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
        CORE_TOPICS = {
            'closures': {
                'title': '–ó–∞–º—ã–∫–∞–Ω–∏—è',
                'icon': 'üîí',
                'color': '#8B5CF6',
                'description': '–ó–∞–º—ã–∫–∞–Ω–∏—è, –æ–±–ª–∞—Å—Ç–∏ –≤–∏–¥–∏–º–æ—Å—Ç–∏, –ª–µ–∫—Å–∏—á–µ—Å–∫–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ',
                'keywords': [
                    'closure', 'hello world', 'counter', 'makeCounter', 'canGetCount',
                    'createFunctionArray', 'lexical', 'scope', '–∑–∞–º—ã–∫–∞', '–∑–∞–º—ã–∫–∞–Ω–∏–µ',
                    'ad(5)()', 'count()', 'callback'
                ]
            },
            'custom_functions': {
                'title': '–ö–∞—Å—Ç–æ–º–Ω—ã–µ –º–µ—Ç–æ–¥—ã –∏ —Ñ—É–Ω–∫—Ü–∏–∏',
                'icon': '‚ö°',
                'color': '#F59E0B',
                'description': '–ö–∞—Ä—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ, –∫–æ–º–ø–æ–∑–∏—Ü–∏—è, –º–µ–º–æ–∏–∑–∞—Ü–∏—è, –ø–µ—Ä–µ–≥—Ä—É–∑–∫–∞',
                'keywords': [
                    'sum(1)(2)(3)', 'add(', 'compose', 'pipe', 'memo', 'memoize',
                    '–ø–µ—Ä–µ–≥—Ä—É–∑–∫–∞', 'curry', '—Ñ—É–Ω–∫—Ü–∏–π', '–º–µ—Ç–æ–¥—ã', '–∫–∞—Ä—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ'
                ]
            },
            'classes': {
                'title': '–ö–ª–∞—Å—Å—ã',
                'icon': 'üèóÔ∏è',
                'color': '#EF4444',
                'description': 'ES6 –∫–ª–∞—Å—Å—ã, –Ω–∞—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ, –ø–∞—Ç—Ç–µ—Ä–Ω—ã –ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è',
                'keywords': [
                    'class', 'constructor', 'singleton', 'queue', 'stack', 'store',
                    'extends', 'super', 'getInstance', 'cat', 'List<T>', 'new '
                ]
            },
            'arrays': {
                'title': '–ú–∞—Å—Å–∏–≤—ã',
                'icon': 'üìä',
                'color': '#10B981',
                'description': '–û–ø–µ—Ä–∞—Ü–∏–∏ —Å –º–∞—Å—Å–∏–≤–∞–º–∏, –∞–ª–≥–æ—Ä–∏—Ç–º—ã, –º–∞–Ω–∏–ø—É–ª—è—Ü–∏–∏',
                'keywords': [
                    'array', 'findMinMax', 'twoSum', 'chunk', 'moveZeroes',
                    'removeEvenIndexedElements', 'getConcatenation', 'maxElementIndex',
                    '–º–∞—Å—Å–∏–≤', 'splice', 'push', 'pop'
                ]
            },
            'matrices': {
                'title': '–ú–∞—Ç—Ä–∏—Ü—ã',
                'icon': 'üî¢',
                'color': '#3B82F6',
                'description': '–î–≤—É–º–µ—Ä–Ω—ã–µ –º–∞—Å—Å–∏–≤—ã, –∞–ª–≥–æ—Ä–∏—Ç–º—ã –Ω–∞ –º–∞—Ç—Ä–∏—Ü–∞—Ö',
                'keywords': [
                    'matrix', 'grid', 'battleship', 'rotate', 'spiral', 'island',
                    'transpose', 'celebrity', 'countShips', 'numIslands',
                    '–º–∞—Ç—Ä–∏—Ü–∞', 'board'
                ]
            },
            'objects': {
                'title': '–û–±—ä–µ–∫—Ç—ã',
                'icon': 'üì¶',
                'color': '#06B6D4',
                'description': '–°—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö, –¥–µ—Ä–µ–≤—å—è, –æ–±—Ö–æ–¥ –≥—Ä–∞—Ñ–æ–≤',
                'keywords': [
                    'tree', 'dfs', 'bfs', 'collectValues', 'children', 'value',
                    'left', 'right', 'root', '–æ–±—ä–µ–∫—Ç', 'nodes', 'traverse'
                ]
            },
            'promises': {
                'title': '–ü—Ä–æ–º–∏—Å—ã',
                'icon': '‚è≥',
                'color': '#8B5CF6',
                'description': '–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ—Å—Ç—å, –ø—Ä–æ–º–∏—Å—ã, async/await',
                'keywords': [
                    'promise', 'async', 'await', 'sleep', 'timeout', 'timeLimit',
                    'withTimeout', 'sumPromises', 'setTimeout', 'then', 'catch',
                    '–ø—Ä–æ–º–∏—Å', '–∞—Å–∏–Ω—Ö—Ä–æ–Ω'
                ]
            },
            'strings': {
                'title': '–°—Ç—Ä–æ–∫–∏',
                'icon': 'üî§',
                'color': '#F97316',
                'description': '–†–∞–±–æ—Ç–∞ —Å–æ —Å—Ç—Ä–æ–∫–∞–º–∏, –∞–ª–≥–æ—Ä–∏—Ç–º—ã –Ω–∞ —Å—Ç—Ä–æ–∫–∞—Ö',
                'keywords': [
                    'string', 'reverse', 'anagram', 'palindrome', 'greet',
                    'lengthOfLastWord', 'compress', '—Å—Ç—Ä–æ–∫–∞', 'charAt', 'substring'
                ]
            },
            'throttle_debounce': {
                'title': 'Throttle & Debounce',
                'icon': 'üéõÔ∏è',
                'color': '#EC4899',
                'description': '–ö–æ–Ω—Ç—Ä–æ–ª—å –≤—ã–∑–æ–≤–æ–≤ —Ñ—É–Ω–∫—Ü–∏–π, –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å',
                'keywords': [
                    'throttle', 'debounce', 'useThrottle', 'useDebounce',
                    '—Ç—Ä–æ—Ç–ª', '–¥–µ–±–∞—É–Ω—Å', '–∑–∞–¥–µ—Ä–∂–∫–∞', '–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å'
                ]
            },
            'numbers': {
                'title': '–ß–∏—Å–ª–∞',
                'icon': 'üßÆ',
                'color': '#84CC16',
                'description': '–ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏, –∞–ª–≥–æ—Ä–∏—Ç–º—ã —Å —á–∏—Å–ª–∞–º–∏',
                'keywords': [
                    'factorial', 'fibonacci', 'reverseNumber', 'fizzBuzz',
                    'sumOfNumber', 'largestPossibleNumber', '—Ñ–∞–∫—Ç–æ—Ä–∏–∞–ª',
                    '—á–∏—Å–ª–æ', '–º–∞—Ç–µ–º–∞—Ç–∏–∫'
                ]
            }
        }
        
        logger.info(f"üîç –ì—Ä—É–ø–ø–∏—Ä—É–µ–º {len(analyses)} –∑–∞–¥–∞—á –ø–æ 10 –æ—Å–Ω–æ–≤–Ω—ã–º —Ç–µ–º–∞–º...")
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –∑–∞–¥–∞—á–∏ –ø–æ —Ç–µ–º–∞–º
        topic_structure = {}
        unassigned_tasks = []
        
        for topic_key, topic_config in CORE_TOPICS.items():
            topic_tasks = []
            
            for analysis in analyses:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º –≤ –∑–∞–≥–æ–ª–æ–≤–∫–µ, –∫–æ–¥–µ –∏ –æ–ø–∏—Å–∞–Ω–∏–∏
                content = (
                    analysis.title + " " + 
                    analysis.code_content + " " + 
                    analysis.text_content + " " +
                    " ".join(analysis.path_titles)
                ).lower()
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è —Å –∫–ª—é—á–µ–≤—ã–º–∏ —Å–ª–æ–≤–∞–º–∏
                matches = 0
                for keyword in topic_config['keywords']:
                    if keyword.lower() in content:
                        matches += 1
                
                # –ï—Å–ª–∏ –µ—Å—Ç—å —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è, –¥–æ–±–∞–≤–ª—è–µ–º –∫ —Ç–µ–º–µ
                if matches > 0:
                    topic_tasks.append({
                        'id': analysis.id,
                        'title': analysis.title,
                        'complexity': analysis.complexity_score,
                        'skill_level': analysis.target_skill_level,
                        'time_minutes': analysis.estimated_time_minutes,
                        'concepts': analysis.programming_concepts,
                        'js_features': analysis.js_features_used,
                        'companies': self.extract_companies_from_text(analysis.text_content),
                        'matches': matches,  # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
                        'code_preview': analysis.code_content[:200] + "..." if len(analysis.code_content) > 200 else analysis.code_content,
                        'text_preview': analysis.text_content[:150] + "..." if len(analysis.text_content) > 150 else analysis.text_content
                    })
            
            # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã (–∑–∞–¥–∞—á–∞ –º–æ–∂–µ—Ç –ø–æ–¥—Ö–æ–¥–∏—Ç—å –∫ –Ω–µ—Å–∫–æ–ª—å–∫–∏–º —Ç–µ–º–∞–º)
            # –û—Å—Ç–∞–≤–ª—è–µ–º –∑–∞–¥–∞—á—É –≤ —Ç–µ–º–µ —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
            unique_tasks = {}
            for task in topic_tasks:
                task_id = task['id']
                if task_id not in unique_tasks or task['matches'] > unique_tasks[task_id]['matches']:
                    unique_tasks[task_id] = task
            
            topic_tasks = list(unique_tasks.values())
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
            topic_tasks.sort(key=lambda x: (x['complexity'], x['time_minutes']))
            
            # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            total_tasks = len(topic_tasks)
            avg_complexity = sum(t['complexity'] for t in topic_tasks) / total_tasks if total_tasks > 0 else 0
            difficulty_distribution = self.calculate_difficulty_distribution(topic_tasks)
            
            topic_structure[topic_key] = {
                'config': topic_config,
                'tasks': topic_tasks,
                'total_tasks': total_tasks,
                'avg_complexity': round(avg_complexity, 2),
                'difficulty_distribution': difficulty_distribution,
                'estimated_total_time': sum(t['time_minutes'] for t in topic_tasks),
                'top_companies': self.get_top_companies(topic_tasks),
                'skill_progression': self.calculate_skill_progression(topic_tasks)
            }
            
            logger.info(f"   üìå {topic_config['title']}: {total_tasks} –∑–∞–¥–∞—á (—Å–ª–æ–∂–Ω–æ—Å—Ç—å: {round(avg_complexity, 2)})")
        
        # –ù–∞—Ö–æ–¥–∏–º –Ω–µ–Ω–∞–∑–Ω–∞—á–µ–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏
        assigned_task_ids = set()
        for topic_data in topic_structure.values():
            for task in topic_data['tasks']:
                assigned_task_ids.add(task['id'])
        
        unassigned_tasks = [a for a in analyses if a.id not in assigned_task_ids]
        
        logger.info(f"‚úÖ –°–æ–∑–¥–∞–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞: {len(assigned_task_ids)} –∑–∞–¥–∞—á —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–æ, {len(unassigned_tasks)} –Ω–µ –Ω–∞–∑–Ω–∞—á–µ–Ω–æ")
        
        return {
            'topics': topic_structure,
            'unassigned_tasks': [
                {
                    'id': task.id,
                    'title': task.title,
                    'complexity': task.complexity_score,
                    'concepts': task.programming_concepts
                }
                for task in unassigned_tasks
            ],
            'total_assigned': len(assigned_task_ids),
            'total_unassigned': len(unassigned_tasks),
            'coverage_percentage': round((len(assigned_task_ids) / len(analyses)) * 100, 1)
        }

    def extract_companies_from_text(self, text: str) -> List[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–º–ø–∞–Ω–∏–π –∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è –∑–∞–¥–∞—á–∏"""
        if not text:
            return []
            
        companies = []
        text = text.lower()
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫–æ–º–ø–∞–Ω–∏–π
        company_patterns = [
            r'–≤—Å—Ç—Ä–µ—á–∞–ª–æ—Å—å –≤\s*[-\s]*([^\n]+)',
            r'–ø–æ–ø–∞–¥–∞–ª–æ—Å—å –≤\s*[-\s]*([^\n]+)',
            r'—Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω[–∏–µ|–∏—è—Ö].*?–≤\s+([–∞-—è—ë\s\-\.]+)',
            r'–∫–æ–º–ø–∞–Ω–∏[–∏—è|–∏]\s+([–∞-—è—ë\s\-\.]+)',
        ]
        
        for pattern in company_patterns:
            matches = re.findall(pattern, text, re.IGNORECASE | re.MULTILINE)
            for match in matches:
                # –û—á–∏—â–∞–µ–º –∏ —Ä–∞–∑–±–∏–≤–∞–µ–º –ø–æ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è–º
                clean_companies = re.split(r'[,\n\-]', match.strip())
                for company in clean_companies:
                    company = company.strip()
                    if company and len(company) > 2:
                        companies.append(company.title())
        
        return list(set(companies))

    def calculate_difficulty_distribution(self, tasks: List[Dict]) -> Dict[str, int]:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —É—Ä–æ–≤–Ω—è–º —Å–ª–æ–∂–Ω–æ—Å—Ç–∏"""
        distribution = {'beginner': 0, 'intermediate': 0, 'advanced': 0}
        
        for task in tasks:
            level = task.get('skill_level', 'intermediate')
            if level in distribution:
                distribution[level] += 1
        
        return distribution

    def get_top_companies(self, tasks: List[Dict]) -> List[Dict[str, Any]]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–æ–ø –∫–æ–º–ø–∞–Ω–∏–π –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —É–ø–æ–º–∏–Ω–∞–Ω–∏–π"""
        company_count = Counter()
        
        for task in tasks:
            for company in task.get('companies', []):
                company_count[company] += 1
        
        return [
            {'name': company, 'count': count}
            for company, count in company_count.most_common(5)
        ]

    def calculate_skill_progression(self, tasks: List[Dict]) -> List[str]:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º—É—é –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏–∑—É—á–µ–Ω–∏—è"""
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –∏ –≤—Ä–µ–º–µ–Ω–∏ –∏–∑—É—á–µ–Ω–∏—è
        sorted_tasks = sorted(tasks, key=lambda x: (x['complexity'], x['time_minutes']))
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–µ—Ä–≤—ã–µ 10 –∑–∞–¥–∞—á –∫–∞–∫ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º—É—é –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å
        return [task['id'] for task in sorted_tasks[:10]]

def main():
    """–ó–∞–ø—É—Å–∫ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
    analyzer = DeepContentAnalyzer()
    result = analyzer.analyze_all_tasks()
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ JSON –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    output_file = "detailed_analysis_result.json"
    
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º dataclass –æ–±—ä–µ–∫—Ç—ã –≤ —Å–ª–æ–≤–∞—Ä–∏ –¥–ª—è JSON
    json_result = {
        'task_analyses': [asdict(analysis) for analysis in result['task_analyses']],
        'concept_clusters': result['concept_clusters'],  # —É–∂–µ —Å–ª–æ–≤–∞—Ä—å
        'learning_sequences': result['learning_sequences'],
        'path_structure': result['path_structure'],
        'pedagogical_analysis': result['pedagogical_analysis'],
        'user_statistics': result['user_statistics'],
        'summary_stats': result['summary_stats']
    }
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º set –≤ list –¥–ª—è JSON
    for task in json_result['task_analyses']:
        task['keywords'] = list(task['keywords'])
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(json_result, f, ensure_ascii=False, indent=2)
    
    print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ —Ñ–∞–π–ª: {output_file}")
    
    # –í—ã–≤–æ–¥–∏–º –¥–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç
    analyzer.print_detailed_report(result)

if __name__ == "__main__":
    main()